{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"None","text":"<p> \ud83d\udea7 SleepKit is under active development </p> <p>Documentation: https://ambiqai.github.io/sleepkit</p> <p>Source Code: https://github.com/AmbiqAI/sleepkit</p> <p>SleepKit is an AI Development Kit (ADK) that enables developers to easily build and deploy real-time sleep monitoring models on Ambiq's family of ultra-low power SoCs. SleepKit explores a number of sleep related tasks including sleep staging, sleep apnea detection, and sleep arousal detection. The kit includes a variety of datasets, efficient model architectures, and a number of pre-trained models. The objective of the models is to outperform conventional, hand-crafted algorithms with efficient AI models that still fit within the stringent resource constraints of embedded devices. Furthermore, the included models are trainined using a large variety datasets- using a subset of biological signals that can be captured from a single body location such as head, chest, or wrist/hand. The goal is to enable models that can be deployed in real-world commercial and consumer applications that are viable for long-term use.</p> <p>Key Features:</p> <ul> <li>Real-time: Inference is performed in real-time on battery-powered, edge devices.</li> <li>Efficient: Leverage modern AI techniques coupled with Ambiq's ultra-low power SoCs</li> <li>Generalizable: Multi-modal, multi-task, multi-dataset</li> <li>Accurate: Achieve SoTA results with stringent resource constraints</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python ^3.11</li> <li>Poetry ^1.6.1</li> </ul> <p>The following are also required to compile/flash the binary for the EVB demo:</p> <ul> <li>Arm GNU Toolchain ^12.2</li> <li>Segger J-Link ^7.92</li> </ul> <p>Note</p> <p>A VSCode Dev Container is also available and defined in ./.devcontainer.</p>"},{"location":"#installation","title":"Installation","text":"<p>To get started, first install the local python package <code>sleepkit</code> along with its dependencies via <code>Poetry</code>:</p> <pre><code>$ poetry install\n\n---&gt; 100%\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>SleepKit can be used as either a CLI-based app or as a python package to perform advanced experimentation. In both forms, SleepKit exposes a number of modes and tasks discussed below. Refer to the Overview Guide to learn more about available options and configurations.</p>"},{"location":"#modes","title":"Modes","text":"<ul> <li><code>download</code>: Download datasets</li> <li><code>feature</code>: Extract features from dataset(s)</li> <li><code>train</code>: Train a model for specified task and dataset(s)</li> <li><code>evaluate</code>: Evaluate a model for specified task and dataset(s)</li> <li><code>export</code>: Export a trained model to TF Lite and TFLM</li> <li><code>demo</code>: Run task-level demo on PC or EVB</li> </ul>"},{"location":"#tasks","title":"Tasks","text":"<ul> <li><code>detect</code>: Detect sustained sleep/inactivity bouts</li> <li><code>stage</code>: Perform advanced 2, 3, 4, or 5 stage sleep assessment</li> <li><code>apnea</code>: Detect hypopnea/apnea events</li> <li><code>arousal</code>: Detect sleep arousal events</li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p>SleepKit leverages modern architectural design strategies to achieve high accuracy while maintaining a small memory footprint and low power consumption. Refer to specific task guides for additional details on the full model design.</p> <ul> <li>Seperable (depthwise + pointwise) Convolutions</li> <li>Inverted Residual Bottlenecks</li> <li>Squeeze &amp; Excitation Blocks</li> <li>Over-Parameterized Convolutional Branches</li> <li>Dilated Convolutions</li> </ul>"},{"location":"#datasets","title":"Datasets","text":"<p>SleepKit uses several open-source datasets for training each of the tasks. In general, we use commercial-use friendly datasets that are publicly available. Check out the Datasets Guide to learn more about the datasets used along with their corresponding licenses and limitations.</p>"},{"location":"#model-zoo","title":"Model Zoo","text":"<p>A number of pre-trained models are available for each task. These models are trained on a variety of datasets and are optimized for deployment on Ambiq's ultra-low power SoCs. Check out the Model Zoo to learn more about the available models and their corresponding performance metrics.</p>"},{"location":"#references","title":"References","text":"<ul> <li>U-Sleep: Resilient High-Frequency Sleep Staging</li> <li>U-Time: A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging</li> <li>DeepSleepNet: a Model for Automatic Sleep Stage Scoring based on Raw Single-Channel EEG</li> <li>AI-Driven sleep staging from actigraphy and heart rate</li> <li>TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis</li> <li>The Promise of Sleep: A Multi-Sensor Approach for Accurate Sleep Stage Detection Using the Oura Ring</li> <li>Interrater reliability of sleep stage scoring: a meta-analysis</li> <li>Development of generalizable automatic sleep staging using heart rate and movement based on large databases</li> </ul>"},{"location":"datasets/","title":"Datasets","text":""},{"location":"datasets/#mesa-dataset","title":"MESA Dataset","text":""},{"location":"datasets/#overview","title":"Overview","text":"<p>Multi-Ethnic Study of Atherosclerosis (MESA) is an NHLBI-sponsored 6-center collaborative longitudinal investigation of factors associated with the development of subclinical cardiovascular disease and the progression of subclinical to clinical cardiovascular disease in 6,814 black, white, Hispanic, and Chinese-American men and women initially ages 45-84 at baseline in 2000-2002. There have been four follow-up exams to date, in the years 2003-2004, 2004-2005, 2005-2007, and 2010-2011. Between 2010-2012, 2,237 participants also were enrolled in a Sleep Exam (MESA Sleep) which included full overnight unattended polysomnography, 7-day wrist-worn actigraphy, and a sleep questionnaire. The objectives of the sleep study are to understand how variations in sleep and sleep disorders vary across gender and ethnic groups and relate to measures of subclinical atherosclerosis.</p> <p>More info available on NSRR website</p>"},{"location":"datasets/#funding","title":"Funding","text":"<p>The Multi-Ethnic Study of Atherosclerosis (MESA) Sleep Ancillary study was funded by NIH-NHLBI Association of Sleep Disorders with Cardiovascular Health Across Ethnic Groups (RO1 HL098433). MESA is supported by NHLBI funded contracts HHSN268201500003I, N01-HC-95159, N01-HC-95160, N01-HC-95161, N01-HC-95162, N01-HC-95163, N01-HC-95164, N01-HC-95165, N01-HC-95166, N01-HC-95167, N01-HC-95168 and N01-HC-95169 from the National Heart, Lung, and Blood Institute, and by cooperative agreements UL1-TR-000040, UL1-TR-001079, and UL1-TR-001420 funded by NCATS. The National Sleep Research Resource was supported by the National Heart, Lung, and Blood Institute (R24 HL114473, 75N92019R002).</p>"},{"location":"datasets/#licensing","title":"Licensing","text":"<p>The STAGES dataset is available for non-commercial and commercial use.</p>"},{"location":"datasets/#stages-dataset","title":"STAGES Dataset","text":""},{"location":"datasets/#overview_1","title":"Overview","text":"<p>The Stanford Technology Analytics and Genomics in Sleep (STAGES) study is a prospective cross-sectional, multi-site study involving 20 data collection sites from six centers including Stanford University, Bogan Sleep Consulting, Geisinger Health, Mayo Clinic, MedSleep, and St. Luke's Hospital. The project has collected data on 1,500 adult/adolescent patients evaluated for sleep disorders, including:</p> <ul> <li>Objective nocturnal sleep polysomnography (PSG) recordings (EEGs, chin and leg EMGs, nasal and oral breathing, chest movements, leg movements, position, EKG). This is the gold standard for sleep evaluation in sleep clinics.</li> <li>Comprehensive subjective sleep symptoms assessment through an on-line sleep questionnaire called the Alliance Sleep Questionnaire (ASQ, developed over 5 years by 5 academic institutions). The questionnaire also includes key medical history questions.</li> <li>Continuous actigraphy over several weeks to get untransformed activity counts (a Huami/Xiaomi actigraph device has been identified and validated against PSG and clinical gold standard Actiwatch)</li> <li>3-D facial scans to extract craniofacial features predictive of sleep apnea (not available on NSRR)</li> <li>On-line neuropsychological assessments and psychovigilance tests (impact of sleep disorders)</li> <li>Medical record data (not available on NSRR)</li> </ul> <p>All data, samples, analytic tools, and supporting documentation will be made publicly available for use by any interested researcher, provided a request is submitted to the National Sleep Research Resource and approved.</p> <p>The National Sleep Research Resource is grateful to the STAGES team for sharing these data.</p> <p>More info available on NSRR website</p>"},{"location":"datasets/#funding_1","title":"Funding","text":"<p>This research has been conducted using the STAGES - Stanford Technology, Analytics and Genomics in Sleep Resource funded by the Klarman Family Foundation. The investigators of the STAGES study contributed to the design and implementation of the STAGES cohort and/or provided data and/or collected biospecimens, but did not necessarily participate in the analysis or writing of this report. The full list of STAGES investigators can be found at the project website.</p> <p>The National Sleep Research Resource was supported by the U.S. National Institutes of Health, National Heart Lung and Blood Institute (R24 HL114473, 75N92019R002).</p>"},{"location":"datasets/#licensing_1","title":"Licensing","text":"<p>The STAGES dataset is available for non-commercial and commercial use.</p>"},{"location":"datasets/#ysyw-dataset","title":"YSYW Dataset","text":""},{"location":"datasets/#overview_2","title":"Overview","text":"<p>A total of 1,983 PSG recordings were provided by the Massachusetts General Hospital\u2019s (MGH) Sleep Lab in the Sleep Division together with the Computational Clinical Neurophysiology Laboratory, and the Clinical Data Ani- mation Center. The Partners Institutional Review Board approved retrospective analysis of the MGH dataset with- out requiring additional consent.</p> <p>More info available on PhysioNet website</p>"},{"location":"datasets/#funding_2","title":"Funding","text":"<p>Funding was from the National Institutes of Health, grant R01-GM104987. We are also grateful to Mathworks and Computing in Cardiology for sponsoring the competi- tion prize money and software licenses.</p>"},{"location":"datasets/#licensing_2","title":"Licensing","text":"<p>The YSYW dataset is available commercial use under Open Data Commons Attribution License.</p>"},{"location":"datasets/#cmidss-dataset","title":"CMIDSS Dataset","text":""},{"location":"datasets/#overview_3","title":"Overview","text":"<p>This dataset comes from the Child Mind Institute - Detect Sleep States (CMIDSS) Kaggle competition. The dataset comprises 300 subjects with over 500 multi-day recordings of wrist-worn accelerometer data annotated with two event types: onset, the beginning of sleep, and wakeup, the end of sleep. While the original data contains 3-axis accelerometer data, this dataset only contains the euclidean norm minus one (ENMO) and z-angle reported every 5 seconds.</p> <p>More info available on PhysioNet website</p>"},{"location":"datasets/#funding_3","title":"Funding","text":"<p>The data was provided by the Healthy Brain Network, a landmark mental health study based in New York City that will help children around the world. In the Healthy Brain Network, families, community leaders, and supporters are partnering with the Child Mind Institute to unlock the secrets of the developing brain. In addition to generous support provided by the Kaggle team, financial support has been provided by the Stavros Niarchos Foundation (SNF) as part of its Global Health Initiative (GHI) through the SNF Global Center for Child and Adolescent Mental Health at the Child Mind Institute.</p>"},{"location":"datasets/#licensing_3","title":"Licensing","text":"<p>The CMIDSS dataset is available for non-commercial use under Attribution-NonCommercial-ShareAlike 4.0 International.</p>"},{"location":"models/","title":"Model Factory","text":"<p>SleepKit provides a model factory that allows you to easily create and train custom models. The model factory is a wrapper around the TensorFlow Keras API that allows you to create functional-based models using high-level parameters. Most of the models are based on state-of-the-art architectures that have been modified to allow for more fine-grain customization. We also provide 1D variants to allow for training on time-series data.</p>"},{"location":"models/#temporal-convolutional-network-tcn","title":"Temporal Convolutional Network (TCN)","text":""},{"location":"models/#overview","title":"Overview","text":"<p>Temporal convolutional network (TCN) is a type of convolutional neural network (CNN) that is commonly used for sequence modeling tasks such as speech recognition, text generation, and video classification. TCN is a fully convolutional network that consists of a series of dilated causal convolutional layers. The dilated convolutional layers allow TCN to have a large receptive field while maintaining a small number of parameters. TCN is also fully parallelizable, which allows for faster training and inference times.</p> <p>For more info, refer to original paper Temporal Convolutional Networks: A Unified Approach to Action Segmentation</p>"},{"location":"models/#additions","title":"Additions","text":"<p>The TCN architecture has been modified to allow the following:</p> <ul> <li>Convolutional pairs can factorized into depthwise separable convolutions.</li> <li>Squeeze and excitation (SE) blocks can be added between convolutional pairs.</li> <li>Normalization can be set between batch normalization and layer normalization.</li> <li>ReLU is replaced with the approximated ReLU6.</li> </ul>"},{"location":"models/#u-net","title":"U-Net","text":""},{"location":"models/#overview_1","title":"Overview","text":"<p>U-Net is a type of convolutional neural network (CNN) that is commonly used for segmentation tasks. U-Net is a fully convolutional network that consists of a series of convolutional layers and pooling layers. The pooling layers are used to downsample the input while the convolutional layers are used to upsample the input. The skip connections between the pooling layers and convolutional layers allow U-Net to preserve spatial/temporal information while also allowing for faster training and inference times.</p> <p>For more info, refer to original paper U-Net: Convolutional Networks for Biomedical Image Segmentation</p>"},{"location":"models/#additions_1","title":"Additions","text":"<p>The U-Net architecture has been modified to allow the following:</p> <ul> <li>Enable 1D and 2D variants.</li> <li>Convolutional pairs can factorized into depthwise separable convolutions.</li> <li>Specifiy the number of convolutional layers per block both downstream and upstream.</li> <li>Normalization can be set between batch normalization and layer normalization.</li> <li>ReLU is replaced with the approximated ReLU6.</li> </ul>"},{"location":"models/#u-next","title":"U-NeXt","text":""},{"location":"models/#overview_2","title":"Overview","text":"<p>U-NeXt is a modification of U-Net that utilizes techniques from ResNeXt and EfficientNetV2. During the encoding phase, mbconv blocks are used to efficiently process the input.</p>"},{"location":"models/#additions_2","title":"Additions","text":"<p>The U-NeXt architecture has been modified to allow the following:</p> <ul> <li>MBConv blocks used in the encoding phase.</li> <li>Squueze and excitation (SE) blocks added within blocks.</li> </ul>"},{"location":"models/#efficientnetv2","title":"EfficientNetV2","text":""},{"location":"models/#overview_3","title":"Overview","text":"<p>EfficientNetV2 is an improvement to EfficientNet that incorporates additional optimizations reduce both computation and memory. In particular, the architecture leverages both fused and non-fused MBConv blocks, non-uniform layer scaling, and training-aware NAS.</p> <p>For more info, refer to original paper EfficientNetV2: Smaller Models and Faster Training</p>"},{"location":"models/#additions_3","title":"Additions","text":"<p>The EfficientNetV2 architecture has been modified to allow the following:</p> <ul> <li>Enable 1D and 2D variants.</li> </ul>"},{"location":"models/#mobileone","title":"MobileOne","text":""},{"location":"models/#overview_4","title":"Overview","text":"<p>MobileOne is a fully convolutional neural network designed to have minimal latency when running in mobile/edge devices. The architecture consists of a series of depthwise separable convolutions and squeeze and excitation (SE) blocks. The network also uses standard batch normalization and ReLU activations that can be easily fused into the convolutional layers. Lastly, the network uses over-parameterized branches to improve training, yet can be merged into a single branch during inference.</p> <p>For more info, refer to original paper MobileOne: An Improved One millisecond Mobile Backbone</p>"},{"location":"models/#additions_4","title":"Additions","text":"<p>The MobileOne architecture has been modified to allow the following:</p> <ul> <li>Enable 1D and 2D variants.</li> <li>Enable dilated convolutions.</li> </ul>"},{"location":"models/#resnet","title":"ResNet","text":""},{"location":"models/#overview_5","title":"Overview","text":"<p>ResNet is a type of convolutional neural network (CNN) that is commonly used for image classification tasks. ResNet is a fully convolutional network that consists of a series of convolutional layers and pooling layers. The pooling layers are used to downsample the input while the convolutional layers are used to upsample the input. The skip connections between the pooling layers and convolutional layers allow ResNet to preserve spatial/temporal information while also allowing for faster training and inference times.</p> <p>For more info, refer to original paper Deep Residual Learning for Image Recognition</p>"},{"location":"models/#additions_5","title":"Additions","text":"<ul> <li>Enable 1D and 2D variants.</li> </ul>"},{"location":"overview/","title":"Overview","text":"<p>SleepKit can be used as either a CLI-based app or as a python package to perform advanced experimentation. In both forms, SleepKit exposes a number of modes and tasks discussed below:</p>"},{"location":"overview/#modes","title":"Modes","text":"<ul> <li><code>download</code>: Download datasets</li> <li><code>feature</code>: Extract features from dataset(s)</li> <li><code>train</code>: Train a model for specified task and dataset(s)</li> <li><code>evaluate</code>: Evaluate a model for specified task and dataset(s)</li> <li><code>export</code>: Export a trained model to TF Lite and TFLM</li> <li><code>demo</code>: Run task-level demo on PC or EVB</li> </ul> <p>Tasks</p> DetectStageApneaArousal"},{"location":"overview/#sleep-detection","title":"Sleep Detection","text":"<p>Detect sustained sleep/inactivity bouts.  Refer to Sleep Detect for more details.</p>"},{"location":"overview/#sleep-stage-classification","title":"Sleep Stage Classification","text":"<p>Perform 2, 3, 4, or 5 stage sleep detection. Refer to Sleep Stages for more details.</p>"},{"location":"overview/#sleep-apnea-detection","title":"Sleep Apnea Detection","text":"<p>Detect hypopnea/apnea events.  Not yet implemented.</p>"},{"location":"overview/#sleep-arousal-detection","title":"Sleep Arousal Detection","text":"<p>Detect sleep arousal events.  Not yet implemented.</p>"},{"location":"overview/#using-cli","title":"Using CLI","text":"<p>The SleepKit command line interface (CLI) makes it easy to run a variefy of single-line commands without the need for writing any code. You can rull all tasks and modes from the terminal with the <code>sleepkit</code> command.</p> <pre><code>$ sleepkit --help\n\nSleepKit CLI Options:\n    --task [detect, stage]\n    --mode [download, feature, train, evaluate, export, demo]\n    --config [\"./path/to/config.json\", or '{\"raw: \"json\"}']\n</code></pre> <p>Note</p> <p>Before running commands, be sure to activate python environment: <code>poetry shell</code>. On Windows using Powershell, use <code>.venv\\Scripts\\activate.ps1</code>.</p>"},{"location":"overview/#1-download-datasets","title":"1. Download Datasets","text":"<p>Note</p> <p>In order to download MESA and STAGES datasets, permission must be granted by NSSR. Both non-commercial and commercial variants are available for these datasets. Once granted permission, please follow NSSR documentation to install their command line <code>nssr</code> tool. Ensure <code>nssr</code> command is available on terminal and authorization token has been supplied.</p> <p>The <code>download</code> command is used to download all datasets specified in the configuration file. Please refer to Datasets for details on the available datasets.</p> <p>Example</p> <p>The following example will download and prepare all currently used datasets:</p> CLIPython <pre><code>sleepkit --mode download --config ./configs/download-datasets.json\n</code></pre> <pre><code>import sleepkit as sk\n\nsk.datasets.download_datasets(sk.defines.SKDownloadParams(\n    ds_path=\"./datasets\",\n    datasets=[\"mesa\", \"ysyw\"],\n    progress=True,\n    force=False\n))\n</code></pre>"},{"location":"overview/#2-extract-features","title":"2. Extract Features","text":"<p>The <code>feature</code> command is used to extract features from the downloaded datasets. In general, we extract physiological features (e.g. heart rate) from the raw signals (e.g. ppg) from a single body location (e.g. wrist). Please refer to <code>sleepkit/defines.py</code> to see supported options.</p> <p>Example</p> <p>The following command will generate feature set for training 2-stage sleep model using the reference configuration:</p> CLIPython <pre><code>sleepkit --mode feature --config ./configs/feature-stage-001.json\n</code></pre> <pre><code>import sleepkit as sk\n\nsk.features.generate_feature_set(sk.defines.SKFeatureParams(\n    ...\n))\n</code></pre>"},{"location":"overview/#3-train-model","title":"3. Train Model","text":"<p>The <code>train</code> command is used to train a SleepKit model for the specified <code>task</code> and <code>datasets</code>. Please refer to <code>sleepkit/defines.py</code> to see supported options.</p> <p>Example</p> <p>The following command will train a 2-stage sleep model using the reference configuration:</p> CLIPython <pre><code>sleepkit --task stage --mode train --config ./configs/sleep-stage-2/train.json\n</code></pre> <pre><code>import sleepkit as sk\n\nsk.stage.train(sk.defines.SKTrainParams(\n    ...\n))\n</code></pre>"},{"location":"overview/#4-evaluate-model","title":"4. Evaluate Model","text":"<p>The <code>evaluate</code> command will evaluate the performance of the model on the reserved test set.</p> <p>Example</p> <p>The following command will test a 2-stage sleep model using the reference configuration:</p> CLIPython <pre><code>sleepkit --task stage --mode evaluate --config ./configs/sleep-stage-2/test.json\n</code></pre> <pre><code>import sleepkit as sk\n\nsk.stage.evaluate(sk.defines.SKTestParams(\n    ...\n))\n</code></pre>"},{"location":"overview/#5-export-model","title":"5. Export Model","text":"<p>The <code>export</code> command will convert the trained TensorFlow model into both TensorFlow Lite (TFL) and TensorFlow Lite for microcontroller (TFLM) variants. The command will also verify the models' outputs match. Post-training quantization can also be enabled by setting the <code>quantization</code> flag in the configuration. Once converted, the TFLM header file will be copied to the location specified by <code>tflm_file</code>.</p> <p>Example</p> <p>The following command will export a 2-stage sleep model to TF Lite and TFLM:</p> CLIPython <pre><code>sleepkit --task stage --mode export --config ./configs/sleep-stage-2/export.json\n</code></pre> <pre><code>import sleepkit as sk\n\nsk.stage.export(sk.defines.SKExportParams(\n    ...\n))\n</code></pre>"},{"location":"overview/#6-demo","title":"6. Demo","text":"<p>The <code>demo</code> command is used to run a full-fledged SleepKit demonstration for the specific task.</p> <p>Example</p> CLIPython <pre><code>sleepkit --task stage --mode demo --config ./configs/sleep-stage-4/demo.json\n</code></pre> <pre><code>import sleepkit as sk\n\nsk.stage.demo(sk.defines.SKDemoParams(\n    ...\n))\n</code></pre>"},{"location":"results/","title":"Model Zoo","text":"<p>A number of pre-trained models are available for download to use in your own project. These models are trained on the datasets listed below and are available in TensorFlow flatbuffer formats.</p>"},{"location":"results/#sleep-detection","title":"Sleep Detection","text":"<p>The following table provides the latest performance and accuracy results for sleep detection models. Additional result details can be found in Tasks \u2192 Detect \u2192 Results.</p> # Classes Model Dataset Fs Params FLOPs Accuracy Config Download 2 TCN CMIDSS 64 Hz 6K 425K/hr 92.5% AP config model"},{"location":"results/#sleep-staging","title":"Sleep Staging","text":"<p>The following table provides the latest performance and accuracy results for sleep staging models. Additional result details can be found in Tasks \u2192 Staging \u2192 Results.</p> # Classes Model Dataset Fs Params FLOPs Accuracy Config Download 2 TCN MESA 64 Hz 10K 1.7M/hr 88.8% F1 config model 3 TCN MESA 64 Hz 14K 2.2M/hr 84.2% F1 config model 4 TCN MESA 64 Hz 14K 2.3M/hr 76.4% F1 config model 5 TCN MESA 64 Hz 17K 2.8M/hr 70.2% F1 config model"},{"location":"results/#sleep-apnea","title":"Sleep Apnea","text":"<p>Coming soon...</p>"},{"location":"results/#sleep-arousal","title":"Sleep Arousal","text":"<p>Coming soon...</p>"},{"location":"api/datasets/","title":"Datasets","text":"<p>See Datasets for information about available datasets.</p>"},{"location":"api/datasets/#sleepkit.datasets.dataset","title":"<code>sleepkit.datasets.dataset</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset","title":"<code>SKDataset</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Base SK dataset.</p> Source code in <code>sleepkit/datasets/dataset.py</code> <pre><code>class SKDataset(abc.ABC):\n    \"\"\"Base SK dataset.\"\"\"\n\n    def __init__(self, ds_path: Path, frame_size: int = 128, **kwargs) -&gt; None:\n        self.ds_path = ds_path\n        self.frame_size = frame_size\n\n    @property\n    def subject_ids(self) -&gt; list[str]:\n        \"\"\"Get dataset subject IDs\n\n        Returns:\n            list[str]: Subject IDs\n        \"\"\"\n        raise NotImplementedError()\n\n    @property\n    def train_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get train subject ids\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def test_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get test subject ids\"\"\"\n        raise NotImplementedError()\n\n    @property\n    def feature_shape(self) -&gt; tuple[int, int]:\n        \"\"\"Get feature shape\"\"\"\n        raise NotImplementedError()\n\n    def uniform_subject_generator(\n        self,\n        subject_ids: list[str] | None = None,\n        repeat: bool = True,\n        shuffle: bool = True,\n    ) -&gt; SubjectGenerator:\n        \"\"\"Yield data for each subject in the array.\n\n        Args:\n            subject_ids (pt.ArrayLike): Array of subject ids\n            repeat (bool, optional): Whether to repeat generator. Defaults to True.\n            shuffle (bool, optional): Whether to shuffle subject ids.. Defaults to True.\n\n        Returns:\n            SubjectGenerator: Subject generator\n\n        Yields:\n            Iterator[SubjectGenerator]\n        \"\"\"\n        raise NotImplementedError()\n\n    def load_subject_data(\n        self, subject_id: str, normalize: bool = True, epsilon: float = 1e-6\n    ) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]:\n        \"\"\"Load subject data\n\n        Args:\n            subject_id (str): Subject ID\n\n        Returns:\n            tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]: Tuple of features and labels\n        \"\"\"\n        raise NotImplementedError()\n\n    def signal_generator(\n        self, subject_generator, samples_per_subject: int = 1, normalize: bool = True, epsilon: float = 1e-6\n    ) -&gt; SampleGenerator:\n        \"\"\"Generate frames using subject generator\n\n        Args:\n            subject_generator (SubjectGenerator): Subject generator\n            samples_per_subject (int): # samples per subject\n\n        Returns:\n            SampleGenerator: Generator of input data of shape (frame_size, 1)\n        \"\"\"\n        raise NotImplementedError()\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.feature_shape","title":"<code>feature_shape: tuple[int, int]</code>  <code>property</code>","text":"<p>Get feature shape</p>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.subject_ids","title":"<code>subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get dataset subject IDs</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Subject IDs</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.test_subject_ids","title":"<code>test_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get test subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.train_subject_ids","title":"<code>train_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get train subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.load_subject_data","title":"<code>load_subject_data(subject_id, normalize=True, epsilon=1e-06)</code>","text":"<p>Load subject data</p> <p>Parameters:</p> <ul> <li> <code>subject_id</code>             (<code>str</code>)         \u2013          <p>Subject ID</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[NDArray, NDArray, NDArray | None]</code>         \u2013          <p>tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]: Tuple of features and labels</p> </li> </ul> Source code in <code>sleepkit/datasets/dataset.py</code> <pre><code>def load_subject_data(\n    self, subject_id: str, normalize: bool = True, epsilon: float = 1e-6\n) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]:\n    \"\"\"Load subject data\n\n    Args:\n        subject_id (str): Subject ID\n\n    Returns:\n        tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]: Tuple of features and labels\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.signal_generator","title":"<code>signal_generator(subject_generator, samples_per_subject=1, normalize=True, epsilon=1e-06)</code>","text":"<p>Generate frames using subject generator</p> <p>Parameters:</p> <ul> <li> <code>subject_generator</code>             (<code>SubjectGenerator</code>)         \u2013          <p>Subject generator</p> </li> <li> <code>samples_per_subject</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          </li> </ul> <p>Returns:</p> <ul> <li> <code>SampleGenerator</code> (            <code>SampleGenerator</code> )        \u2013          <p>Generator of input data of shape (frame_size, 1)</p> </li> </ul> Source code in <code>sleepkit/datasets/dataset.py</code> <pre><code>def signal_generator(\n    self, subject_generator, samples_per_subject: int = 1, normalize: bool = True, epsilon: float = 1e-6\n) -&gt; SampleGenerator:\n    \"\"\"Generate frames using subject generator\n\n    Args:\n        subject_generator (SubjectGenerator): Subject generator\n        samples_per_subject (int): # samples per subject\n\n    Returns:\n        SampleGenerator: Generator of input data of shape (frame_size, 1)\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.signal_generator--samples-per-subject","title":"samples per subject","text":""},{"location":"api/datasets/#sleepkit.datasets.dataset.SKDataset.uniform_subject_generator","title":"<code>uniform_subject_generator(subject_ids=None, repeat=True, shuffle=True)</code>","text":"<p>Yield data for each subject in the array.</p> <p>Parameters:</p> <ul> <li> <code>subject_ids</code>             (<code>ArrayLike</code>, default:                 <code>None</code> )         \u2013          <p>Array of subject ids</p> </li> <li> <code>repeat</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to repeat generator. Defaults to True.</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to shuffle subject ids.. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SubjectGenerator</code> (            <code>SubjectGenerator</code> )        \u2013          <p>Subject generator</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>SubjectGenerator</code>         \u2013          <p>Iterator[SubjectGenerator]</p> </li> </ul> Source code in <code>sleepkit/datasets/dataset.py</code> <pre><code>def uniform_subject_generator(\n    self,\n    subject_ids: list[str] | None = None,\n    repeat: bool = True,\n    shuffle: bool = True,\n) -&gt; SubjectGenerator:\n    \"\"\"Yield data for each subject in the array.\n\n    Args:\n        subject_ids (pt.ArrayLike): Array of subject ids\n        repeat (bool, optional): Whether to repeat generator. Defaults to True.\n        shuffle (bool, optional): Whether to shuffle subject ids.. Defaults to True.\n\n    Returns:\n        SubjectGenerator: Subject generator\n\n    Yields:\n        Iterator[SubjectGenerator]\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.defines","title":"<code>sleepkit.datasets.defines</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.download","title":"<code>sleepkit.datasets.download</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.download.download_datasets","title":"<code>download_datasets(params)</code>","text":"<p>Download datasets</p> Source code in <code>sleepkit/datasets/download.py</code> <pre><code>def download_datasets(params: SKDownloadParams):\n    \"\"\"Download datasets\"\"\"\n    if \"cmidss\" in params.datasets:\n        download_cmidss(params)\n\n    if \"mesa\" in params.datasets:\n        download_mesa(params)\n\n    if \"stages\" in params.datasets:\n        download_stages(params)\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.download.download_mesa","title":"<code>download_mesa(args)</code>","text":"<p>Download MESA dataset</p> Source code in <code>sleepkit/datasets/download.py</code> <pre><code>def download_mesa(args: SKDownloadParams):\n    \"\"\"Download MESA dataset\"\"\"\n    is_commercial = True\n    dataset = \"mesa-commercial-use\" if is_commercial else \"mesa\"\n    download_nssr_dataset(dataset, args.ds_path)\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.download.download_nssr_dataset","title":"<code>download_nssr_dataset(dataset, save_path)</code>","text":"<p>Download dataset from NSSR using nssr CLI tool</p> Source code in <code>sleepkit/datasets/download.py</code> <pre><code>def download_nssr_dataset(dataset: str, save_path: Path):\n    \"\"\"Download dataset from NSSR using nssr CLI tool\"\"\"\n    token = os.environ.get(\"NSSR_TOKEN\")\n    if token is None:\n        raise ValueError(\"NSSR_TOKEN is not set\")\n\n    if shutil.which(\"nssr\") is None:\n        raise ValueError(\"nssr is not installed or not in $PATH\")\n\n    logger.info(f\"Downloading {dataset} dataset to {save_path}\")\n\n    os.makedirs(save_path, exist_ok=True)\n\n    subprocess.run(\n        [\n            \"nssr\",\n            \"d\",\n            dataset,\n            f\"--token={os.environ.get('NSSR_TOKEN')}\",\n        ],\n        cwd=save_path.parent,\n        check=False,\n    )\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.download.download_stages","title":"<code>download_stages(args)</code>","text":"<p>Download STAGES dataset from NSSR</p> Source code in <code>sleepkit/datasets/download.py</code> <pre><code>def download_stages(args: SKDownloadParams):\n    \"\"\"Download STAGES dataset from NSSR\"\"\"\n    download_nssr_dataset(\"stages\", args.ds_path)\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.hdf5","title":"<code>sleepkit.datasets.hdf5</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset","title":"<code>Hdf5Dataset</code>","text":"<p>             Bases: <code>SKDataset</code></p> <p>Subject feature sets saved in HDF5 format.</p> Source code in <code>sleepkit/datasets/hdf5.py</code> <pre><code>class Hdf5Dataset(SKDataset):\n    \"\"\"Subject feature sets saved in HDF5 format.\"\"\"\n\n    def __init__(\n        self,\n        ds_path: Path,\n        frame_size: int = 128,\n        feat_key: str = \"features\",\n        label_key: str = \"labels\",\n        mask_key: str | None = None,\n        feat_cols: list[int] | None = None,\n        mask_threshold: float = 0.90,\n        **kwargs,\n    ) -&gt; None:\n        super().__init__(ds_path, frame_size)\n        self.ds_path = ds_path\n        self.frame_size = frame_size\n        self.feat_key = feat_key\n        self.label_key = label_key\n        self.mask_key = mask_key\n        self.feat_cols = feat_cols\n        self.mask_threshold = mask_threshold\n\n    @property\n    def subject_ids(self) -&gt; list[str]:\n        \"\"\"Get dataset subject IDs\n\n        Returns:\n            list[str]: Subject IDs\n        \"\"\"\n        subj_paths = glob.glob(str(self.ds_path / \"*.h5\"), recursive=True)\n        subjs = [os.path.splitext(os.path.basename(p))[0] for p in subj_paths]\n        subjs.sort()\n        return subjs\n\n    @property\n    def train_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get train subject ids.\n\n        Returns:\n            list[str]: Train subject ids\n        \"\"\"\n        return self.subject_ids[: int(0.8 * len(self.subject_ids))]\n\n    @property\n    def test_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get test subject ids.\n\n        Returns:\n            list[str]: Test subject ids\n\n        \"\"\"\n        return self.subject_ids[int(0.8 * len(self.subject_ids)) :]\n\n    @functools.cached_property\n    def feature_shape(self) -&gt; tuple[int, ...]:\n        \"\"\"Get feature shape.\n\n        Returns:\n            tuple[int, ...]: Feature shape\n        \"\"\"\n        with h5py.File(os.path.join(self.ds_path, f\"{self.subject_ids[0]}.h5\"), mode=\"r\") as h5:\n            feat_shape = (self.frame_size, h5[self.feat_key].shape[-1])\n        if self.feat_cols:\n            feat_shape = (feat_shape[0], len(self.feat_cols))\n        return feat_shape\n\n    @functools.lru_cache(maxsize=2000)\n    def subject_stats(self, subject_id: str) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray, npt.NDArray]:\n        \"\"\"Get subject feature stats.\n\n        Args:\n            subject_id (str): Subject ID\n\n        Returns:\n            tuple[npt.NDArray, npt.NDArray, npt.NDArray, npt.NDArray]: Tuple of feature mean and std\n        \"\"\"\n        with h5py.File(os.path.join(self.ds_path, f\"{subject_id}.h5\"), mode=\"r\") as h5:\n            features = h5[self.feat_key][:]\n            if self.mask_key:\n                mask = h5[self.mask_key][:]\n                features = features[mask == 1, :]\n        feats_mu = np.nanmean(features, axis=0)\n        feats_var = np.nanvar(features, axis=0)\n        feats_med = np.nanmedian(features, axis=0)\n        feats_iqr = np.nanpercentile(features, 75, axis=0) - np.nanpercentile(features, 25, axis=0)\n        return feats_mu, feats_var, feats_med, feats_iqr\n\n    def uniform_subject_generator(\n        self,\n        subject_ids: list[str] | None = None,\n        repeat: bool = True,\n        shuffle: bool = True,\n    ) -&gt; SubjectGenerator:\n        \"\"\"Yield data for each subject in the array.\n\n        Args:\n            subject_ids (pt.ArrayLike): Array of subject ids\n            repeat (bool, optional): Whether to repeat generator. Defaults to True.\n            shuffle (bool, optional): Whether to shuffle subject ids.. Defaults to True.\n\n        Returns:\n            SubjectGenerator: Subject generator\n\n        Yields:\n            Iterator[SubjectGenerator]\n        \"\"\"\n        if subject_ids is None:\n            subject_ids = self.subject_ids\n        subject_idxs = list(range(len(subject_ids)))\n        while True:\n            if shuffle:\n                random.shuffle(subject_idxs)\n            for subject_idx in subject_idxs:\n                subject_id = subject_ids[subject_idx]\n                subject_id = subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n                with h5py.File(os.path.join(self.ds_path, f\"{subject_id}.h5\"), mode=\"r\") as h5:\n                    yield subject_id, h5\n            # END FOR\n            if not repeat:\n                break\n        # END WHILE\n\n    def _preprocess_data(\n        self,\n        subject_id: str,\n        x: npt.NDArray,\n        y: npt.NDArray,\n        mask: npt.NDArray | None = None,\n        normalize: bool = False,\n        epsilon: float = 1e-3,\n    ) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]:\n        if self.feat_cols:\n            x = x[:, self.feat_cols]\n\n        mask_x = x[mask == 1] if mask is not None else x\n\n        # Impute missing values with median\n        if mask is not None:\n            x_med = np.nanmedian(mask_x, axis=0)\n            x[mask == 0, :] = x_med\n\n        if normalize:\n            # x = self.normalize_signals(x)\n            x_mu = np.nanmean(mask_x, axis=0)\n            x_var = np.nanvar(mask_x, axis=0)\n            # x_med = np.nanmedian(mask_x, axis=0)\n            # x_iqr = np.nanpercentile(mask_x, 75, axis=0) - np.nanpercentile(mask_x, 25, axis=0)\n            x = (x - x_mu) / np.sqrt(x_var + epsilon)\n            # x = (x - x_med) / (x_iqr + epsilon)\n        # END IF\n\n        return x, y, mask\n\n    def load_subject_data(\n        self, subject_id: str, normalize: bool = True, epsilon: float = 1e-3\n    ) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]:\n        \"\"\"Load subject data\n        Args:\n            subject_id (str): Subject ID\n        Returns:\n            tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]: Tuple of features, labels, and mask\n        \"\"\"\n        mask = None\n        with h5py.File(os.path.join(self.ds_path, f\"{subject_id}.h5\"), mode=\"r\") as h5:\n            x = h5[self.feat_key][:]\n            y = h5[self.label_key][:]\n            if self.mask_key:\n                mask = h5[self.mask_key][:]\n\n        return self._preprocess_data(subject_id, x, y, mask, normalize, epsilon)\n\n    def signal_generator(\n        self, subject_generator, samples_per_subject: int = 1, normalize: bool = True, epsilon: float = 1e-3\n    ) -&gt; SampleGenerator:\n        \"\"\"Generate frames using subject generator from the segments in subject data by\n        placing a frame in a random location within one of the segments.\n\n        Args:\n            subject_generator (SubjectGenerator): Generator that yields a tuple of subject id and subject data.\n                    subject data may contain only signals, since labels are not used.\n            samples_per_subject (int): Samples per subject.\n        Yields:\n            Iterator[SampleGenerator]: Iterator of frames and labels.\n\n        Returns:\n            SampleGenerator: Generator of frames and labels.\n        \"\"\"\n        in_mem = True\n        for subject_id, subject_data in subject_generator:\n            xx = subject_data[self.feat_key][:] if in_mem else subject_data[self.feat_key]\n            yy = subject_data[self.label_key][:] if in_mem else subject_data[self.label_key]\n            mm: npt.NDArray = subject_data[self.mask_key][:] if self.mask_key else None\n            xx, yy, mm = self._preprocess_data(subject_id, xx, yy, mm, normalize, epsilon)\n\n            num_samples = 0\n            num_attempts = 0\n            while num_samples &lt; samples_per_subject:\n                frame_start = np.random.randint(xx.shape[0] - self.frame_size)\n                frame_end = frame_start + self.frame_size\n                x = xx[frame_start:frame_end]\n                y = yy[frame_start:frame_end]\n\n                is_invalid = np.isnan(x).any() or (np.mean(mm[frame_start:frame_end]) &lt; self.mask_threshold)\n                if is_invalid:\n                    num_attempts += 1\n                    if num_attempts &gt; 10:\n                        num_samples += 1\n                        num_attempts = 0\n                else:\n                    num_samples += 1\n                    num_attempts = 0\n                    yield x, y\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.feature_shape","title":"<code>feature_shape: tuple[int, ...]</code>  <code>cached</code> <code>property</code>","text":"<p>Get feature shape.</p> <p>Returns:</p> <ul> <li> <code>tuple[int, ...]</code>         \u2013          <p>tuple[int, ...]: Feature shape</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.subject_ids","title":"<code>subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get dataset subject IDs</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Subject IDs</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.test_subject_ids","title":"<code>test_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get test subject ids.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Test subject ids</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.train_subject_ids","title":"<code>train_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get train subject ids.</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Train subject ids</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.load_subject_data","title":"<code>load_subject_data(subject_id, normalize=True, epsilon=0.001)</code>","text":"<p>Load subject data Args:     subject_id (str): Subject ID Returns:     tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]: Tuple of features, labels, and mask</p> Source code in <code>sleepkit/datasets/hdf5.py</code> <pre><code>def load_subject_data(\n    self, subject_id: str, normalize: bool = True, epsilon: float = 1e-3\n) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]:\n    \"\"\"Load subject data\n    Args:\n        subject_id (str): Subject ID\n    Returns:\n        tuple[npt.NDArray, npt.NDArray, npt.NDArray | None]: Tuple of features, labels, and mask\n    \"\"\"\n    mask = None\n    with h5py.File(os.path.join(self.ds_path, f\"{subject_id}.h5\"), mode=\"r\") as h5:\n        x = h5[self.feat_key][:]\n        y = h5[self.label_key][:]\n        if self.mask_key:\n            mask = h5[self.mask_key][:]\n\n    return self._preprocess_data(subject_id, x, y, mask, normalize, epsilon)\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.signal_generator","title":"<code>signal_generator(subject_generator, samples_per_subject=1, normalize=True, epsilon=0.001)</code>","text":"<p>Generate frames using subject generator from the segments in subject data by placing a frame in a random location within one of the segments.</p> <p>Parameters:</p> <ul> <li> <code>subject_generator</code>             (<code>SubjectGenerator</code>)         \u2013          <p>Generator that yields a tuple of subject id and subject data.     subject data may contain only signals, since labels are not used.</p> </li> <li> <code>samples_per_subject</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Samples per subject.</p> </li> </ul> <p>Yields:     Iterator[SampleGenerator]: Iterator of frames and labels.</p> <p>Returns:</p> <ul> <li> <code>SampleGenerator</code> (            <code>SampleGenerator</code> )        \u2013          <p>Generator of frames and labels.</p> </li> </ul> Source code in <code>sleepkit/datasets/hdf5.py</code> <pre><code>def signal_generator(\n    self, subject_generator, samples_per_subject: int = 1, normalize: bool = True, epsilon: float = 1e-3\n) -&gt; SampleGenerator:\n    \"\"\"Generate frames using subject generator from the segments in subject data by\n    placing a frame in a random location within one of the segments.\n\n    Args:\n        subject_generator (SubjectGenerator): Generator that yields a tuple of subject id and subject data.\n                subject data may contain only signals, since labels are not used.\n        samples_per_subject (int): Samples per subject.\n    Yields:\n        Iterator[SampleGenerator]: Iterator of frames and labels.\n\n    Returns:\n        SampleGenerator: Generator of frames and labels.\n    \"\"\"\n    in_mem = True\n    for subject_id, subject_data in subject_generator:\n        xx = subject_data[self.feat_key][:] if in_mem else subject_data[self.feat_key]\n        yy = subject_data[self.label_key][:] if in_mem else subject_data[self.label_key]\n        mm: npt.NDArray = subject_data[self.mask_key][:] if self.mask_key else None\n        xx, yy, mm = self._preprocess_data(subject_id, xx, yy, mm, normalize, epsilon)\n\n        num_samples = 0\n        num_attempts = 0\n        while num_samples &lt; samples_per_subject:\n            frame_start = np.random.randint(xx.shape[0] - self.frame_size)\n            frame_end = frame_start + self.frame_size\n            x = xx[frame_start:frame_end]\n            y = yy[frame_start:frame_end]\n\n            is_invalid = np.isnan(x).any() or (np.mean(mm[frame_start:frame_end]) &lt; self.mask_threshold)\n            if is_invalid:\n                num_attempts += 1\n                if num_attempts &gt; 10:\n                    num_samples += 1\n                    num_attempts = 0\n            else:\n                num_samples += 1\n                num_attempts = 0\n                yield x, y\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.subject_stats","title":"<code>subject_stats(subject_id)</code>  <code>cached</code>","text":"<p>Get subject feature stats.</p> <p>Parameters:</p> <ul> <li> <code>subject_id</code>             (<code>str</code>)         \u2013          <p>Subject ID</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[NDArray, NDArray, NDArray, NDArray]</code>         \u2013          <p>tuple[npt.NDArray, npt.NDArray, npt.NDArray, npt.NDArray]: Tuple of feature mean and std</p> </li> </ul> Source code in <code>sleepkit/datasets/hdf5.py</code> <pre><code>@functools.lru_cache(maxsize=2000)\ndef subject_stats(self, subject_id: str) -&gt; tuple[npt.NDArray, npt.NDArray, npt.NDArray, npt.NDArray]:\n    \"\"\"Get subject feature stats.\n\n    Args:\n        subject_id (str): Subject ID\n\n    Returns:\n        tuple[npt.NDArray, npt.NDArray, npt.NDArray, npt.NDArray]: Tuple of feature mean and std\n    \"\"\"\n    with h5py.File(os.path.join(self.ds_path, f\"{subject_id}.h5\"), mode=\"r\") as h5:\n        features = h5[self.feat_key][:]\n        if self.mask_key:\n            mask = h5[self.mask_key][:]\n            features = features[mask == 1, :]\n    feats_mu = np.nanmean(features, axis=0)\n    feats_var = np.nanvar(features, axis=0)\n    feats_med = np.nanmedian(features, axis=0)\n    feats_iqr = np.nanpercentile(features, 75, axis=0) - np.nanpercentile(features, 25, axis=0)\n    return feats_mu, feats_var, feats_med, feats_iqr\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.hdf5.Hdf5Dataset.uniform_subject_generator","title":"<code>uniform_subject_generator(subject_ids=None, repeat=True, shuffle=True)</code>","text":"<p>Yield data for each subject in the array.</p> <p>Parameters:</p> <ul> <li> <code>subject_ids</code>             (<code>ArrayLike</code>, default:                 <code>None</code> )         \u2013          <p>Array of subject ids</p> </li> <li> <code>repeat</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to repeat generator. Defaults to True.</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to shuffle subject ids.. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SubjectGenerator</code> (            <code>SubjectGenerator</code> )        \u2013          <p>Subject generator</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>SubjectGenerator</code>         \u2013          <p>Iterator[SubjectGenerator]</p> </li> </ul> Source code in <code>sleepkit/datasets/hdf5.py</code> <pre><code>def uniform_subject_generator(\n    self,\n    subject_ids: list[str] | None = None,\n    repeat: bool = True,\n    shuffle: bool = True,\n) -&gt; SubjectGenerator:\n    \"\"\"Yield data for each subject in the array.\n\n    Args:\n        subject_ids (pt.ArrayLike): Array of subject ids\n        repeat (bool, optional): Whether to repeat generator. Defaults to True.\n        shuffle (bool, optional): Whether to shuffle subject ids.. Defaults to True.\n\n    Returns:\n        SubjectGenerator: Subject generator\n\n    Yields:\n        Iterator[SubjectGenerator]\n    \"\"\"\n    if subject_ids is None:\n        subject_ids = self.subject_ids\n    subject_idxs = list(range(len(subject_ids)))\n    while True:\n        if shuffle:\n            random.shuffle(subject_idxs)\n        for subject_idx in subject_idxs:\n            subject_id = subject_ids[subject_idx]\n            subject_id = subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n            with h5py.File(os.path.join(self.ds_path, f\"{subject_id}.h5\"), mode=\"r\") as h5:\n                yield subject_id, h5\n        # END FOR\n        if not repeat:\n            break\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa","title":"<code>sleepkit.datasets.mesa</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset","title":"<code>MesaDataset</code>","text":"<p>MESA dataset</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>class MesaDataset:\n    \"\"\"MESA dataset\"\"\"\n\n    def __init__(\n        self,\n        ds_path: Path,\n        frame_size: int = 30 * 128,\n        target_rate: int = 128,\n        is_commercial: bool = True,\n    ) -&gt; None:\n        self.frame_size = frame_size\n        self.target_rate = target_rate\n        self.ds_path = ds_path / (\"mesa-commercial-use\" if is_commercial else \"mesa\")\n        self.sleep_mapping = lambda v: {0: 0, 1: 1, 2: 2, 3: 3, 4: 3, 5: 5, 6: 0, 9: 0}.get(v, 0)\n        self.is_commercial = is_commercial\n\n    @property\n    def subject_ids(self) -&gt; list[str]:\n        \"\"\"Get dataset subject IDs\n\n        Returns:\n            list[str]: Subject IDs\n        \"\"\"\n        subj_paths = glob.glob(str(self.ds_path / \"polysomnography\" / \"edfs\" / \"*.edf\"))\n        # /polysomnography/edfs/mesa-sleep-NNNN.edf -&gt; NNNN\n        subjs = [os.path.splitext(os.path.basename(p))[0].split(\"-\")[-1] for p in subj_paths]\n        subjs.sort()\n        return subjs\n\n    @property\n    def train_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get train subject ids\"\"\"\n        return self.subject_ids[: int(0.8 * len(self.subject_ids))]\n\n    @property\n    def test_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get test subject ids\"\"\"\n        return self.subject_ids[int(0.8 * len(self.subject_ids)) :]\n\n    @property\n    def actigraphy_signal_names(self) -&gt; list[str]:\n        \"\"\"Actigraphy signal names\"\"\"\n        return [\"activity\", \"linetime\", \"whitelight\", \"offwrist\", \"wake\"]\n\n    @property\n    def psg_signal_names(self) -&gt; list[str]:\n        \"\"\"PSG signal names\"\"\"\n        return [\n            \"EKG\",\n            \"EOG-L\",\n            \"EOG-R\",\n            \"EMG\",\n            \"EEG1\",\n            \"EEG2\",\n            \"EEG3\",\n            \"Pres\",\n            \"Flow\",\n            \"Snore\",\n            \"Thor\",\n            \"Abdo\",\n            \"Leg\",\n            \"Aux_AC\",\n            \"Therm\",\n            \"Pos\",\n            \"Pleth\",\n            \"OxStatus\",\n            \"SpO2\",\n            \"HR\",\n            \"DHR\",\n        ]\n\n    @property\n    def signal_names(self) -&gt; list[str]:\n        \"\"\"Signal names as they appear in the EDF files\"\"\"\n        return self.actigraphy_signal_names + self.psg_signal_names\n\n    def set_sleep_mapping(self, mapping: Callable[[int], int]):\n        \"\"\"Set sleep mapping\"\"\"\n        self.sleep_mapping = mapping\n\n    def uniform_subject_generator(\n        self,\n        subject_ids: list[str] | None = None,\n        repeat: bool = True,\n        shuffle: bool = True,\n    ) -&gt; SubjectGenerator:\n        \"\"\"Yield Subject IDs uniformly.\n\n        Args:\n            subject_ids (list[str], optional): Array of subject ids. Defaults to None.\n            repeat (bool, optional): Whether to repeat generator. Defaults to True.\n            shuffle (bool, optional): Whether to shuffle subject ids. Defaults to True.\n\n        Returns:\n            SubjectGenerator: Subject generator\n        \"\"\"\n        if subject_ids is None:\n            subject_ids = self.subject_ids\n        subject_idxs = list(range(len(subject_ids)))\n        while True:\n            if shuffle:\n                random.shuffle(subject_idxs)\n            for subject_idx in subject_idxs:\n                subject_id = subject_ids[subject_idx]\n                yield subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n            # END FOR\n            if not repeat:\n                break\n        # END WHILE\n\n    def signal_generator(\n        self, subject_generator: SubjectGenerator, signals: list[str], samples_per_subject: int = 1\n    ) -&gt; SampleGenerator:\n        \"\"\"Randomly generate frames of sleep data for given subjects.\n        Args:\n            subject_generator (SubjectGenerator): Generator that yields subject ids.\n            samples_per_subject (int): Samples per subject.\n        Returns:\n            SampleGenerator: Generator of input data of shape (frame_size, num_signals)\n        \"\"\"\n        subjs_sleep_stages = dict()\n        # subjs_apnea_events = dict()\n        for subject_id in subject_generator:\n            max_size = int(self.target_rate * self.get_subject_duration(subject_id))\n            if subject_id in subjs_sleep_stages:\n                sleep_stages = subjs_sleep_stages[subject_id]\n            else:\n                sleep_stages = self.extract_sleep_stages(subject_id=subject_id)\n                subjs_sleep_stages[subject_id] = sleep_stages\n            # END IF\n            sleep_mask = self.sleep_stages_to_mask(sleep_stages, max_size)\n            # if subject_id in subjs_apnea_events:\n            #     apnea_events = subjs_apnea_events[subject_id]\n            # else:\n            #     apnea_events = self.extract_sleep_apneas(subject_id=subject_id)\n            #     subjs_apnea_events[subject_id] = apnea_events\n            # # END IF\n            # apnea_mask = self.apnea_events_to_mask(apnea_events, max_size)\n\n            x = np.zeros((self.frame_size, len(signals)), dtype=np.float32)\n            y = np.zeros((self.frame_size,), dtype=np.int32)\n            for _ in range(samples_per_subject):\n                frame_start = random.randint(0, max_size - 2 * self.frame_size)\n                frame_end = frame_start + self.frame_size\n                for i, signal_label in enumerate(signals):\n                    signal_label = signal_label.decode(\"ascii\") if isinstance(signal_label, bytes) else signal_label\n                    signal = self.load_signal_for_subject(\n                        subject_id, signal_label=signal_label, start=frame_start, data_size=self.frame_size\n                    )\n                    signal_len = min(signal.size, x.shape[0])\n                    x[:signal_len, i] = signal[:signal_len]\n                # END FOR\n                y = sleep_mask[frame_start:frame_end]\n                yield x, y\n            # END FOR\n        # END FOR\n\n    def _load_actigraphy_signal_for_subject(\n        self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n    ) -&gt; npt.NDArray[np.float32]:\n        if data_size is None:\n            raise ValueError(\"data_size must be specified for actigraphy signals\")\n\n        overlap_path = str(self.ds_path / \"overlap\" / \"mesa-actigraphy-psg-overlap.csv\")\n        df = pd.read_csv(overlap_path)\n        line = df[df[\"mesaid\"] == int(subject_id)].line.to_numpy()\n        if len(line) != 1:\n            raise ValueError(f\"Invalid line for subject {subject_id}\")\n\n        df = pd.read_csv(self._get_subject_actigraphy_path(subject_id))\n        df = df[df[\"line\"] &gt;= line[0]]\n        l_idx = math.floor(start / self.target_rate / 30.0)\n        r_idx = l_idx + math.ceil(data_size / self.target_rate / 30.0)\n        signal = df[signal_label][l_idx:r_idx].to_numpy()\n        # Upsample signal to target rate\n        signal = np.repeat(signal, 30 * self.target_rate)\n        return signal[:data_size]\n\n    def load_signal_for_subject(\n        self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n    ) -&gt; npt.NDArray[np.float32]:\n        \"\"\"Load signal into memory for subject at target rate (resampling if needed)\n        Args:\n            subject_id (str): Subject ID\n            signal_label (str): Signal label\n            start (int): Start location @ target rate\n            data_size (int): Data length @ target rate\n        Returns:\n            npt.NDArray[np.float32]: Signal\n        \"\"\"\n        if signal_label in self.actigraphy_signal_names:\n            return self._load_actigraphy_signal_for_subject(subject_id, signal_label, start, data_size)\n\n        with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n            signal_labels = fp.getSignalLabels()\n            signal_idx = signal_labels.index(signal_label)\n            sample_rate = fp.samplefrequency(signal_idx)\n            sig_start = round(start * (sample_rate / self.target_rate))\n            sig_len = fp.getNSamples()\n            sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n            signal = fp.readSignal(signal_idx, sig_start, sig_duration, digital=False).astype(np.float32)\n        # END WITH\n        if sample_rate != self.target_rate:\n            signal = pk.signal.resample_signal(signal, sample_rate, self.target_rate)\n        if data_size is None:\n            return signal\n        return signal[:data_size]\n\n    def extract_sleep_apneas(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n        \"\"\"Extract sleep apnea events for subject\n        Args:\n            subject_id (str): Subject ID\n        Returns:\n            list[tuple[int, float, float]]: Apnea events (apnea, start_time, duration)\n        \"\"\"\n\n        def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n            \"\"\"Get first element matching tag name\"\"\"\n            elements = element.getElementsByTagName(tag_name)\n            return elements[0] if elements else None\n\n        def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n            \"\"\"Check if element has child element matching tag name\"\"\"\n            return bool(get_first_element_by_tag_name(element, tag_name))\n\n        def element_has_node_value(element: XmlElement, node_value) -&gt; bool:\n            \"\"\"Check if element has child node with value\"\"\"\n            return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n        def is_apnea_event(event: XmlElement) -&gt; bool:\n            \"\"\"Determine if event is an apnea event\"\"\"\n            event_type = get_first_element_by_tag_name(event, \"EventType\")\n            return all(\n                (\n                    event_type is not None,\n                    element_has_node_value(event_type, \"Respiratory|Respiratory\"),\n                    has_element_by_tag_name(event, \"EventConcept\"),\n                    has_element_by_tag_name(event, \"Duration\"),\n                    has_element_by_tag_name(event, \"Start\"),\n                )\n            )\n\n        xml_path = self._get_subject_xml_path(subject_id=subject_id)\n        doc = xml_parse(xml_path)\n        events = doc.getElementsByTagName(\"ScoredEvent\")\n        events = [event for event in events if is_apnea_event(event)]\n        apneas = []\n        for event in events:\n            event_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n            start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n            duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n            apnea_labels = [\"Hypopnea|Hypopnea\", \"Unsure|Unsure\", \"Obstructive apnea|Obstructive Apnea\"]\n            try:\n                apnea = apnea_labels.index(event_label) + 1\n            except ValueError:\n                continue\n            apneas.append((apnea, start_time, duration))\n        return apneas\n\n    def extract_sleep_stages(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n        \"\"\"Extract sleep stages for subject\n        Args:\n            subject_id (str): Subject ID\n        Returns:\n            list[tuple[int, float, float]]: Sleep stages (stage, start_time, duration)\n        \"\"\"\n\n        def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n            \"\"\"Get first element matching tag name\"\"\"\n            elements = element.getElementsByTagName(tag_name)\n            return elements[0] if elements else None\n\n        def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n            \"\"\"Check if element has child element matching tag name\"\"\"\n            return bool(get_first_element_by_tag_name(element, tag_name))\n\n        def element_has_node_value(element: XmlElement, node_value):\n            \"\"\"Check if element has child node with value\"\"\"\n            return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n        def is_sleep_stage_event(event: XmlElement) -&gt; bool:\n            \"\"\"Check if event is a sleep stage event\"\"\"\n            event_type = get_first_element_by_tag_name(event, \"EventType\")\n            return all(\n                (\n                    event_type is not None,\n                    element_has_node_value(event_type, \"Stages|Stages\"),\n                    has_element_by_tag_name(event, \"EventConcept\"),\n                    has_element_by_tag_name(event, \"Duration\"),\n                    has_element_by_tag_name(event, \"Start\"),\n                )\n            )\n\n        xml_path = self._get_subject_xml_path(subject_id=subject_id)\n        doc = xml_parse(xml_path)\n        events = doc.getElementsByTagName(\"ScoredEvent\")\n        events = [event for event in events if is_sleep_stage_event(event)]\n        sleep_stages: list[tuple[int, float, float]] = []\n        for event in events:\n            stage_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n            start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n            duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n            sleep_stage = self.sleep_mapping(int(stage_label.split(\"|\")[-1]))\n            sleep_stages.append((sleep_stage, start_time, duration))\n        return sleep_stages\n\n    def get_subject_duration(self, subject_id: str) -&gt; float:\n        \"\"\"Get subject duration in seconds\"\"\"\n        with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n            # return int(min(fp.getNSamples()/[fp.samplefrequency(i) for i in range(fp.signals_in_file)]))\n            return fp.getFileDuration()\n\n    def _get_subject_actigraphy_path(self, subject_id: str) -&gt; str:\n        return str(self.ds_path / \"actigraphy\" / f\"mesa-sleep-{subject_id}.csv\")\n\n    def _get_subject_edf_path(self, subject_id: str) -&gt; str:\n        \"\"\"Get subject EDF data path\"\"\"\n        return str(self.ds_path / \"polysomnography\" / \"edfs\" / f\"mesa-sleep-{subject_id}.edf\")\n\n    def _get_subject_xml_path(self, subject_id: str) -&gt; str:\n        \"\"\"Get subject XML NSRR path\"\"\"\n        return str(self.ds_path / \"polysomnography\" / \"annotations-events-nsrr\" / f\"mesa-sleep-{subject_id}-nsrr.xml\")\n\n    def sleep_stages_to_mask(\n        self, sleep_stages: list[tuple[int, float, float]], data_size: int\n    ) -&gt; npt.NDArray[np.int32]:\n        \"\"\"Convert sleep stages to mask array\n        Args:\n            sleep_stages (list[tuple[int, float, float]]): Sleep stages\n            data_size (int): Data size\n        Returns:\n            npt.NDArray[np.int32]: Sleep mask\n        \"\"\"\n        sleep_mask = np.zeros(data_size, dtype=np.int32)\n        for sleep_stage, start_time, duration in sleep_stages:\n            left_idx = int(self.target_rate * start_time)\n            right_idx = left_idx + int(self.target_rate * duration)\n            sleep_mask[left_idx : right_idx + 1] = sleep_stage\n        # END FOR\n        return sleep_mask\n\n    def apnea_events_to_mask(\n        self, apnea_events: list[tuple[int, float, float]], data_size: int\n    ) -&gt; npt.NDArray[np.int32]:\n        \"\"\"Convert apnea events to mask array\n        Args:\n            apnea_events (list[tuple[int, float, float]]): Apnea events\n            data_size (int): Data size\n        Returns:\n            npt.NDArray[np.int32]: Apnea mask\n        \"\"\"\n        apnea_mask = np.zeros(data_size, dtype=np.int32)\n        for apnea_event, start_time, duration in apnea_events:\n            left_idx = int(self.target_rate * start_time)\n            right_idx = left_idx + int(self.target_rate * duration)\n            apnea_mask[left_idx : right_idx + 1] = apnea_event\n        # END FOR\n        return apnea_mask\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.actigraphy_signal_names","title":"<code>actigraphy_signal_names: list[str]</code>  <code>property</code>","text":"<p>Actigraphy signal names</p>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.psg_signal_names","title":"<code>psg_signal_names: list[str]</code>  <code>property</code>","text":"<p>PSG signal names</p>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.signal_names","title":"<code>signal_names: list[str]</code>  <code>property</code>","text":"<p>Signal names as they appear in the EDF files</p>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.subject_ids","title":"<code>subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get dataset subject IDs</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Subject IDs</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.test_subject_ids","title":"<code>test_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get test subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.train_subject_ids","title":"<code>train_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get train subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.apnea_events_to_mask","title":"<code>apnea_events_to_mask(apnea_events, data_size)</code>","text":"<p>Convert apnea events to mask array Args:     apnea_events (list[tuple[int, float, float]]): Apnea events     data_size (int): Data size Returns:     npt.NDArray[np.int32]: Apnea mask</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def apnea_events_to_mask(\n    self, apnea_events: list[tuple[int, float, float]], data_size: int\n) -&gt; npt.NDArray[np.int32]:\n    \"\"\"Convert apnea events to mask array\n    Args:\n        apnea_events (list[tuple[int, float, float]]): Apnea events\n        data_size (int): Data size\n    Returns:\n        npt.NDArray[np.int32]: Apnea mask\n    \"\"\"\n    apnea_mask = np.zeros(data_size, dtype=np.int32)\n    for apnea_event, start_time, duration in apnea_events:\n        left_idx = int(self.target_rate * start_time)\n        right_idx = left_idx + int(self.target_rate * duration)\n        apnea_mask[left_idx : right_idx + 1] = apnea_event\n    # END FOR\n    return apnea_mask\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.extract_sleep_apneas","title":"<code>extract_sleep_apneas(subject_id)</code>","text":"<p>Extract sleep apnea events for subject Args:     subject_id (str): Subject ID Returns:     list[tuple[int, float, float]]: Apnea events (apnea, start_time, duration)</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def extract_sleep_apneas(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n    \"\"\"Extract sleep apnea events for subject\n    Args:\n        subject_id (str): Subject ID\n    Returns:\n        list[tuple[int, float, float]]: Apnea events (apnea, start_time, duration)\n    \"\"\"\n\n    def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n        \"\"\"Get first element matching tag name\"\"\"\n        elements = element.getElementsByTagName(tag_name)\n        return elements[0] if elements else None\n\n    def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n        \"\"\"Check if element has child element matching tag name\"\"\"\n        return bool(get_first_element_by_tag_name(element, tag_name))\n\n    def element_has_node_value(element: XmlElement, node_value) -&gt; bool:\n        \"\"\"Check if element has child node with value\"\"\"\n        return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n    def is_apnea_event(event: XmlElement) -&gt; bool:\n        \"\"\"Determine if event is an apnea event\"\"\"\n        event_type = get_first_element_by_tag_name(event, \"EventType\")\n        return all(\n            (\n                event_type is not None,\n                element_has_node_value(event_type, \"Respiratory|Respiratory\"),\n                has_element_by_tag_name(event, \"EventConcept\"),\n                has_element_by_tag_name(event, \"Duration\"),\n                has_element_by_tag_name(event, \"Start\"),\n            )\n        )\n\n    xml_path = self._get_subject_xml_path(subject_id=subject_id)\n    doc = xml_parse(xml_path)\n    events = doc.getElementsByTagName(\"ScoredEvent\")\n    events = [event for event in events if is_apnea_event(event)]\n    apneas = []\n    for event in events:\n        event_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n        start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n        duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n        apnea_labels = [\"Hypopnea|Hypopnea\", \"Unsure|Unsure\", \"Obstructive apnea|Obstructive Apnea\"]\n        try:\n            apnea = apnea_labels.index(event_label) + 1\n        except ValueError:\n            continue\n        apneas.append((apnea, start_time, duration))\n    return apneas\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.extract_sleep_stages","title":"<code>extract_sleep_stages(subject_id)</code>","text":"<p>Extract sleep stages for subject Args:     subject_id (str): Subject ID Returns:     list[tuple[int, float, float]]: Sleep stages (stage, start_time, duration)</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def extract_sleep_stages(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n    \"\"\"Extract sleep stages for subject\n    Args:\n        subject_id (str): Subject ID\n    Returns:\n        list[tuple[int, float, float]]: Sleep stages (stage, start_time, duration)\n    \"\"\"\n\n    def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n        \"\"\"Get first element matching tag name\"\"\"\n        elements = element.getElementsByTagName(tag_name)\n        return elements[0] if elements else None\n\n    def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n        \"\"\"Check if element has child element matching tag name\"\"\"\n        return bool(get_first_element_by_tag_name(element, tag_name))\n\n    def element_has_node_value(element: XmlElement, node_value):\n        \"\"\"Check if element has child node with value\"\"\"\n        return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n    def is_sleep_stage_event(event: XmlElement) -&gt; bool:\n        \"\"\"Check if event is a sleep stage event\"\"\"\n        event_type = get_first_element_by_tag_name(event, \"EventType\")\n        return all(\n            (\n                event_type is not None,\n                element_has_node_value(event_type, \"Stages|Stages\"),\n                has_element_by_tag_name(event, \"EventConcept\"),\n                has_element_by_tag_name(event, \"Duration\"),\n                has_element_by_tag_name(event, \"Start\"),\n            )\n        )\n\n    xml_path = self._get_subject_xml_path(subject_id=subject_id)\n    doc = xml_parse(xml_path)\n    events = doc.getElementsByTagName(\"ScoredEvent\")\n    events = [event for event in events if is_sleep_stage_event(event)]\n    sleep_stages: list[tuple[int, float, float]] = []\n    for event in events:\n        stage_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n        start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n        duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n        sleep_stage = self.sleep_mapping(int(stage_label.split(\"|\")[-1]))\n        sleep_stages.append((sleep_stage, start_time, duration))\n    return sleep_stages\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.get_subject_duration","title":"<code>get_subject_duration(subject_id)</code>","text":"<p>Get subject duration in seconds</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def get_subject_duration(self, subject_id: str) -&gt; float:\n    \"\"\"Get subject duration in seconds\"\"\"\n    with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n        # return int(min(fp.getNSamples()/[fp.samplefrequency(i) for i in range(fp.signals_in_file)]))\n        return fp.getFileDuration()\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.load_signal_for_subject","title":"<code>load_signal_for_subject(subject_id, signal_label, start=0, data_size=None)</code>","text":"<p>Load signal into memory for subject at target rate (resampling if needed) Args:     subject_id (str): Subject ID     signal_label (str): Signal label     start (int): Start location @ target rate     data_size (int): Data length @ target rate Returns:     npt.NDArray[np.float32]: Signal</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def load_signal_for_subject(\n    self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n) -&gt; npt.NDArray[np.float32]:\n    \"\"\"Load signal into memory for subject at target rate (resampling if needed)\n    Args:\n        subject_id (str): Subject ID\n        signal_label (str): Signal label\n        start (int): Start location @ target rate\n        data_size (int): Data length @ target rate\n    Returns:\n        npt.NDArray[np.float32]: Signal\n    \"\"\"\n    if signal_label in self.actigraphy_signal_names:\n        return self._load_actigraphy_signal_for_subject(subject_id, signal_label, start, data_size)\n\n    with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n        signal_labels = fp.getSignalLabels()\n        signal_idx = signal_labels.index(signal_label)\n        sample_rate = fp.samplefrequency(signal_idx)\n        sig_start = round(start * (sample_rate / self.target_rate))\n        sig_len = fp.getNSamples()\n        sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n        signal = fp.readSignal(signal_idx, sig_start, sig_duration, digital=False).astype(np.float32)\n    # END WITH\n    if sample_rate != self.target_rate:\n        signal = pk.signal.resample_signal(signal, sample_rate, self.target_rate)\n    if data_size is None:\n        return signal\n    return signal[:data_size]\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.set_sleep_mapping","title":"<code>set_sleep_mapping(mapping)</code>","text":"<p>Set sleep mapping</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def set_sleep_mapping(self, mapping: Callable[[int], int]):\n    \"\"\"Set sleep mapping\"\"\"\n    self.sleep_mapping = mapping\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.signal_generator","title":"<code>signal_generator(subject_generator, signals, samples_per_subject=1)</code>","text":"<p>Randomly generate frames of sleep data for given subjects. Args:     subject_generator (SubjectGenerator): Generator that yields subject ids.     samples_per_subject (int): Samples per subject. Returns:     SampleGenerator: Generator of input data of shape (frame_size, num_signals)</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def signal_generator(\n    self, subject_generator: SubjectGenerator, signals: list[str], samples_per_subject: int = 1\n) -&gt; SampleGenerator:\n    \"\"\"Randomly generate frames of sleep data for given subjects.\n    Args:\n        subject_generator (SubjectGenerator): Generator that yields subject ids.\n        samples_per_subject (int): Samples per subject.\n    Returns:\n        SampleGenerator: Generator of input data of shape (frame_size, num_signals)\n    \"\"\"\n    subjs_sleep_stages = dict()\n    # subjs_apnea_events = dict()\n    for subject_id in subject_generator:\n        max_size = int(self.target_rate * self.get_subject_duration(subject_id))\n        if subject_id in subjs_sleep_stages:\n            sleep_stages = subjs_sleep_stages[subject_id]\n        else:\n            sleep_stages = self.extract_sleep_stages(subject_id=subject_id)\n            subjs_sleep_stages[subject_id] = sleep_stages\n        # END IF\n        sleep_mask = self.sleep_stages_to_mask(sleep_stages, max_size)\n        # if subject_id in subjs_apnea_events:\n        #     apnea_events = subjs_apnea_events[subject_id]\n        # else:\n        #     apnea_events = self.extract_sleep_apneas(subject_id=subject_id)\n        #     subjs_apnea_events[subject_id] = apnea_events\n        # # END IF\n        # apnea_mask = self.apnea_events_to_mask(apnea_events, max_size)\n\n        x = np.zeros((self.frame_size, len(signals)), dtype=np.float32)\n        y = np.zeros((self.frame_size,), dtype=np.int32)\n        for _ in range(samples_per_subject):\n            frame_start = random.randint(0, max_size - 2 * self.frame_size)\n            frame_end = frame_start + self.frame_size\n            for i, signal_label in enumerate(signals):\n                signal_label = signal_label.decode(\"ascii\") if isinstance(signal_label, bytes) else signal_label\n                signal = self.load_signal_for_subject(\n                    subject_id, signal_label=signal_label, start=frame_start, data_size=self.frame_size\n                )\n                signal_len = min(signal.size, x.shape[0])\n                x[:signal_len, i] = signal[:signal_len]\n            # END FOR\n            y = sleep_mask[frame_start:frame_end]\n            yield x, y\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.sleep_stages_to_mask","title":"<code>sleep_stages_to_mask(sleep_stages, data_size)</code>","text":"<p>Convert sleep stages to mask array Args:     sleep_stages (list[tuple[int, float, float]]): Sleep stages     data_size (int): Data size Returns:     npt.NDArray[np.int32]: Sleep mask</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def sleep_stages_to_mask(\n    self, sleep_stages: list[tuple[int, float, float]], data_size: int\n) -&gt; npt.NDArray[np.int32]:\n    \"\"\"Convert sleep stages to mask array\n    Args:\n        sleep_stages (list[tuple[int, float, float]]): Sleep stages\n        data_size (int): Data size\n    Returns:\n        npt.NDArray[np.int32]: Sleep mask\n    \"\"\"\n    sleep_mask = np.zeros(data_size, dtype=np.int32)\n    for sleep_stage, start_time, duration in sleep_stages:\n        left_idx = int(self.target_rate * start_time)\n        right_idx = left_idx + int(self.target_rate * duration)\n        sleep_mask[left_idx : right_idx + 1] = sleep_stage\n    # END FOR\n    return sleep_mask\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaDataset.uniform_subject_generator","title":"<code>uniform_subject_generator(subject_ids=None, repeat=True, shuffle=True)</code>","text":"<p>Yield Subject IDs uniformly.</p> <p>Parameters:</p> <ul> <li> <code>subject_ids</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Array of subject ids. Defaults to None.</p> </li> <li> <code>repeat</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to repeat generator. Defaults to True.</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to shuffle subject ids. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SubjectGenerator</code> (            <code>SubjectGenerator</code> )        \u2013          <p>Subject generator</p> </li> </ul> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>def uniform_subject_generator(\n    self,\n    subject_ids: list[str] | None = None,\n    repeat: bool = True,\n    shuffle: bool = True,\n) -&gt; SubjectGenerator:\n    \"\"\"Yield Subject IDs uniformly.\n\n    Args:\n        subject_ids (list[str], optional): Array of subject ids. Defaults to None.\n        repeat (bool, optional): Whether to repeat generator. Defaults to True.\n        shuffle (bool, optional): Whether to shuffle subject ids. Defaults to True.\n\n    Returns:\n        SubjectGenerator: Subject generator\n    \"\"\"\n    if subject_ids is None:\n        subject_ids = self.subject_ids\n    subject_idxs = list(range(len(subject_ids)))\n    while True:\n        if shuffle:\n            random.shuffle(subject_idxs)\n        for subject_idx in subject_idxs:\n            subject_id = subject_ids[subject_idx]\n            yield subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n        # END FOR\n        if not repeat:\n            break\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.mesa.MesaSleepStage","title":"<code>MesaSleepStage</code>","text":"<p>             Bases: <code>IntEnum</code></p> <p>MESA sleep stages</p> Source code in <code>sleepkit/datasets/mesa.py</code> <pre><code>class MesaSleepStage(IntEnum):\n    \"\"\"MESA sleep stages\"\"\"\n\n    WAKE = 0\n    N1 = 1\n    N2 = 2\n    N3 = 3\n    N4 = 4\n    REM = 5\n    MOVEMENT = 6\n    UNSCORED = 9\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages","title":"<code>sleepkit.datasets.stages</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset","title":"<code>StagesDataset</code>","text":"<p>STAGES dataset</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>class StagesDataset:\n    \"\"\"STAGES dataset\"\"\"\n\n    def __init__(\n        self,\n        ds_path: Path,\n        frame_size: int = 30 * 128,\n        target_rate: int = 128,\n        is_commercial: bool = True,\n    ) -&gt; None:\n        self.frame_size = frame_size\n        self.target_rate = target_rate\n        self.ds_path = ds_path / \"stages\"\n        self.sleep_mapping = lambda v: {0: 0, 1: 1, 2: 2, 3: 3, 4: 3, 5: 5, 6: 0, 9: 0}.get(v, 0)\n\n    @property\n    def subject_ids(self) -&gt; list[str]:\n        \"\"\"Get dataset subject IDs\n\n        Returns:\n            list[str]: Subject IDs\n        \"\"\"\n        subj_paths = glob.glob(str(self.ds_path / \"original\" / \"STAGES PSGs\" / \"*.edf\"), recursive=True)\n        # /polysomnography/edfs/mesa-sleep-NNNN.edf -&gt; NNNN\n        subjs = [os.path.splitext(os.path.basename(p))[0].split(\"-\")[-1] for p in subj_paths]\n        subjs.sort()\n        return subjs\n\n    @property\n    def train_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get train subject ids\"\"\"\n        return self.subject_ids[: int(0.8 * len(self.subject_ids))]\n\n    @property\n    def test_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get test subject ids\"\"\"\n        return self.subject_ids[int(0.8 * len(self.subject_ids)) :]\n\n    @property\n    def signal_names(self) -&gt; list[str]:\n        \"\"\"Signal names as they appear in the EDF files\"\"\"\n        return [\n            # Actigraphy\n            \"activity\",\n            \"linetime\",\n            \"whitelight\",\n            \"offwrist\",\n            \"wake\",\n            # PSG\n            \"EKG\",\n            \"EOG-L\",\n            \"EOG-R\",\n            \"EMG\",\n            \"EEG1\",\n            \"EEG2\",\n            \"EEG3\",\n            \"Pres\",\n            \"Flow\",\n            \"Snore\",\n            \"Thor\",\n            \"Abdo\",\n            \"Leg\",\n            \"Aux_AC\",\n            \"Therm\",\n            \"Pos\",\n            \"Pleth\",\n            \"OxStatus\",\n            \"SpO2\",\n            \"HR\",\n            \"DHR\",\n        ]\n\n    def set_sleep_mapping(self, mapping: Callable[[int], int]):\n        \"\"\"Set sleep mapping\"\"\"\n        self.sleep_mapping = mapping\n\n    def uniform_subject_generator(\n        self,\n        subject_ids: list[str] | None = None,\n        repeat: bool = True,\n        shuffle: bool = True,\n    ) -&gt; SubjectGenerator:\n        \"\"\"Yield Subject IDs uniformly.\n\n        Args:\n            subject_ids (list[str], optional): Array of subject ids. Defaults to None.\n            repeat (bool, optional): Whether to repeat generator. Defaults to True.\n            shuffle (bool, optional): Whether to shuffle subject ids. Defaults to True.\n\n        Returns:\n            SubjectGenerator: Subject generator\n        \"\"\"\n        if subject_ids is None:\n            subject_ids = self.subject_ids\n        subject_idxs = list(range(len(subject_ids)))\n        while True:\n            if shuffle:\n                random.shuffle(subject_idxs)\n            for subject_idx in subject_idxs:\n                subject_id = subject_ids[subject_idx]\n                yield subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n            # END FOR\n            if not repeat:\n                break\n        # END WHILE\n\n    def signal_generator(\n        self, subject_generator: SubjectGenerator, signals: list[str], samples_per_subject: int = 1\n    ) -&gt; SampleGenerator:\n        \"\"\"Randomly generate frames of sleep data for given subjects.\n        Args:\n            subject_generator (SubjectGenerator): Generator that yields subject ids.\n            samples_per_subject (int): Samples per subject.\n        Returns:\n            SampleGenerator: Generator of input data of shape (frame_size, num_signals)\n        \"\"\"\n        subjs_sleep_stages = dict()\n        # subjs_apnea_events = dict()\n        for subject_id in subject_generator:\n            max_size = int(self.target_rate * self.get_subject_duration(subject_id))\n            if subject_id in subjs_sleep_stages:\n                sleep_stages = subjs_sleep_stages[subject_id]\n            else:\n                sleep_stages = self.extract_sleep_stages(subject_id=subject_id)\n                subjs_sleep_stages[subject_id] = sleep_stages\n            # END IF\n            sleep_mask = self.sleep_stages_to_mask(sleep_stages, max_size)\n            # if subject_id in subjs_apnea_events:\n            #     apnea_events = subjs_apnea_events[subject_id]\n            # else:\n            #     apnea_events = self.extract_sleep_apneas(subject_id=subject_id)\n            #     subjs_apnea_events[subject_id] = apnea_events\n            # # END IF\n            # apnea_mask = self.apnea_events_to_mask(apnea_events, max_size)\n\n            x = np.zeros((self.frame_size, len(signals)), dtype=np.float32)\n            y = np.zeros((self.frame_size,), dtype=np.int32)\n            for _ in range(samples_per_subject):\n                frame_start = random.randint(0, max_size - 2 * self.frame_size)\n                frame_end = frame_start + self.frame_size\n                for i, signal_label in enumerate(signals):\n                    signal_label = signal_label.decode(\"ascii\") if isinstance(signal_label, bytes) else signal_label\n                    signal = self.load_signal_for_subject(\n                        subject_id, signal_label=signal_label, start=frame_start, data_size=self.frame_size\n                    )\n                    signal_len = min(signal.size, x.shape[0])\n                    x[:signal_len, i] = signal[:signal_len]\n                # END FOR\n                y = sleep_mask[frame_start:frame_end]\n                yield x, y\n            # END FOR\n        # END FOR\n\n    def _load_actigraphy_signal_for_subject(\n        self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n    ) -&gt; npt.NDArray[np.float32]:\n        if data_size is None:\n            raise ValueError(\"data_size must be specified for actigraphy signals\")\n\n        overlap_path = str(self.ds_path / \"overlap\" / \"mesa-actigraphy-psg-overlap.csv\")\n        df = pd.read_csv(overlap_path)\n        line = df[df[\"mesaid\"] == int(subject_id)].line.to_numpy()\n        if len(line) != 1:\n            raise ValueError(f\"Invalid line for subject {subject_id}\")\n\n        df = pd.read_csv(self._get_subject_actigraphy_path(subject_id))\n        df = df[df[\"line\"] &gt;= line[0]]\n        l_idx = math.floor(start / self.target_rate / 30.0)\n        r_idx = l_idx + math.ceil(data_size / self.target_rate / 30.0)\n        signal = df[signal_label][l_idx:r_idx].to_numpy()\n        # Upsample signal to target rate\n        signal = np.repeat(signal, 30 * self.target_rate)\n        return signal[:data_size]\n\n    def load_signal_for_subject(\n        self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n    ) -&gt; npt.NDArray[np.float32]:\n        \"\"\"Load signal into memory for subject at target rate (resampling if needed)\n        Args:\n            subject_id (str): Subject ID\n            signal_label (str): Signal label\n            start (int): Start location @ target rate\n            data_size (int): Data length @ target rate\n        Returns:\n            npt.NDArray[np.float32]: Signal\n        \"\"\"\n        if signal_label in [\"activity\", \"linetime\", \"whitelight\", \"offwrist\", \"wake\"]:\n            return self._load_actigraphy_signal_for_subject(subject_id, signal_label, start, data_size)\n\n        with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n            signal_labels = fp.getSignalLabels()\n            signal_idx = signal_labels.index(signal_label)\n            sample_rate = fp.samplefrequency(signal_idx)\n            sig_start = round(start * (sample_rate / self.target_rate))\n            sig_len = fp.getNSamples()\n            sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n            signal = fp.readSignal(signal_idx, sig_start, sig_duration, digital=False).astype(np.float32)\n        # END WITH\n        if sample_rate != self.target_rate:\n            signal = pk.signal.resample_signal(signal, sample_rate, self.target_rate)\n        if data_size is None:\n            return signal\n        return signal[:data_size]\n\n    def extract_sleep_apneas(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n        \"\"\"Extract sleep apnea events for subject\n        Args:\n            subject_id (str): Subject ID\n        Returns:\n            list[tuple[int, float, float]]: Apnea events (apnea, start_time, duration)\n        \"\"\"\n\n        def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n            \"\"\"Get first element matching tag name\"\"\"\n            elements = element.getElementsByTagName(tag_name)\n            return elements[0] if elements else None\n\n        def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n            \"\"\"Check if element has child element matching tag name\"\"\"\n            return bool(get_first_element_by_tag_name(element, tag_name))\n\n        def element_has_node_value(element: XmlElement, node_value) -&gt; bool:\n            \"\"\"Check if element has child node with value\"\"\"\n            return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n        def is_apnea_event(event: XmlElement) -&gt; bool:\n            \"\"\"Determine if event is an apnea event\"\"\"\n            event_type = get_first_element_by_tag_name(event, \"EventType\")\n            return all(\n                (\n                    event_type is not None,\n                    element_has_node_value(event_type, \"Respiratory|Respiratory\"),\n                    has_element_by_tag_name(event, \"EventConcept\"),\n                    has_element_by_tag_name(event, \"Duration\"),\n                    has_element_by_tag_name(event, \"Start\"),\n                )\n            )\n\n        xml_path = self._get_subject_xml_path(subject_id=subject_id)\n        doc = xml_parse(xml_path)\n        events = doc.getElementsByTagName(\"ScoredEvent\")\n        events = [event for event in events if is_apnea_event(event)]\n        apneas = []\n        for event in events:\n            event_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n            start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n            duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n            apnea_labels = [\"Hypopnea|Hypopnea\", \"Unsure|Unsure\", \"Obstructive apnea|Obstructive Apnea\"]\n            try:\n                apnea = apnea_labels.index(event_label) + 1\n            except ValueError:\n                continue\n            apneas.append((apnea, start_time, duration))\n        return apneas\n\n    def extract_sleep_stages(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n        \"\"\"Extract sleep stages for subject\n        Args:\n            subject_id (str): Subject ID\n        Returns:\n            list[tuple[int, float, float]]: Sleep stages (stage, start_time, duration)\n        \"\"\"\n\n        def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n            \"\"\"Get first element matching tag name\"\"\"\n            elements = element.getElementsByTagName(tag_name)\n            return elements[0] if elements else None\n\n        def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n            \"\"\"Check if element has child element matching tag name\"\"\"\n            return bool(get_first_element_by_tag_name(element, tag_name))\n\n        def element_has_node_value(element: XmlElement, node_value):\n            \"\"\"Check if element has child node with value\"\"\"\n            return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n        def is_sleep_stage_event(event: XmlElement) -&gt; bool:\n            \"\"\"Check if event is a sleep stage event\"\"\"\n            event_type = get_first_element_by_tag_name(event, \"EventType\")\n            return all(\n                (\n                    event_type is not None,\n                    element_has_node_value(event_type, \"Stages|Stages\"),\n                    has_element_by_tag_name(event, \"EventConcept\"),\n                    has_element_by_tag_name(event, \"Duration\"),\n                    has_element_by_tag_name(event, \"Start\"),\n                )\n            )\n\n        xml_path = self._get_subject_xml_path(subject_id=subject_id)\n        doc = xml_parse(xml_path)\n        events = doc.getElementsByTagName(\"ScoredEvent\")\n        events = [event for event in events if is_sleep_stage_event(event)]\n        sleep_stages: list[tuple[int, float, float]] = []\n        for event in events:\n            stage_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n            start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n            duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n            sleep_stage = self.sleep_mapping(int(stage_label.split(\"|\")[-1]))\n            sleep_stages.append((sleep_stage, start_time, duration))\n        return sleep_stages\n\n    def get_subject_duration(self, subject_id: str) -&gt; float:\n        \"\"\"Get subject duration in seconds\"\"\"\n        with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n            # return int(min(fp.getNSamples()/[fp.samplefrequency(i) for i in range(fp.signals_in_file)]))\n            return fp.getFileDuration()\n\n    def _get_subject_actigraphy_path(self, subject_id: str) -&gt; str:\n        return str(self.ds_path / \"actigraphy\" / f\"mesa-sleep-{subject_id}.csv\")\n\n    def _get_subject_edf_path(self, subject_id: str) -&gt; str:\n        \"\"\"Get subject EDF data path\"\"\"\n        return str(self.ds_path / \"polysomnography\" / \"edfs\" / f\"mesa-sleep-{subject_id}.edf\")\n\n    def _get_subject_xml_path(self, subject_id: str) -&gt; str:\n        \"\"\"Get subject XML NSRR path\"\"\"\n        return str(self.ds_path / \"polysomnography\" / \"annotations-events-nsrr\" / f\"mesa-sleep-{subject_id}-nsrr.xml\")\n\n    def sleep_stages_to_mask(\n        self, sleep_stages: list[tuple[int, float, float]], data_size: int\n    ) -&gt; npt.NDArray[np.int32]:\n        \"\"\"Convert sleep stages to mask array\n        Args:\n            sleep_stages (list[tuple[int, float, float]]): Sleep stages\n            data_size (int): Data size\n        Returns:\n            npt.NDArray[np.int32]: Sleep mask\n        \"\"\"\n        sleep_mask = np.zeros(data_size, dtype=np.int32)\n        for sleep_stage, start_time, duration in sleep_stages:\n            left_idx = int(self.target_rate * start_time)\n            right_idx = left_idx + int(self.target_rate * duration)\n            sleep_mask[left_idx : right_idx + 1] = sleep_stage\n        # END FOR\n        return sleep_mask\n\n    def apnea_events_to_mask(\n        self, apnea_events: list[tuple[int, float, float]], data_size: int\n    ) -&gt; npt.NDArray[np.int32]:\n        \"\"\"Convert apnea events to mask array\n        Args:\n            apnea_events (list[tuple[int, float, float]]): Apnea events\n            data_size (int): Data size\n        Returns:\n            npt.NDArray[np.int32]: Apnea mask\n        \"\"\"\n        apnea_mask = np.zeros(data_size, dtype=np.int32)\n        for apnea_event, start_time, duration in apnea_events:\n            left_idx = int(self.target_rate * start_time)\n            right_idx = left_idx + int(self.target_rate * duration)\n            apnea_mask[left_idx : right_idx + 1] = apnea_event\n        # END FOR\n        return apnea_mask\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.signal_names","title":"<code>signal_names: list[str]</code>  <code>property</code>","text":"<p>Signal names as they appear in the EDF files</p>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.subject_ids","title":"<code>subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get dataset subject IDs</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Subject IDs</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.test_subject_ids","title":"<code>test_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get test subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.train_subject_ids","title":"<code>train_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get train subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.apnea_events_to_mask","title":"<code>apnea_events_to_mask(apnea_events, data_size)</code>","text":"<p>Convert apnea events to mask array Args:     apnea_events (list[tuple[int, float, float]]): Apnea events     data_size (int): Data size Returns:     npt.NDArray[np.int32]: Apnea mask</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def apnea_events_to_mask(\n    self, apnea_events: list[tuple[int, float, float]], data_size: int\n) -&gt; npt.NDArray[np.int32]:\n    \"\"\"Convert apnea events to mask array\n    Args:\n        apnea_events (list[tuple[int, float, float]]): Apnea events\n        data_size (int): Data size\n    Returns:\n        npt.NDArray[np.int32]: Apnea mask\n    \"\"\"\n    apnea_mask = np.zeros(data_size, dtype=np.int32)\n    for apnea_event, start_time, duration in apnea_events:\n        left_idx = int(self.target_rate * start_time)\n        right_idx = left_idx + int(self.target_rate * duration)\n        apnea_mask[left_idx : right_idx + 1] = apnea_event\n    # END FOR\n    return apnea_mask\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.extract_sleep_apneas","title":"<code>extract_sleep_apneas(subject_id)</code>","text":"<p>Extract sleep apnea events for subject Args:     subject_id (str): Subject ID Returns:     list[tuple[int, float, float]]: Apnea events (apnea, start_time, duration)</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def extract_sleep_apneas(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n    \"\"\"Extract sleep apnea events for subject\n    Args:\n        subject_id (str): Subject ID\n    Returns:\n        list[tuple[int, float, float]]: Apnea events (apnea, start_time, duration)\n    \"\"\"\n\n    def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n        \"\"\"Get first element matching tag name\"\"\"\n        elements = element.getElementsByTagName(tag_name)\n        return elements[0] if elements else None\n\n    def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n        \"\"\"Check if element has child element matching tag name\"\"\"\n        return bool(get_first_element_by_tag_name(element, tag_name))\n\n    def element_has_node_value(element: XmlElement, node_value) -&gt; bool:\n        \"\"\"Check if element has child node with value\"\"\"\n        return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n    def is_apnea_event(event: XmlElement) -&gt; bool:\n        \"\"\"Determine if event is an apnea event\"\"\"\n        event_type = get_first_element_by_tag_name(event, \"EventType\")\n        return all(\n            (\n                event_type is not None,\n                element_has_node_value(event_type, \"Respiratory|Respiratory\"),\n                has_element_by_tag_name(event, \"EventConcept\"),\n                has_element_by_tag_name(event, \"Duration\"),\n                has_element_by_tag_name(event, \"Start\"),\n            )\n        )\n\n    xml_path = self._get_subject_xml_path(subject_id=subject_id)\n    doc = xml_parse(xml_path)\n    events = doc.getElementsByTagName(\"ScoredEvent\")\n    events = [event for event in events if is_apnea_event(event)]\n    apneas = []\n    for event in events:\n        event_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n        start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n        duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n        apnea_labels = [\"Hypopnea|Hypopnea\", \"Unsure|Unsure\", \"Obstructive apnea|Obstructive Apnea\"]\n        try:\n            apnea = apnea_labels.index(event_label) + 1\n        except ValueError:\n            continue\n        apneas.append((apnea, start_time, duration))\n    return apneas\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.extract_sleep_stages","title":"<code>extract_sleep_stages(subject_id)</code>","text":"<p>Extract sleep stages for subject Args:     subject_id (str): Subject ID Returns:     list[tuple[int, float, float]]: Sleep stages (stage, start_time, duration)</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def extract_sleep_stages(self, subject_id: str) -&gt; list[tuple[int, float, float]]:\n    \"\"\"Extract sleep stages for subject\n    Args:\n        subject_id (str): Subject ID\n    Returns:\n        list[tuple[int, float, float]]: Sleep stages (stage, start_time, duration)\n    \"\"\"\n\n    def get_first_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; XmlNode | None:\n        \"\"\"Get first element matching tag name\"\"\"\n        elements = element.getElementsByTagName(tag_name)\n        return elements[0] if elements else None\n\n    def has_element_by_tag_name(element: XmlElement, tag_name: str) -&gt; bool:\n        \"\"\"Check if element has child element matching tag name\"\"\"\n        return bool(get_first_element_by_tag_name(element, tag_name))\n\n    def element_has_node_value(element: XmlElement, node_value):\n        \"\"\"Check if element has child node with value\"\"\"\n        return any((node for node in element.childNodes if node.nodeValue == node_value))\n\n    def is_sleep_stage_event(event: XmlElement) -&gt; bool:\n        \"\"\"Check if event is a sleep stage event\"\"\"\n        event_type = get_first_element_by_tag_name(event, \"EventType\")\n        return all(\n            (\n                event_type is not None,\n                element_has_node_value(event_type, \"Stages|Stages\"),\n                has_element_by_tag_name(event, \"EventConcept\"),\n                has_element_by_tag_name(event, \"Duration\"),\n                has_element_by_tag_name(event, \"Start\"),\n            )\n        )\n\n    xml_path = self._get_subject_xml_path(subject_id=subject_id)\n    doc = xml_parse(xml_path)\n    events = doc.getElementsByTagName(\"ScoredEvent\")\n    events = [event for event in events if is_sleep_stage_event(event)]\n    sleep_stages: list[tuple[int, float, float]] = []\n    for event in events:\n        stage_label = get_first_element_by_tag_name(event, \"EventConcept\").childNodes[0].nodeValue\n        start_time = float(get_first_element_by_tag_name(event, \"Start\").childNodes[0].nodeValue)\n        duration = float(get_first_element_by_tag_name(event, \"Duration\").childNodes[0].nodeValue)\n        sleep_stage = self.sleep_mapping(int(stage_label.split(\"|\")[-1]))\n        sleep_stages.append((sleep_stage, start_time, duration))\n    return sleep_stages\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.get_subject_duration","title":"<code>get_subject_duration(subject_id)</code>","text":"<p>Get subject duration in seconds</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def get_subject_duration(self, subject_id: str) -&gt; float:\n    \"\"\"Get subject duration in seconds\"\"\"\n    with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n        # return int(min(fp.getNSamples()/[fp.samplefrequency(i) for i in range(fp.signals_in_file)]))\n        return fp.getFileDuration()\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.load_signal_for_subject","title":"<code>load_signal_for_subject(subject_id, signal_label, start=0, data_size=None)</code>","text":"<p>Load signal into memory for subject at target rate (resampling if needed) Args:     subject_id (str): Subject ID     signal_label (str): Signal label     start (int): Start location @ target rate     data_size (int): Data length @ target rate Returns:     npt.NDArray[np.float32]: Signal</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def load_signal_for_subject(\n    self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n) -&gt; npt.NDArray[np.float32]:\n    \"\"\"Load signal into memory for subject at target rate (resampling if needed)\n    Args:\n        subject_id (str): Subject ID\n        signal_label (str): Signal label\n        start (int): Start location @ target rate\n        data_size (int): Data length @ target rate\n    Returns:\n        npt.NDArray[np.float32]: Signal\n    \"\"\"\n    if signal_label in [\"activity\", \"linetime\", \"whitelight\", \"offwrist\", \"wake\"]:\n        return self._load_actigraphy_signal_for_subject(subject_id, signal_label, start, data_size)\n\n    with pyedflib.EdfReader(self._get_subject_edf_path(subject_id)) as fp:\n        signal_labels = fp.getSignalLabels()\n        signal_idx = signal_labels.index(signal_label)\n        sample_rate = fp.samplefrequency(signal_idx)\n        sig_start = round(start * (sample_rate / self.target_rate))\n        sig_len = fp.getNSamples()\n        sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n        signal = fp.readSignal(signal_idx, sig_start, sig_duration, digital=False).astype(np.float32)\n    # END WITH\n    if sample_rate != self.target_rate:\n        signal = pk.signal.resample_signal(signal, sample_rate, self.target_rate)\n    if data_size is None:\n        return signal\n    return signal[:data_size]\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.set_sleep_mapping","title":"<code>set_sleep_mapping(mapping)</code>","text":"<p>Set sleep mapping</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def set_sleep_mapping(self, mapping: Callable[[int], int]):\n    \"\"\"Set sleep mapping\"\"\"\n    self.sleep_mapping = mapping\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.signal_generator","title":"<code>signal_generator(subject_generator, signals, samples_per_subject=1)</code>","text":"<p>Randomly generate frames of sleep data for given subjects. Args:     subject_generator (SubjectGenerator): Generator that yields subject ids.     samples_per_subject (int): Samples per subject. Returns:     SampleGenerator: Generator of input data of shape (frame_size, num_signals)</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def signal_generator(\n    self, subject_generator: SubjectGenerator, signals: list[str], samples_per_subject: int = 1\n) -&gt; SampleGenerator:\n    \"\"\"Randomly generate frames of sleep data for given subjects.\n    Args:\n        subject_generator (SubjectGenerator): Generator that yields subject ids.\n        samples_per_subject (int): Samples per subject.\n    Returns:\n        SampleGenerator: Generator of input data of shape (frame_size, num_signals)\n    \"\"\"\n    subjs_sleep_stages = dict()\n    # subjs_apnea_events = dict()\n    for subject_id in subject_generator:\n        max_size = int(self.target_rate * self.get_subject_duration(subject_id))\n        if subject_id in subjs_sleep_stages:\n            sleep_stages = subjs_sleep_stages[subject_id]\n        else:\n            sleep_stages = self.extract_sleep_stages(subject_id=subject_id)\n            subjs_sleep_stages[subject_id] = sleep_stages\n        # END IF\n        sleep_mask = self.sleep_stages_to_mask(sleep_stages, max_size)\n        # if subject_id in subjs_apnea_events:\n        #     apnea_events = subjs_apnea_events[subject_id]\n        # else:\n        #     apnea_events = self.extract_sleep_apneas(subject_id=subject_id)\n        #     subjs_apnea_events[subject_id] = apnea_events\n        # # END IF\n        # apnea_mask = self.apnea_events_to_mask(apnea_events, max_size)\n\n        x = np.zeros((self.frame_size, len(signals)), dtype=np.float32)\n        y = np.zeros((self.frame_size,), dtype=np.int32)\n        for _ in range(samples_per_subject):\n            frame_start = random.randint(0, max_size - 2 * self.frame_size)\n            frame_end = frame_start + self.frame_size\n            for i, signal_label in enumerate(signals):\n                signal_label = signal_label.decode(\"ascii\") if isinstance(signal_label, bytes) else signal_label\n                signal = self.load_signal_for_subject(\n                    subject_id, signal_label=signal_label, start=frame_start, data_size=self.frame_size\n                )\n                signal_len = min(signal.size, x.shape[0])\n                x[:signal_len, i] = signal[:signal_len]\n            # END FOR\n            y = sleep_mask[frame_start:frame_end]\n            yield x, y\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.sleep_stages_to_mask","title":"<code>sleep_stages_to_mask(sleep_stages, data_size)</code>","text":"<p>Convert sleep stages to mask array Args:     sleep_stages (list[tuple[int, float, float]]): Sleep stages     data_size (int): Data size Returns:     npt.NDArray[np.int32]: Sleep mask</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def sleep_stages_to_mask(\n    self, sleep_stages: list[tuple[int, float, float]], data_size: int\n) -&gt; npt.NDArray[np.int32]:\n    \"\"\"Convert sleep stages to mask array\n    Args:\n        sleep_stages (list[tuple[int, float, float]]): Sleep stages\n        data_size (int): Data size\n    Returns:\n        npt.NDArray[np.int32]: Sleep mask\n    \"\"\"\n    sleep_mask = np.zeros(data_size, dtype=np.int32)\n    for sleep_stage, start_time, duration in sleep_stages:\n        left_idx = int(self.target_rate * start_time)\n        right_idx = left_idx + int(self.target_rate * duration)\n        sleep_mask[left_idx : right_idx + 1] = sleep_stage\n    # END FOR\n    return sleep_mask\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesDataset.uniform_subject_generator","title":"<code>uniform_subject_generator(subject_ids=None, repeat=True, shuffle=True)</code>","text":"<p>Yield Subject IDs uniformly.</p> <p>Parameters:</p> <ul> <li> <code>subject_ids</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Array of subject ids. Defaults to None.</p> </li> <li> <code>repeat</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to repeat generator. Defaults to True.</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to shuffle subject ids. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SubjectGenerator</code> (            <code>SubjectGenerator</code> )        \u2013          <p>Subject generator</p> </li> </ul> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>def uniform_subject_generator(\n    self,\n    subject_ids: list[str] | None = None,\n    repeat: bool = True,\n    shuffle: bool = True,\n) -&gt; SubjectGenerator:\n    \"\"\"Yield Subject IDs uniformly.\n\n    Args:\n        subject_ids (list[str], optional): Array of subject ids. Defaults to None.\n        repeat (bool, optional): Whether to repeat generator. Defaults to True.\n        shuffle (bool, optional): Whether to shuffle subject ids. Defaults to True.\n\n    Returns:\n        SubjectGenerator: Subject generator\n    \"\"\"\n    if subject_ids is None:\n        subject_ids = self.subject_ids\n    subject_idxs = list(range(len(subject_ids)))\n    while True:\n        if shuffle:\n            random.shuffle(subject_idxs)\n        for subject_idx in subject_idxs:\n            subject_id = subject_ids[subject_idx]\n            yield subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n        # END FOR\n        if not repeat:\n            break\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.stages.StagesSleepStage","title":"<code>StagesSleepStage</code>","text":"<p>             Bases: <code>IntEnum</code></p> <p>Sleep stage enum</p> Source code in <code>sleepkit/datasets/stages.py</code> <pre><code>class StagesSleepStage(IntEnum):\n    \"\"\"Sleep stage enum\"\"\"\n\n    WAKE = 0\n    N1 = 1\n    N2 = 2\n    N3 = 3\n    N4 = 4\n    REM = 5\n    MOVEMENT = 6\n    UNSCORED = 9\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.utils","title":"<code>sleepkit.datasets.utils</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.utils.buffered_generator","title":"<code>buffered_generator(generator, buffer_size)</code>","text":"<p>Buffer the elements yielded by a generator. New elements replace the oldest elements in the buffer.</p> <p>Parameters:</p> <ul> <li> <code>generator</code>             (<code>Generator[T]</code>)         \u2013          <p>Generator object.</p> </li> <li> <code>buffer_size</code>             (<code>int</code>)         \u2013          <p>Number of elements in the buffer.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Generator[list[T], None, None]</code>         \u2013          <p>Generator[list[T], None, None]: Yields a buffer.</p> </li> </ul> Source code in <code>sleepkit/datasets/utils.py</code> <pre><code>def buffered_generator(generator: Generator[T, None, None], buffer_size: int) -&gt; Generator[list[T], None, None]:\n    \"\"\"Buffer the elements yielded by a generator. New elements replace the oldest elements in the buffer.\n\n    Args:\n        generator (Generator[T]): Generator object.\n        buffer_size (int): Number of elements in the buffer.\n\n    Returns:\n        Generator[list[T], None, None]: Yields a buffer.\n    \"\"\"\n    buffer = []\n    for e in generator:\n        buffer.append(e)\n        if len(buffer) == buffer_size:\n            break\n    yield buffer\n    for e in generator:\n        buffer = buffer[1:] + [e]\n        yield buffer\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.utils.create_dataset_from_data","title":"<code>create_dataset_from_data(x, y, output_signature)</code>","text":"<p>Helper function to create dataset from static data Args:     x (npt.NDArray): Numpy data     y (npt.NDArray): Numpy labels Returns:     tf.data.Dataset: Dataset</p> Source code in <code>sleepkit/datasets/utils.py</code> <pre><code>def create_dataset_from_data(x: npt.NDArray, y: npt.NDArray, output_signature: tuple[tf.TensorSpec]) -&gt; tf.data.Dataset:\n    \"\"\"Helper function to create dataset from static data\n    Args:\n        x (npt.NDArray): Numpy data\n        y (npt.NDArray): Numpy labels\n    Returns:\n        tf.data.Dataset: Dataset\n    \"\"\"\n    gen = functools.partial(numpy_dataset_generator, x=x, y=y)\n    dataset = tf.data.Dataset.from_generator(generator=gen, output_signature=output_signature)\n    return dataset\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.utils.numpy_dataset_generator","title":"<code>numpy_dataset_generator(x, y)</code>","text":"<p>Create generator from numpy dataset where first axis is samples</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>NDArray</code>)         \u2013          <p>X data</p> </li> <li> <code>y</code>             (<code>NDArray</code>)         \u2013          <p>Y data</p> </li> </ul> <p>Yields:</p> <ul> <li> <code>NDArray</code>         \u2013          <p>Generator[tuple[npt.NDArray, npt.NDArray], None, None]: Samples</p> </li> </ul> Source code in <code>sleepkit/datasets/utils.py</code> <pre><code>def numpy_dataset_generator(x: npt.NDArray, y: npt.NDArray) -&gt; Generator[tuple[npt.NDArray, npt.NDArray], None, None]:\n    \"\"\"Create generator from numpy dataset where first axis is samples\n\n    Args:\n        x (npt.NDArray): X data\n        y (npt.NDArray): Y data\n\n    Yields:\n        Generator[tuple[npt.NDArray, npt.NDArray], None, None]: Samples\n    \"\"\"\n    for i in range(x.shape[0]):\n        yield x[i], y[i]\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw","title":"<code>sleepkit.datasets.ysyw</code>","text":""},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset","title":"<code>YsywDataset</code>","text":"<p>YSYW dataset</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>class YsywDataset:\n    \"\"\"YSYW dataset\"\"\"\n\n    def __init__(\n        self,\n        ds_path: Path,\n        frame_size: int = 30 * 128,\n        target_rate: int = 128,\n    ) -&gt; None:\n        self.frame_size = frame_size\n        self.target_rate = target_rate\n        self.ds_path = ds_path / \"ysyw\"\n        self.sleep_mapping = lambda v: {\n            YsywSleepStage.wake: 0,\n            YsywSleepStage.nonrem1: 1,\n            YsywSleepStage.nonrem2: 2,\n            YsywSleepStage.nonrem3: 3,\n            YsywSleepStage.rem: 5,\n            YsywSleepStage.undefined: 0,\n        }.get(v, 0)\n\n    @property\n    def sampling_rate(self) -&gt; int:\n        \"\"\"Sampling rate in Hz\"\"\"\n        return 200\n\n    @functools.cached_property\n    def subject_ids(self) -&gt; list[str]:\n        \"\"\"Get dataset subject IDs\n\n        Returns:\n            list[str]: Subject IDs\n        \"\"\"\n        pts = glob.glob(os.path.join(self.ds_path, \"*.h5\"))\n        pts = [os.path.splitext(os.path.basename(p))[0] for p in pts]\n        pts.sort()\n        return pts\n\n    @property\n    def train_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get train subject ids\"\"\"\n        return self.subject_ids[: int(0.8 * len(self.subject_ids))]\n\n    @property\n    def test_subject_ids(self) -&gt; list[str]:\n        \"\"\"Get test subject ids\"\"\"\n        return self.subject_ids[int(0.8 * len(self.subject_ids)) :]\n\n    @property\n    def signal_names(self) -&gt; list[str]:\n        \"\"\"Signal names\"\"\"\n        return [\n            # EEG\n            \"F3-M2\",\n            \"F4-M1\",\n            \"C3-M2\",\n            \"C4-M1\",\n            \"O1-M2\",\n            \"O2-M1\",\n            # EOG\n            \"E1-M2\",\n            # EMG\n            \"Chin1-Chin2\",\n            # RSP\n            \"ABD\",\n            \"CHEST\",\n            \"AIRFLOW\",\n            # SPO2\n            \"SaO2\",\n            # ECG\n            \"ECG\",\n        ]\n\n    def set_sleep_mapping(self, mapping: Callable[[int], int]):\n        \"\"\"Set sleep mapping\"\"\"\n        self.sleep_mapping = mapping\n\n    def uniform_subject_generator(\n        self,\n        subject_ids: list[str] | None = None,\n        repeat: bool = True,\n        shuffle: bool = True,\n    ) -&gt; SubjectGenerator:\n        \"\"\"Yield Subject IDs uniformly.\n\n        Args:\n            subject_ids (list[str], optional): Array of subject ids. Defaults to None.\n            repeat (bool, optional): Whether to repeat generator. Defaults to True.\n            shuffle (bool, optional): Whether to shuffle subject ids. Defaults to True.\n\n        Returns:\n            SubjectGenerator: Subject generator\n        \"\"\"\n        if subject_ids is None:\n            subject_ids = self.subject_ids\n        subject_idxs = list(range(len(subject_ids)))\n        while True:\n            if shuffle:\n                random.shuffle(subject_idxs)\n            for subject_idx in subject_idxs:\n                subject_id = subject_ids[subject_idx]\n                yield subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n            # END FOR\n            if not repeat:\n                break\n        # END WHILE\n\n    def signal_generator(\n        self, subject_generator: SubjectGenerator, signals: list[str], samples_per_subject: int = 1\n    ) -&gt; SampleGenerator:\n        \"\"\"Randomly generate frames of sleep data for given subjects.\n        Args:\n            subject_generator (SubjectGenerator): Generator that yields subject ids.\n            samples_per_subject (int): Samples per subject.\n        Returns:\n            SampleGenerator: Generator of input data of shape (frame_size, num_signals)\n        \"\"\"\n        for subject_id in subject_generator:\n            max_size = int(self.target_rate * self.get_subject_duration(subject_id))\n\n            sleep_mask = self.load_sleep_stages_for_subject(subject_id=subject_id)\n\n            x = np.zeros((self.frame_size, len(signals)), dtype=np.float32)\n            y = np.zeros((self.frame_size,), dtype=np.int32)\n            for _ in range(samples_per_subject):\n                frame_start = random.randint(0, max_size - 2 * self.frame_size)\n                frame_end = frame_start + self.frame_size\n                for i, signal_label in enumerate(signals):\n                    signal_label = signal_label.decode(\"ascii\") if isinstance(signal_label, bytes) else signal_label\n                    signal = self.load_signal_for_subject(\n                        subject_id, signal_label=signal_label, start=frame_start, data_size=self.frame_size\n                    )\n                    signal_len = min(signal.size, x.shape[0])\n                    x[:signal_len, i] = signal[:signal_len]\n                # END FOR\n                y = sleep_mask[frame_start:frame_end]\n                yield x, y\n            # END FOR\n        # END FOR\n\n    def load_signal_for_subject(\n        self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n    ) -&gt; npt.NDArray[np.float32]:\n        \"\"\"Load signal into memory for subject at target rate (resampling if needed)\n        Args:\n            subject_id (str): Subject ID\n            signal_label (str): Signal label\n            start (int): Start location @ target rate\n            data_size (int): Data length @ target rate\n        Returns:\n            npt.NDArray[np.float32]: Signal\n        \"\"\"\n        with h5py.File(self._get_subject_h5_path(subject_id), mode=\"r\") as fp:\n            signal_idx = self.signal_names.index(signal_label)\n            sample_rate = self.sampling_rate\n            sig_start = round(start * (sample_rate / self.target_rate))\n            sig_len = fp[\"/data\"].shape[1]  # pylint: disable=no-member\n            sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n            # pylint: disable=no-member\n            signal = fp[\"/data\"][signal_idx, sig_start : sig_start + sig_duration].astype(np.float32)\n        # END WITH\n        if sample_rate != self.target_rate:\n            signal = pk.signal.resample_signal(signal, sample_rate, self.target_rate)\n        if data_size is None:\n            return signal\n        return signal[:data_size]\n\n    def load_sleep_stages_for_subject(\n        self, subject_id: str, start: int = 0, data_size: int | None = None\n    ) -&gt; npt.NDArray[np.int32]:\n        \"\"\"Load sleep stages for subject\n        Args:\n            subject_id (str): Subject ID\n        Returns:\n            npt.NDArray[np.int32]: Sleep stages\n        \"\"\"\n        sample_rate = self.sampling_rate\n        with h5py.File(self._get_subject_h5_path(subject_id), mode=\"r\") as fp:\n            sig_start = round(start * (sample_rate / self.target_rate))\n            sig_len = fp[\"/sleep_stages\"].shape[1]  # pylint: disable=no-member\n            sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n            # pylint: disable=no-member\n            sleep_stages = fp[\"/sleep_stages\"][:, sig_start : sig_start + sig_duration].astype(np.int32)\n        # END WITH\n        sleep_stages = np.argmax(sleep_stages, axis=0)\n        sleep_stages = np.vectorize(self.sleep_mapping)(sleep_stages)\n        if sample_rate != self.target_rate:\n            sleep_stages = pk.signal.filter.resample_categorical(sleep_stages, sample_rate, self.target_rate)\n\n        if data_size is None:\n            return sleep_stages\n\n        return sleep_stages[:data_size]\n\n    def download(self, num_workers: int | None = None, force: bool = False):\n        \"\"\"Download dataset\n\n        Args:\n            num_workers (int | None, optional): # parallel workers. Defaults to None.\n            force (bool, optional): Force redownload. Defaults to False.\n        \"\"\"\n\n        def download_s3_file(\n            s3_file: str,\n            save_path: str,\n            bucket: str,\n            client: boto3.client,\n            force: bool = False,\n        ):\n            if not force and os.path.exists(save_path):\n                return\n            client.download_file(\n                Bucket=bucket,\n                Key=s3_file,\n                Filename=save_path,\n            )\n\n        s3_bucket = \"ambiqai-ysyw-2018-dataset\"\n        s3_prefix = \"training\"\n\n        os.makedirs(self.ds_path, exist_ok=True)\n\n        # Creating only one session and one client\n        session = boto3.Session()\n        client = session.client(\"s3\", config=Config(signature_version=UNSIGNED))\n\n        rst = client.list_objects(Bucket=s3_bucket, Prefix=s3_prefix, MaxKeys=1000)\n        pt_s3_paths = list(filter(lambda obj: obj.endswith(\"h5\"), (obj[\"Key\"] for obj in rst[\"Contents\"])))\n\n        func = functools.partial(download_s3_file, bucket=s3_bucket, client=client, force=force)\n\n        with tqdm(desc=\"Downloading YSYW dataset from S3\", total=len(pt_s3_paths)) as pbar:\n            with ThreadPoolExecutor(max_workers=num_workers) as executor:\n                futures = (\n                    executor.submit(\n                        func,\n                        pt_s3_path,\n                        os.path.join(self.ds_path, os.path.basename(pt_s3_path)),\n                    )\n                    for pt_s3_path in pt_s3_paths\n                )\n                for future in as_completed(futures):\n                    err = future.exception()\n                    if err:\n                        logger.error(f\"Failed on file {err}\")\n                    pbar.update(1)\n                # END FOR\n            # END WITH\n        # END WITH\n\n    def download_raw_dataset(self, src_path: str, num_workers: int | None = None, force: bool = False):\n        \"\"\"Download raw dataset\"\"\"\n        os.makedirs(self.ds_path, exist_ok=True)\n\n        # 1. Download source data\n        # NOTE: Skip for now\n\n        # 2. Extract and convert subject data to H5 files\n        logger.info(\"Generating YSYW subject data\")\n\n        pt_paths = list(filter(os.path.isdir, glob.glob(os.path.join(src_path, \"training\", \"*\"))))\n        # pt_paths += list(filter(os.path.isdir, glob.glob(os.path.join(src_path, \"test\", \"*\"))))\n\n        f = functools.partial(self._convert_pt_to_hdf5, force=force)\n        with Pool(processes=num_workers) as pool:\n            _ = list(tqdm(pool.imap(f, pt_paths), total=len(pt_paths)))\n\n        logger.info(\"Finished YSYW subject data\")\n\n    def get_subject_duration(self, subject_id: str) -&gt; float:\n        \"\"\"Get subject duration in seconds\"\"\"\n        with h5py.File(self._get_subject_h5_path(subject_id), mode=\"r\") as fp:\n            return fp[\"/data\"].shape[1] / self.sampling_rate  # pylint: disable=no-member\n        # END WITH\n\n    def _convert_pt_to_hdf5(self, pt_path: str, force: bool = False):\n        \"\"\"Extract subject data from Physionet.\n\n        Args:\n            pt_path (str): Source path\n            force (bool, optional): Whether to override destination if it exists. Defaults to False.\n        \"\"\"\n        sleep_stage_names = [\"nonrem1\", \"nonrem2\", \"nonrem3\", \"rem\", \"undefined\", \"wake\"]\n        pt_id = os.path.basename(pt_path)\n        pt_src_data_path = os.path.join(pt_path, f\"{pt_id}.mat\")\n        pt_src_ann_path = os.path.join(pt_path, f\"{pt_id}-arousal.mat\")\n        pt_dst_h5_path = os.path.join(self.ds_path, f\"{pt_id}.h5\")\n\n        if os.path.exists(pt_dst_h5_path) and not force:\n            return\n\n        data = scipy.io.loadmat(pt_src_data_path)\n        atr = h5py.File(pt_src_ann_path, mode=\"r\")\n        h5 = h5py.File(pt_dst_h5_path, mode=\"w\")\n\n        sleep_stages = np.vstack([atr[\"data\"][\"sleep_stages\"][stage][:] for stage in sleep_stage_names])\n        arousals: npt.NDArray = atr[\"data\"][\"arousals\"][:]\n        arousals = arousals.squeeze().astype(np.int8)  # pylint: disable=no-member\n        h5.create_dataset(name=\"/data\", data=data[\"val\"], compression=\"gzip\", compression_opts=5)\n        h5.create_dataset(name=\"/arousals\", data=arousals, compression=\"gzip\", compression_opts=5)\n        h5.create_dataset(name=\"/sleep_stages\", data=sleep_stages, compression=\"gzip\", compression_opts=5)\n        h5.close()\n\n    def _get_subject_h5_path(self, subject_id: str) -&gt; Path:\n        \"\"\"Get subject HDF5 data path\"\"\"\n        return self.ds_path / f\"{subject_id}.h5\"\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.sampling_rate","title":"<code>sampling_rate: int</code>  <code>property</code>","text":"<p>Sampling rate in Hz</p>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.signal_names","title":"<code>signal_names: list[str]</code>  <code>property</code>","text":"<p>Signal names</p>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.subject_ids","title":"<code>subject_ids: list[str]</code>  <code>cached</code> <code>property</code>","text":"<p>Get dataset subject IDs</p> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Subject IDs</p> </li> </ul>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.test_subject_ids","title":"<code>test_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get test subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.train_subject_ids","title":"<code>train_subject_ids: list[str]</code>  <code>property</code>","text":"<p>Get train subject ids</p>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.download","title":"<code>download(num_workers=None, force=False)</code>","text":"<p>Download dataset</p> <p>Parameters:</p> <ul> <li> <code>num_workers</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          </li> <li> <code>force</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Force redownload. Defaults to False.</p> </li> </ul> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def download(self, num_workers: int | None = None, force: bool = False):\n    \"\"\"Download dataset\n\n    Args:\n        num_workers (int | None, optional): # parallel workers. Defaults to None.\n        force (bool, optional): Force redownload. Defaults to False.\n    \"\"\"\n\n    def download_s3_file(\n        s3_file: str,\n        save_path: str,\n        bucket: str,\n        client: boto3.client,\n        force: bool = False,\n    ):\n        if not force and os.path.exists(save_path):\n            return\n        client.download_file(\n            Bucket=bucket,\n            Key=s3_file,\n            Filename=save_path,\n        )\n\n    s3_bucket = \"ambiqai-ysyw-2018-dataset\"\n    s3_prefix = \"training\"\n\n    os.makedirs(self.ds_path, exist_ok=True)\n\n    # Creating only one session and one client\n    session = boto3.Session()\n    client = session.client(\"s3\", config=Config(signature_version=UNSIGNED))\n\n    rst = client.list_objects(Bucket=s3_bucket, Prefix=s3_prefix, MaxKeys=1000)\n    pt_s3_paths = list(filter(lambda obj: obj.endswith(\"h5\"), (obj[\"Key\"] for obj in rst[\"Contents\"])))\n\n    func = functools.partial(download_s3_file, bucket=s3_bucket, client=client, force=force)\n\n    with tqdm(desc=\"Downloading YSYW dataset from S3\", total=len(pt_s3_paths)) as pbar:\n        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n            futures = (\n                executor.submit(\n                    func,\n                    pt_s3_path,\n                    os.path.join(self.ds_path, os.path.basename(pt_s3_path)),\n                )\n                for pt_s3_path in pt_s3_paths\n            )\n            for future in as_completed(futures):\n                err = future.exception()\n                if err:\n                    logger.error(f\"Failed on file {err}\")\n                pbar.update(1)\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.download--parallel-workers-defaults-to-none","title":"parallel workers. Defaults to None.","text":""},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.download_raw_dataset","title":"<code>download_raw_dataset(src_path, num_workers=None, force=False)</code>","text":"<p>Download raw dataset</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def download_raw_dataset(self, src_path: str, num_workers: int | None = None, force: bool = False):\n    \"\"\"Download raw dataset\"\"\"\n    os.makedirs(self.ds_path, exist_ok=True)\n\n    # 1. Download source data\n    # NOTE: Skip for now\n\n    # 2. Extract and convert subject data to H5 files\n    logger.info(\"Generating YSYW subject data\")\n\n    pt_paths = list(filter(os.path.isdir, glob.glob(os.path.join(src_path, \"training\", \"*\"))))\n    # pt_paths += list(filter(os.path.isdir, glob.glob(os.path.join(src_path, \"test\", \"*\"))))\n\n    f = functools.partial(self._convert_pt_to_hdf5, force=force)\n    with Pool(processes=num_workers) as pool:\n        _ = list(tqdm(pool.imap(f, pt_paths), total=len(pt_paths)))\n\n    logger.info(\"Finished YSYW subject data\")\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.get_subject_duration","title":"<code>get_subject_duration(subject_id)</code>","text":"<p>Get subject duration in seconds</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def get_subject_duration(self, subject_id: str) -&gt; float:\n    \"\"\"Get subject duration in seconds\"\"\"\n    with h5py.File(self._get_subject_h5_path(subject_id), mode=\"r\") as fp:\n        return fp[\"/data\"].shape[1] / self.sampling_rate  # pylint: disable=no-member\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.load_signal_for_subject","title":"<code>load_signal_for_subject(subject_id, signal_label, start=0, data_size=None)</code>","text":"<p>Load signal into memory for subject at target rate (resampling if needed) Args:     subject_id (str): Subject ID     signal_label (str): Signal label     start (int): Start location @ target rate     data_size (int): Data length @ target rate Returns:     npt.NDArray[np.float32]: Signal</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def load_signal_for_subject(\n    self, subject_id: str, signal_label: str, start: int = 0, data_size: int | None = None\n) -&gt; npt.NDArray[np.float32]:\n    \"\"\"Load signal into memory for subject at target rate (resampling if needed)\n    Args:\n        subject_id (str): Subject ID\n        signal_label (str): Signal label\n        start (int): Start location @ target rate\n        data_size (int): Data length @ target rate\n    Returns:\n        npt.NDArray[np.float32]: Signal\n    \"\"\"\n    with h5py.File(self._get_subject_h5_path(subject_id), mode=\"r\") as fp:\n        signal_idx = self.signal_names.index(signal_label)\n        sample_rate = self.sampling_rate\n        sig_start = round(start * (sample_rate / self.target_rate))\n        sig_len = fp[\"/data\"].shape[1]  # pylint: disable=no-member\n        sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n        # pylint: disable=no-member\n        signal = fp[\"/data\"][signal_idx, sig_start : sig_start + sig_duration].astype(np.float32)\n    # END WITH\n    if sample_rate != self.target_rate:\n        signal = pk.signal.resample_signal(signal, sample_rate, self.target_rate)\n    if data_size is None:\n        return signal\n    return signal[:data_size]\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.load_sleep_stages_for_subject","title":"<code>load_sleep_stages_for_subject(subject_id, start=0, data_size=None)</code>","text":"<p>Load sleep stages for subject Args:     subject_id (str): Subject ID Returns:     npt.NDArray[np.int32]: Sleep stages</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def load_sleep_stages_for_subject(\n    self, subject_id: str, start: int = 0, data_size: int | None = None\n) -&gt; npt.NDArray[np.int32]:\n    \"\"\"Load sleep stages for subject\n    Args:\n        subject_id (str): Subject ID\n    Returns:\n        npt.NDArray[np.int32]: Sleep stages\n    \"\"\"\n    sample_rate = self.sampling_rate\n    with h5py.File(self._get_subject_h5_path(subject_id), mode=\"r\") as fp:\n        sig_start = round(start * (sample_rate / self.target_rate))\n        sig_len = fp[\"/sleep_stages\"].shape[1]  # pylint: disable=no-member\n        sig_duration = sig_len if data_size is None else math.ceil(data_size * (sample_rate / self.target_rate))\n        # pylint: disable=no-member\n        sleep_stages = fp[\"/sleep_stages\"][:, sig_start : sig_start + sig_duration].astype(np.int32)\n    # END WITH\n    sleep_stages = np.argmax(sleep_stages, axis=0)\n    sleep_stages = np.vectorize(self.sleep_mapping)(sleep_stages)\n    if sample_rate != self.target_rate:\n        sleep_stages = pk.signal.filter.resample_categorical(sleep_stages, sample_rate, self.target_rate)\n\n    if data_size is None:\n        return sleep_stages\n\n    return sleep_stages[:data_size]\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.set_sleep_mapping","title":"<code>set_sleep_mapping(mapping)</code>","text":"<p>Set sleep mapping</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def set_sleep_mapping(self, mapping: Callable[[int], int]):\n    \"\"\"Set sleep mapping\"\"\"\n    self.sleep_mapping = mapping\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.signal_generator","title":"<code>signal_generator(subject_generator, signals, samples_per_subject=1)</code>","text":"<p>Randomly generate frames of sleep data for given subjects. Args:     subject_generator (SubjectGenerator): Generator that yields subject ids.     samples_per_subject (int): Samples per subject. Returns:     SampleGenerator: Generator of input data of shape (frame_size, num_signals)</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def signal_generator(\n    self, subject_generator: SubjectGenerator, signals: list[str], samples_per_subject: int = 1\n) -&gt; SampleGenerator:\n    \"\"\"Randomly generate frames of sleep data for given subjects.\n    Args:\n        subject_generator (SubjectGenerator): Generator that yields subject ids.\n        samples_per_subject (int): Samples per subject.\n    Returns:\n        SampleGenerator: Generator of input data of shape (frame_size, num_signals)\n    \"\"\"\n    for subject_id in subject_generator:\n        max_size = int(self.target_rate * self.get_subject_duration(subject_id))\n\n        sleep_mask = self.load_sleep_stages_for_subject(subject_id=subject_id)\n\n        x = np.zeros((self.frame_size, len(signals)), dtype=np.float32)\n        y = np.zeros((self.frame_size,), dtype=np.int32)\n        for _ in range(samples_per_subject):\n            frame_start = random.randint(0, max_size - 2 * self.frame_size)\n            frame_end = frame_start + self.frame_size\n            for i, signal_label in enumerate(signals):\n                signal_label = signal_label.decode(\"ascii\") if isinstance(signal_label, bytes) else signal_label\n                signal = self.load_signal_for_subject(\n                    subject_id, signal_label=signal_label, start=frame_start, data_size=self.frame_size\n                )\n                signal_len = min(signal.size, x.shape[0])\n                x[:signal_len, i] = signal[:signal_len]\n            # END FOR\n            y = sleep_mask[frame_start:frame_end]\n            yield x, y\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywDataset.uniform_subject_generator","title":"<code>uniform_subject_generator(subject_ids=None, repeat=True, shuffle=True)</code>","text":"<p>Yield Subject IDs uniformly.</p> <p>Parameters:</p> <ul> <li> <code>subject_ids</code>             (<code>list[str]</code>, default:                 <code>None</code> )         \u2013          <p>Array of subject ids. Defaults to None.</p> </li> <li> <code>repeat</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to repeat generator. Defaults to True.</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to shuffle subject ids. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SubjectGenerator</code> (            <code>SubjectGenerator</code> )        \u2013          <p>Subject generator</p> </li> </ul> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>def uniform_subject_generator(\n    self,\n    subject_ids: list[str] | None = None,\n    repeat: bool = True,\n    shuffle: bool = True,\n) -&gt; SubjectGenerator:\n    \"\"\"Yield Subject IDs uniformly.\n\n    Args:\n        subject_ids (list[str], optional): Array of subject ids. Defaults to None.\n        repeat (bool, optional): Whether to repeat generator. Defaults to True.\n        shuffle (bool, optional): Whether to shuffle subject ids. Defaults to True.\n\n    Returns:\n        SubjectGenerator: Subject generator\n    \"\"\"\n    if subject_ids is None:\n        subject_ids = self.subject_ids\n    subject_idxs = list(range(len(subject_ids)))\n    while True:\n        if shuffle:\n            random.shuffle(subject_idxs)\n        for subject_idx in subject_idxs:\n            subject_id = subject_ids[subject_idx]\n            yield subject_id.decode(\"ascii\") if isinstance(subject_id, bytes) else subject_id\n        # END FOR\n        if not repeat:\n            break\n</code></pre>"},{"location":"api/datasets/#sleepkit.datasets.ysyw.YsywSleepStage","title":"<code>YsywSleepStage</code>","text":"<p>             Bases: <code>IntEnum</code></p> <p>YSYW sleep stages</p> Source code in <code>sleepkit/datasets/ysyw.py</code> <pre><code>class YsywSleepStage(IntEnum):\n    \"\"\"YSYW sleep stages\"\"\"\n\n    nonrem1 = 0  # N1\n    nonrem2 = 1  # N2\n    nonrem3 = 2  # N3/4\n    rem = 3\n    undefined = 4\n    wake = 5\n</code></pre>"},{"location":"api/models/","title":"Models","text":"<p>A number of custom model architectures are provided in the <code>sleepkit.models</code> module. These models are designed to be used with the <code>sleepkit</code> package, but can be used independently as well.</p>"},{"location":"api/models/#sleepkit.models.mobileone","title":"<code>sleepkit.models.mobileone</code>","text":"<p>MobileOne https://arxiv.org/abs/2206.04040</p>"},{"location":"api/models/#sleepkit.models.mobileone.MobileOneBlockParams","title":"<code>MobileOneBlockParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>MobileOne block parameters</p> Source code in <code>sleepkit/models/mobileone.py</code> <pre><code>class MobileOneBlockParams(BaseModel):\n    \"\"\"MobileOne block parameters\"\"\"\n\n    filters: int = Field(..., description=\"# filters\")\n    depth: int = Field(default=1, description=\"Layer depth\")\n    kernel_size: int | tuple[int, int] = Field(default=3, description=\"Kernel size\")\n    strides: int | tuple[int, int] = Field(default=1, description=\"Stride size\")\n    padding: int | tuple[int, int] = Field(default=0, description=\"Padding size\")\n    se_ratio: float = Field(default=8, description=\"Squeeze Excite ratio\")\n    se_depth: int = Field(default=0, description=\"Depth length to apply SE\")\n    num_conv_branches: int = Field(default=2, description=\"# conv branches\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.mobileone.MobileOneParams","title":"<code>MobileOneParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>MobileOne parameters</p> Source code in <code>sleepkit/models/mobileone.py</code> <pre><code>class MobileOneParams(BaseModel):\n    \"\"\"MobileOne parameters\"\"\"\n\n    blocks: list[MobileOneBlockParams] = Field(default_factory=list, description=\"MobileOne blocks\")\n\n    input_filters: int = Field(default=3, description=\"Input filters\")\n    input_kernel_size: int | tuple[int, int] = Field(default=3, description=\"Input kernel size\")\n    input_strides: int | tuple[int, int] = Field(default=2, description=\"Input stride\")\n    input_padding: int | tuple[int, int] = Field(default=1, description=\"Input padding\")\n\n    # output_filters: int = Field(default=0, description=\"Output filters\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    dropout: float = Field(default=0.2, description=\"Dropout rate\")\n    # drop_connect_rate: float = Field(default=0.2, description=\"Drop connect rate\")\n    model_name: str = Field(default=\"MobileOne\", description=\"Model name\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.mobileone.MobileOne","title":"<code>MobileOne(x, params, num_classes=None, inference_mode=False)</code>","text":"<p>Create MobileOne TF functional model</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor</p> </li> <li> <code>params</code>             (<code>MobileOneParams</code>)         \u2013          <p>Model parameters.</p> </li> <li> <code>num_classes</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/models/mobileone.py</code> <pre><code>def MobileOne(\n    x: tf.Tensor,\n    params: MobileOneParams,\n    num_classes: int | None = None,\n    inference_mode: bool = False,\n) -&gt; keras.Model:\n    \"\"\"Create MobileOne TF functional model\n\n    Args:\n        x (tf.Tensor): Input tensor\n        params (MobileOneParams): Model parameters.\n        num_classes (int, optional): # classes.\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n\n    requires_reshape = len(x.shape) == 3\n    if requires_reshape:\n        y = keras.layers.Reshape((1,) + x.shape[1:])(x)\n    else:\n        y = x\n    # END IF\n\n    y = mobileone_block(\n        output_filters=params.input_filters,\n        kernel_size=params.input_kernel_size,\n        strides=params.input_strides,\n        padding=params.input_padding,\n        groups=1,\n        inference_mode=inference_mode,\n        name=f\"M0.B{0}.D{0}.DW\",\n    )(y)\n\n    for b, block in enumerate(params.blocks):\n        for d in range(block.depth):\n            se_ratio = block.se_ratio if d &gt;= block.depth - block.se_depth else 0\n            # Depthwise block\n            y = mobileone_block(\n                output_filters=y.shape[-1],\n                kernel_size=block.kernel_size,\n                strides=block.strides if d == 0 else (1, 1),\n                padding=block.padding,\n                groups=y.shape[-1],\n                inference_mode=inference_mode,\n                se_ratio=se_ratio,\n                num_conv_branches=block.num_conv_branches,\n                name=f\"M1.B{b+1}.D{d+1}.DW\",\n            )(y)\n\n            # Pointwise block\n            y = mobileone_block(\n                output_filters=block.filters,\n                kernel_size=(1, 1),\n                strides=(1, 1),\n                padding=(0, 0),\n                groups=1,\n                inference_mode=inference_mode,\n                se_ratio=se_ratio,\n                num_conv_branches=block.num_conv_branches,\n                name=f\"M1.B{b+1}.D{d+1}.PW\",\n            )(y)\n        # END FOR\n    # END FOR\n\n    if params.include_top:\n        name = \"top\"\n        y = keras.layers.GlobalAveragePooling2D(name=f\"{name}.pool\")(y)\n        if 0 &lt; params.dropout &lt; 1:\n            y = keras.layers.Dropout(params.dropout)(y)\n        y = keras.layers.Dense(num_classes, name=name)(y)\n\n    model = keras.Model(x, y, name=params.model_name)\n\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.mobileone.MobileOne--classes","title":"classes.","text":""},{"location":"api/models/#sleepkit.models.mobileone.MobileOneU0","title":"<code>MobileOneU0(x, num_classes)</code>","text":"<p>micro-0 MobileOne network</p> Source code in <code>sleepkit/models/mobileone.py</code> <pre><code>def MobileOneU0(x, num_classes):\n    \"\"\"micro-0 MobileOne network\"\"\"\n    return MobileOne(\n        x=x,\n        params=MobileOneParams(\n            input_filters=16,\n            input_kernel_size=(1, 7),\n            input_strides=(1, 2),\n            input_padding=(0, 3),\n            blocks=[\n                MobileOneBlockParams(\n                    filters=32,\n                    depth=2,\n                    kernel_size=(1, 5),\n                    strides=(1, 2),\n                    padding=(0, 2),\n                    se_ratio=0,\n                    se_depth=0,\n                    num_conv_branches=3,\n                ),\n                MobileOneBlockParams(\n                    filters=64,\n                    depth=3,\n                    kernel_size=(1, 3),\n                    strides=(1, 2),\n                    padding=(0, 1),\n                    se_ratio=2,\n                    se_depth=1,\n                    num_conv_branches=3,\n                ),\n                MobileOneBlockParams(\n                    filters=128,\n                    depth=3,\n                    kernel_size=(1, 3),\n                    strides=(1, 2),\n                    padding=(0, 1),\n                    se_ratio=4,\n                    se_depth=1,\n                    num_conv_branches=3,\n                ),\n                MobileOneBlockParams(\n                    filters=256,\n                    depth=2,\n                    kernel_size=(1, 3),\n                    strides=(1, 2),\n                    padding=(0, 1),\n                    se_ratio=4,\n                    se_depth=1,\n                    num_conv_branches=3,\n                ),\n            ],\n        ),\n        num_classes=num_classes,\n        inference_mode=False,\n    )\n</code></pre>"},{"location":"api/models/#sleepkit.models.mobileone.mobileone_block","title":"<code>mobileone_block(output_filters, kernel_size=3, strides=1, padding=0, groups=1, dilation=1, inference_mode=False, se_ratio=0, num_conv_branches=1, name=None)</code>","text":"<p>MBOne block w/ expansion and SE</p> <p>Parameters:</p> <ul> <li> <code>output_filters</code>             (<code>int</code>)         \u2013          <p>Output filter size</p> </li> <li> <code>kernel_size</code>             (<code>int | tuple[int, int]</code>, default:                 <code>3</code> )         \u2013          <p>Kernel size. Defaults to 3.</p> </li> <li> <code>strides</code>             (<code>int | tuple[int, int]</code>, default:                 <code>1</code> )         \u2013          <p>Stride length. Defaults to 1.</p> </li> <li> <code>padding</code>             (<code>int | tuple[int, int]</code>, default:                 <code>0</code> )         \u2013          <p>Padding size. Defaults to 0.</p> </li> <li> <code>groups</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          </li> <li> <code>dilation</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Dilation rate. Defaults to 1.</p> </li> <li> <code>inference_mode</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Inference mode. Defaults to False.</p> </li> <li> <code>se_ratio</code>             (<code>int</code>, default:                 <code>0</code> )         \u2013          <p>Squeeze-Excite ratio. Defaults to 0.</p> </li> <li> <code>num_conv_branches</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          </li> <li> <code>name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Layer name. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>Functional layer</p> </li> </ul> Source code in <code>sleepkit/models/mobileone.py</code> <pre><code>def mobileone_block(\n    output_filters: int,\n    kernel_size: int | tuple[int, int] = 3,\n    strides: int | tuple[int, int] = 1,\n    padding: int | tuple[int, int] = 0,\n    groups: int = 1,\n    dilation: int = 1,\n    inference_mode: bool = False,\n    se_ratio: int = 0,\n    num_conv_branches: int = 1,\n    name: str | None = None,\n) -&gt; KerasLayer:\n    \"\"\"MBOne block w/ expansion and SE\n\n    Args:\n        output_filters (int): Output filter size\n        kernel_size (int | tuple[int, int], optional): Kernel size. Defaults to 3.\n        strides (int | tuple[int, int], optional): Stride length. Defaults to 1.\n        padding (int | tuple[int, int], optional): Padding size. Defaults to 0.\n        groups (int, optional): # groups. Defaults to 1.\n        dilation (int, optional): Dilation rate. Defaults to 1.\n        inference_mode (bool, optional): Inference mode. Defaults to False.\n        se_ratio (int, optional): Squeeze-Excite ratio. Defaults to 0.\n        num_conv_branches (int, optional): # conv branches. Defaults to 1.\n        name (str | None, optional): Layer name. Defaults to None.\n\n    Returns:\n        KerasLayer: Functional layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        input_filters = x.shape[-1]\n        stride_len = strides if isinstance(strides, int) else sum(strides) / len(strides)\n        kernel_len = kernel_size if isinstance(kernel_size, int) else sum(kernel_size) / len(kernel_size)\n        is_downsample = stride_len &gt; 1\n        is_depthwise = groups &gt; 1 and groups == input_filters\n        has_skip_branch = output_filters == input_filters and stride_len == 1\n\n        if inference_mode:\n            y = keras.layers.ZeroPadding2D(padding=padding)(x)\n            y = conv2d(\n                output_filters,\n                kernel_size=kernel_size,\n                strides=strides,\n                padding=\"valid\",\n                dilation=dilation,\n                groups=groups,\n                use_bias=True,\n                name=name,\n            )(y)\n            if se_ratio &gt; 0:\n                name_se = f\"{name}.se\" if name else None\n                y = se_block(ratio=se_ratio, name=name_se)(y)\n            # END IF\n            y = relu6(name=name)(y)\n            return y\n        # END IF\n\n        branches = []\n\n        # Skip branch\n        if has_skip_branch:\n            name_skip = f\"{name}.skip\" if name else None\n            y_skip = batch_norm(name=name_skip)(x)\n            branches.append(y_skip)\n        # END IF\n\n        # Either groups is input_filters or is 1\n\n        # Scale branch\n        if kernel_len &gt; 1:\n            name_scale = f\"{name}.scale\" if name else None\n            if is_depthwise:\n                y_scale = keras.layers.DepthwiseConv2D(\n                    kernel_size=(1, 1),\n                    strides=(1, 1),  # strides,\n                    padding=\"valid\",\n                    use_bias=False,\n                    depthwise_initializer=\"he_normal\",\n                    name=f\"{name_scale}.conv\" if name_scale else None,\n                )(x)\n                y_scale = batch_norm(name=name_scale)(y_scale)\n                if is_downsample:\n                    y_scale = keras.layers.MaxPool2D(pool_size=strides, padding=\"same\")(y_scale)\n            else:\n                y_scale = keras.layers.Conv2D(\n                    output_filters,\n                    kernel_size=(1, 1),\n                    strides=strides,\n                    padding=\"valid\",\n                    groups=groups,\n                    use_bias=False,\n                    kernel_initializer=\"he_normal\",\n                    name=f\"{name_scale}.conv\" if name_scale else None,\n                )(x)\n                y_scale = batch_norm(name=name_scale)(y_scale)\n            branches.append(y_scale)\n        # END IF\n\n        # Other branches\n        yp = keras.layers.ZeroPadding2D(padding=padding)(x)\n        for b in range(num_conv_branches):\n            name_branch = f\"{name}.branch{b+1}\" if name else None\n            if is_depthwise:\n                y_branch = keras.layers.DepthwiseConv2D(\n                    kernel_size=kernel_size,\n                    strides=(1, 1),\n                    padding=\"valid\",\n                    use_bias=False,\n                    depthwise_initializer=\"he_normal\",\n                    name=f\"{name_branch}.conv\" if name else None,\n                )(yp)\n                y_branch = batch_norm(name=name_branch)(y_branch)\n                if is_downsample:\n                    y_branch = keras.layers.MaxPool2D(pool_size=strides, padding=\"same\")(y_branch)\n            else:\n                y_branch = keras.layers.Conv2D(\n                    output_filters,\n                    kernel_size=kernel_size,\n                    strides=strides,\n                    groups=groups,\n                    padding=\"valid\",\n                    use_bias=False,\n                    kernel_initializer=\"he_normal\",\n                    name=f\"{name_branch}.conv\" if name else None,\n                )(yp)\n                y_branch = batch_norm(name=name_branch)(y_branch)\n            branches.append(y_branch)\n        # END FOR\n\n        # Merge branches\n        y = keras.layers.Add(name=f\"{name}.add\" if name else None)(branches)\n\n        # Squeeze-Excite block\n        if se_ratio &gt; 0:\n            name_se = f\"{name}.se\" if name else None\n            y = se_block(ratio=se_ratio, name=name_se)(y)\n        # END IF\n        y = relu6(name=name)(y)\n        return y\n\n    # END DEF\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.mobileone.mobileone_block--groups-defaults-to-1","title":"groups. Defaults to 1.","text":""},{"location":"api/models/#sleepkit.models.mobileone.mobileone_block--conv-branches-defaults-to-1","title":"conv branches. Defaults to 1.","text":""},{"location":"api/models/#sleepkit.models.efficientnet","title":"<code>sleepkit.models.efficientnet</code>","text":"<p>EfficientNet https://arxiv.org/abs/2104.00298</p>"},{"location":"api/models/#sleepkit.models.efficientnet.EfficientNetParams","title":"<code>EfficientNetParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>EfficientNet parameters</p> Source code in <code>sleepkit/models/efficientnet.py</code> <pre><code>class EfficientNetParams(BaseModel):\n    \"\"\"EfficientNet parameters\"\"\"\n\n    blocks: list[MBConvParams] = Field(default_factory=list, description=\"EfficientNet blocks\")\n    input_filters: int = Field(default=0, description=\"Input filters\")\n    input_kernel_size: int | tuple[int, int] = Field(default=3, description=\"Input kernel size\")\n    input_strides: int | tuple[int, int] = Field(default=2, description=\"Input stride\")\n    output_filters: int = Field(default=0, description=\"Output filters\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    dropout: float = Field(default=0.2, description=\"Dropout rate\")\n    drop_connect_rate: float = Field(default=0.2, description=\"Drop connect rate\")\n    model_name: str = Field(default=\"EfficientNetV2\", description=\"Model name\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.efficientnet.EfficientNetV2","title":"<code>EfficientNetV2(x, params, num_classes=None)</code>","text":"<p>Create EfficientNet V2 TF functional model</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor</p> </li> <li> <code>params</code>             (<code>EfficientNetParams</code>)         \u2013          <p>Model parameters.</p> </li> <li> <code>num_classes</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/models/efficientnet.py</code> <pre><code>def EfficientNetV2(\n    x: tf.Tensor,\n    params: EfficientNetParams,\n    num_classes: int | None = None,\n) -&gt; keras.Model:\n    \"\"\"Create EfficientNet V2 TF functional model\n\n    Args:\n        x (tf.Tensor): Input tensor\n        params (EfficientNetParams): Model parameters.\n        num_classes (int, optional): # classes.\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n    # Force input to be 4D (add dummy dimension)\n    requires_reshape = len(x.shape) == 3\n    if requires_reshape:\n        y = keras.layers.Reshape((1,) + x.shape[1:])(x)\n    else:\n        y = x\n\n    # END IF\n    if params.input_filters &gt; 0:\n        name = \"stem\"\n        filters = make_divisible(params.input_filters, 8)\n        y = conv2d(\n            filters,\n            kernel_size=params.input_kernel_size,\n            strides=params.input_strides,\n            name=name,\n        )(x)\n        y = batch_norm(name=name)(y)\n        y = relu6(name=name)(y)\n    else:\n        y = x\n\n    y = efficientnet_core(blocks=params.blocks, drop_connect_rate=params.drop_connect_rate)(y)\n\n    if params.output_filters:\n        name = \"neck\"\n        filters = make_divisible(params.output_filters, 8)\n        y = conv2d(filters, kernel_size=(1, 1), strides=(1, 1), padding=\"same\", name=name)(y)\n        y = batch_norm(name=name)(y)\n        y = relu6(name=name)(y)\n\n    if params.include_top:\n        name = \"top\"\n        y = keras.layers.GlobalAveragePooling2D(name=f\"{name}.pool\")(y)\n        if 0 &lt; params.dropout &lt; 1:\n            y = keras.layers.Dropout(params.dropout)(y)\n        y = keras.layers.Dense(num_classes, name=name)(y)\n    model = keras.Model(x, y, name=params.model_name)\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.efficientnet.EfficientNetV2--classes","title":"classes.","text":""},{"location":"api/models/#sleepkit.models.efficientnet.efficientnet_core","title":"<code>efficientnet_core(blocks, drop_connect_rate=0)</code>","text":"<p>EfficientNet core</p> <p>Parameters:</p> <ul> <li> <code>blocks</code>             (<code>list[MBConvParam]</code>)         \u2013          <p>MBConv params</p> </li> <li> <code>drop_connect_rate</code>             (<code>float</code>, default:                 <code>0</code> )         \u2013          <p>Drop connect rate. Defaults to 0.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>Core</p> </li> </ul> Source code in <code>sleepkit/models/efficientnet.py</code> <pre><code>def efficientnet_core(blocks: list[MBConvParams], drop_connect_rate: float = 0) -&gt; KerasLayer:\n    \"\"\"EfficientNet core\n\n    Args:\n        blocks (list[MBConvParam]): MBConv params\n        drop_connect_rate (float, optional): Drop connect rate. Defaults to 0.\n\n    Returns:\n        KerasLayer: Core\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        global_block_id = 0\n        total_blocks = sum((b.depth for b in blocks))\n        for i, block in enumerate(blocks):\n            filters = make_divisible(block.filters, 8)\n            for d in range(block.depth):\n                name = f\"stage{i+1}.mbconv{d+1}\"\n                block_drop_rate = drop_connect_rate * global_block_id / total_blocks\n                x = mbconv_block(\n                    filters,\n                    block.ex_ratio,\n                    block.kernel_size,\n                    block.strides if d == 0 else 1,\n                    block.se_ratio,\n                    droprate=block_drop_rate,\n                    name=name,\n                )(x)\n                global_block_id += 1\n            # END FOR\n        # END FOR\n        return x\n\n    # END DEF\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.multiresnet","title":"<code>sleepkit.models.multiresnet</code>","text":""},{"location":"api/models/#sleepkit.models.multiresnet.MultiresNetParams","title":"<code>MultiresNetParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Multiresnet parameters</p> Source code in <code>sleepkit/models/multiresnet.py</code> <pre><code>class MultiresNetParams(BaseModel):\n    \"\"\"Multiresnet parameters\"\"\"\n\n    d_model: int = Field(256, description=\"Model depth\")\n    n_layers: int = Field(4, description=\"Number of layers\")\n    dropout: float = Field(default=0.2, description=\"Dropout rate\")\n    kernel_size: int = Field(default=2, description=\"Kernel size\")\n    depth: int | None = Field(default=None, description=\"Depth\")\n    seq_len: int | None = Field(default=None, description=\"Sequence length\")\n    activation_scaling: float = Field(default=2.0, description=\"Activation scaling\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    model_name: str = Field(default=\"MultiresNet\", description=\"Model name\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.multiresnet.MultiresNet","title":"<code>MultiresNet(x, params, num_classes=None)</code>","text":"<p>MultiresNet architecture</p> Source code in <code>sleepkit/models/multiresnet.py</code> <pre><code>def MultiresNet(\n    x: tf.Tensor,\n    params: MultiresNetParams,\n    num_classes: int | None = None,\n):\n    \"\"\"MultiresNet architecture\"\"\"\n    y = x\n    # Apply stem\n    y = keras.layers.Conv1D(params.d_model, kernel_size=1)(y)\n\n    # Apply multiresnet blocks\n    for _ in range(params.n_layers):\n        y_res = y\n        y = multiresnet_block(\n            d_model=params.d_model,\n            kernel_size=params.kernel_size,\n            depth=params.depth,\n            seq_len=params.seq_len,\n            droprate=params.dropout,\n        )(y)\n        # Mix channels\n        y = keras.layers.Conv1D(int(params.activation_scaling * params.d_model), 1)(y)\n        y = glu()(y)\n        y = keras.layers.Dropout(params.dropout)(y)\n        y = keras.layers.Add()([y, y_res])\n        y = batch_norm()(y)\n    # END FOR\n\n    if params.include_top:\n        name = \"top\"\n        y = keras.layers.GlobalAveragePooling1D(name=f\"{name}.pool\")(y)\n        if 0 &lt; params.dropout &lt; 1:\n            y = keras.layers.Dropout(params.dropout)(y)\n        y = keras.layers.Dense(num_classes, name=name)(y)\n    model = keras.Model(x, y, name=params.model_name)\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.multiresnet.multiresnet_block","title":"<code>multiresnet_block(d_model, kernel_size=3, depth=None, wavelet_init=None, tree_select='fading', seq_len=None, droprate=0, memory_size=None, indep_res_init=False, name=None)</code>","text":"<p>Multiresnet block</p> <p>Parameters:</p> <ul> <li> <code>name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Block name. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>Functional layer</p> </li> </ul> Source code in <code>sleepkit/models/multiresnet.py</code> <pre><code>def multiresnet_block(\n    d_model: int,\n    kernel_size: int | tuple[int, int] = 3,\n    depth: int | None = None,\n    wavelet_init=None,\n    tree_select: str = \"fading\",\n    seq_len: int | None = None,\n    droprate: float = 0,\n    memory_size: int | None = None,\n    indep_res_init: bool = False,\n    name: str | None = None,\n) -&gt; KerasLayer:\n    \"\"\"Multiresnet block\n\n    Args:\n        name (str|None, optional): Block name. Defaults to None.\n\n    Returns:\n       KerasLayer: Functional layer\n\n    \"\"\"\n\n    if depth is None and seq_len is None:\n        raise ValueError(\"Either depth or seq_len must be specified\")\n\n    if depth is None:\n        depth = math.ceil(math.log2((seq_len - 1) / (kernel_size - 1) + 1))\n\n    # if tree_select == 'fading':\n    #     m = depth + 1\n    # elif memory_size is not None:\n    #     m = memory_size\n    # else:\n    #     raise ValueError(\"Either tree_select is fading or memory_size must be specified\")\n\n    if wavelet_init is not None:\n        import pywt  # pylint: disable=import-outside-toplevel,import-error  # type: ignore\n\n        wavelet = pywt.Wavelet(wavelet_init)\n        h0 = tf.convert_to_tensor(wavelet.dec_lo[::-1])\n        h1 = tf.convert_to_tensor(wavelet.dec_hi[::-1])\n        h0 = tf.tile(tf.reshape(h0, (1, 1, -1)), [d_model, 1, 1])\n        h1 = tf.tile(tf.reshape(h1, (1, 1, -1)), [d_model, 1, 1])\n    elif kernel_size is not None:\n        h0 = \"glorot_uniform\"\n        h1 = \"glorot_uniform\"\n    else:\n        raise ValueError(\"Either wavelet_init or kernel_size must be specified\")\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        if tree_select == \"fading\":\n            res_lo = x\n            y = keras.layers.DepthwiseConv1D(\n                kernel_size=1,\n            )(x)\n            conv_hi = keras.layers.Conv1D(\n                filters=d_model,\n                kernel_size=kernel_size,\n                kernel_initializer=h1,\n                dilation_rate=1,\n                padding=\"valid\",\n                groups=x.shape[2],\n            )\n            conv_lo = keras.layers.Conv1D(\n                filters=d_model,\n                kernel_size=kernel_size,\n                kernel_initializer=h0,\n                dilation_rate=1,\n                padding=\"valid\",\n                groups=x.shape[2],\n            )\n            dilation = 1\n            for _ in range(depth, 0, -1):\n                padding = dilation * (kernel_size - 1)\n                res_lo_pad = keras.layers.ZeroPadding1D((padding, 0))(res_lo)\n                res_hi = SharedWeightsConv(conv_hi, dilation_rate=dilation)(res_lo_pad)\n                res_lo = SharedWeightsConv(conv_lo, dilation_rate=dilation)(res_lo_pad)\n                res_hi = keras.layers.DepthwiseConv1D(kernel_size=1)(res_hi)\n                y = keras.layers.add([y, res_hi])\n                dilation *= 2\n            # END FOR\n            res_lo = keras.layers.DepthwiseConv1D(\n                kernel_size=1,\n            )(res_lo)\n            y = keras.layers.add([y, res_lo])\n\n        elif tree_select == \"uniform\":\n            raise NotImplementedError(\"tree_select == 'uniform' is not implemented yet\")\n\n        y = keras.layers.Dropout(droprate)(y)\n        y = relu6()(y)\n        return y\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.resnet","title":"<code>sleepkit.models.resnet</code>","text":"<p>ResNet</p>"},{"location":"api/models/#sleepkit.models.resnet.ResNetBlockParams","title":"<code>ResNetBlockParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>ResNet block parameters</p> Source code in <code>sleepkit/models/resnet.py</code> <pre><code>class ResNetBlockParams(BaseModel):\n    \"\"\"ResNet block parameters\"\"\"\n\n    filters: int = Field(..., description=\"# filters\")\n    depth: int = Field(default=1, description=\"Layer depth\")\n    kernel_size: int | tuple[int, int] = Field(default=3, description=\"Kernel size\")\n    strides: int | tuple[int, int] = Field(default=1, description=\"Stride size\")\n    bottleneck: bool = Field(default=False, description=\"Use bottleneck blocks\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.resnet.ResNetParams","title":"<code>ResNetParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>ResNet parameters</p> Source code in <code>sleepkit/models/resnet.py</code> <pre><code>class ResNetParams(BaseModel):\n    \"\"\"ResNet parameters\"\"\"\n\n    blocks: list[ResNetBlockParams] = Field(default_factory=list, description=\"ResNet blocks\")\n    input_filters: int = Field(default=0, description=\"Input filters\")\n    input_kernel_size: int | tuple[int, int] = Field(default=3, description=\"Input kernel size\")\n    input_strides: int | tuple[int, int] = Field(default=2, description=\"Input stride\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    dropout: float = Field(default=0.2, description=\"Dropout rate\")\n    model_name: str = Field(default=\"ResNet\", description=\"Model name\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.resnet.ResNet","title":"<code>ResNet(x, params, num_classes=None)</code>","text":"<p>Generate functional ResNet model. Args:     x (tf.Tensor): Inputs     params (ResNetParams): Model parameters.     num_classes (int, optional): # class outputs. Defaults to None.</p> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/models/resnet.py</code> <pre><code>def ResNet(\n    x: tf.Tensor,\n    params: ResNetParams,\n    num_classes: int | None = None,\n) -&gt; keras.Model:\n    \"\"\"Generate functional ResNet model.\n    Args:\n        x (tf.Tensor): Inputs\n        params (ResNetParams): Model parameters.\n        num_classes (int, optional): # class outputs. Defaults to None.\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n    if params.input_filters:\n        y = conv2d(\n            params.input_filters,\n            kernel_size=params.input_kernel_size,\n            strides=params.input_strides,\n        )(x)\n        y = batch_norm()(y)\n        y = relu6()(y)\n    else:\n        y = x\n\n    for stage, block in enumerate(params.blocks):\n        for d in range(block.depth):\n            func = generate_bottleneck_block if block.bottleneck else generate_residual_block\n            y = func(\n                filters=block.filters,\n                kernel_size=block.kernel_size,\n                strides=block.strides if d == 0 and stage &gt; 0 else 1,\n            )(y)\n        # END FOR\n    # END FOR\n\n    if params.include_top:\n        y = keras.layers.GlobalAveragePooling2D()(y)\n        y = keras.layers.Dense(num_classes)(y)\n\n    model = keras.Model(x, y, name=\"model\")\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.resnet.generate_bottleneck_block","title":"<code>generate_bottleneck_block(filters, kernel_size=3, strides=1, expansion=4)</code>","text":"<p>Generate functional bottleneck block.</p> <p>Parameters:</p> <ul> <li> <code>filters</code>             (<code>int</code>)         \u2013          <p>Filter size</p> </li> <li> <code>kernel_size</code>             (<code>int | tuple[int, int]</code>, default:                 <code>3</code> )         \u2013          <p>Kernel size. Defaults to 3.</p> </li> <li> <code>strides</code>             (<code>int | tuple[int, int]</code>, default:                 <code>1</code> )         \u2013          <p>Stride length. Defaults to 1.</p> </li> <li> <code>expansion</code>             (<code>int</code>, default:                 <code>4</code> )         \u2013          <p>Expansion factor. Defaults to 4.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>TF functional layer</p> </li> </ul> Source code in <code>sleepkit/models/resnet.py</code> <pre><code>def generate_bottleneck_block(\n    filters: int,\n    kernel_size: int | tuple[int, int] = 3,\n    strides: int | tuple[int, int] = 1,\n    expansion: int = 4,\n) -&gt; KerasLayer:\n    \"\"\"Generate functional bottleneck block.\n\n    Args:\n        filters (int): Filter size\n        kernel_size (int | tuple[int, int], optional): Kernel size. Defaults to 3.\n        strides (int | tuple[int, int], optional): Stride length. Defaults to 1.\n        expansion (int, optional): Expansion factor. Defaults to 4.\n\n    Returns:\n        KerasLayer: TF functional layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        num_chan = x.shape[-1]\n        projection = num_chan != filters * expansion or (strides &gt; 1 if isinstance(strides, int) else strides[0] &gt; 1)\n\n        bx = conv2d(filters, 1, 1)(x)\n        bx = batch_norm()(bx)\n        bx = relu6()(bx)\n\n        bx = conv2d(filters, kernel_size, strides)(x)\n        bx = batch_norm()(bx)\n        bx = relu6()(bx)\n\n        bx = conv2d(filters * expansion, 1, 1)(bx)\n        bx = batch_norm()(bx)\n\n        if projection:\n            x = conv2d(filters * expansion, 1, strides)(x)\n            x = batch_norm()(x)\n        x = keras.layers.Add()([bx, x])\n        x = relu6()(x)\n        return x\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.resnet.generate_residual_block","title":"<code>generate_residual_block(filters, kernel_size=3, strides=1)</code>","text":"<p>Generate functional residual block</p> <p>Parameters:</p> <ul> <li> <code>filters</code>             (<code>int</code>)         \u2013          <p>Filter size</p> </li> <li> <code>kernel_size</code>             (<code>int | tuple[int, int]</code>, default:                 <code>3</code> )         \u2013          <p>Kernel size. Defaults to 3.</p> </li> <li> <code>strides</code>             (<code>int | tuple[int, int]</code>, default:                 <code>1</code> )         \u2013          <p>Stride length. Defaults to 1.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>TF functional layer</p> </li> </ul> Source code in <code>sleepkit/models/resnet.py</code> <pre><code>def generate_residual_block(\n    filters: int,\n    kernel_size: int | tuple[int, int] = 3,\n    strides: int | tuple[int, int] = 1,\n) -&gt; KerasLayer:\n    \"\"\"Generate functional residual block\n\n    Args:\n        filters (int): Filter size\n        kernel_size (int | tuple[int, int], optional): Kernel size. Defaults to 3.\n        strides (int | tuple[int, int], optional): Stride length. Defaults to 1.\n\n    Returns:\n        KerasLayer: TF functional layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        num_chan = x.shape[-1]\n        projection = num_chan != filters or (strides &gt; 1 if isinstance(strides, int) else strides[0] &gt; 1)\n        bx = conv2d(filters, kernel_size, strides)(x)\n        bx = batch_norm()(bx)\n        bx = relu6()(bx)\n\n        bx = conv2d(filters, kernel_size, 1)(bx)\n        bx = batch_norm()(bx)\n        if projection:\n            x = conv2d(filters, 1, strides)(x)\n            x = batch_norm()(x)\n        x = keras.layers.Add()([bx, x])\n        x = relu6()(x)\n        return x\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn","title":"<code>sleepkit.models.tcn</code>","text":"<p>TCN</p>"},{"location":"api/models/#sleepkit.models.tcn.TcnBlockParams","title":"<code>TcnBlockParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>TCN block parameters</p> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>class TcnBlockParams(BaseModel):\n    \"\"\"TCN block parameters\"\"\"\n\n    depth: int = Field(default=1, description=\"Layer depth\")\n    branch: int = Field(default=1, description=\"Number of branches\")\n    filters: int = Field(..., description=\"# filters\")\n    kernel: int | tuple[int, int] = Field(default=3, description=\"Kernel size\")\n    dilation: int | tuple[int, int] = Field(default=1, description=\"Dilation rate\")\n    ex_ratio: float = Field(default=1, description=\"Expansion ratio\")\n    se_ratio: float = Field(default=0, description=\"Squeeze and excite ratio\")\n    dropout: float | None = Field(default=None, description=\"Dropout rate\")\n    norm: Literal[\"batch\", \"layer\"] | None = Field(default=\"layer\", description=\"Normalization type\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.TcnParams","title":"<code>TcnParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>TCN parameters</p> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>class TcnParams(BaseModel):\n    \"\"\"TCN parameters\"\"\"\n\n    input_kernel: int | tuple[int, int] | None = Field(default=None, description=\"Input kernel size\")\n    input_norm: Literal[\"batch\", \"layer\"] | None = Field(default=\"layer\", description=\"Input normalization type\")\n    block_type: Literal[\"lg\", \"mb\", \"sm\"] = Field(default=\"mb\", description=\"Block type\")\n    blocks: list[TcnBlockParams] = Field(default_factory=list, description=\"UNext blocks\")\n    output_kernel: int | tuple[int, int] = Field(default=3, description=\"Output kernel size\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    use_logits: bool = Field(default=True, description=\"Use logits\")\n    model_name: str = Field(default=\"UNext\", description=\"Model name\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.Tcn","title":"<code>Tcn(x, params, num_classes)</code>","text":"<p>TCN model</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor</p> </li> <li> <code>params</code>             (<code>TcnParams</code>)         \u2013          <p>Parameters</p> </li> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          <p>Number of classes</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>def Tcn(\n    x: tf.Tensor,\n    params: TcnParams,\n    num_classes: int,\n) -&gt; keras.Model:\n    \"\"\"TCN model\n\n    Args:\n        x (tf.Tensor): Input tensor\n        params (TcnParams): Parameters\n        num_classes (int): Number of classes\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n    requires_reshape = len(x.shape) == 3\n    if requires_reshape:\n        y = keras.layers.Reshape((1,) + x.shape[1:])(x)\n    else:\n        y = x\n\n    # Encode each channel separately\n    if params.input_kernel:\n        y = keras.layers.DepthwiseConv2D(\n            kernel_size=params.input_kernel, use_bias=params.input_norm is None, name=\"ENC.CN\", padding=\"same\"\n        )(y)\n        y = norm_layer(params.input_norm, \"ENC\")(y)\n    # END IF\n\n    y = tcn_core(params)(y)\n\n    if params.include_top:\n        # Add a per-point classification layer\n        y = keras.layers.Conv2D(\n            num_classes,\n            kernel_size=params.output_kernel,\n            padding=\"same\",\n            name=\"NECK.conv\",\n            use_bias=True,\n        )(y)\n        if not params.use_logits:\n            y = keras.layers.Softmax()(y)\n        # END IF\n    # END IF\n\n    if requires_reshape:\n        y = keras.layers.Reshape(y.shape[2:])(y)\n\n    # Define the model\n    model = keras.Model(x, y, name=params.model_name)\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.norm_layer","title":"<code>norm_layer(norm, name)</code>","text":"<p>Normalization layer</p> <p>Parameters:</p> <ul> <li> <code>norm</code>             (<code>str</code>)         \u2013          <p>Normalization type</p> </li> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>Layer</p> </li> </ul> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>def norm_layer(norm: str, name: str) -&gt; KerasLayer:\n    \"\"\"Normalization layer\n\n    Args:\n        norm (str): Normalization type\n        name (str): Name\n\n    Returns:\n        KerasLayer: Layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"Functional normalization layer\n\n        Args:\n            x (tf.Tensor): Input tensor\n\n        Returns:\n            tf.Tensor: Output tensor\n        \"\"\"\n        if norm == \"batch\":\n            return keras.layers.BatchNormalization(axis=-1, name=f\"{name}.BN\")(x)\n        if norm == \"layer\":\n            return keras.layers.LayerNormalization(axis=(1, 2), name=f\"{name}.LN\")(x)\n        return x\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.tcn_block_lg","title":"<code>tcn_block_lg(params, name)</code>","text":"<p>TCN large block</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>TcnBlockParams</code>)         \u2013          <p>Parameters</p> </li> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>Layer</p> </li> </ul> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>def tcn_block_lg(params: TcnBlockParams, name: str) -&gt; KerasLayer:\n    \"\"\"TCN large block\n\n    Args:\n        params (TcnBlockParams): Parameters\n        name (str): Name\n\n    Returns:\n        KerasLayer: Layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"TCN block layer\"\"\"\n        y = x\n\n        for d in range(params.depth):\n            lcl_name = f\"{name}.D{d+1}\"\n            y_skip = y\n\n            y = keras.layers.Conv2D(\n                filters=params.filters,\n                kernel_size=params.kernel,\n                strides=(1, 1),\n                padding=\"same\",\n                use_bias=False,\n                dilation_rate=params.dilation,\n                kernel_initializer=\"he_normal\",\n                kernel_regularizer=keras.regularizers.L2(1e-3),\n                name=f\"{lcl_name}.CN1\",\n            )(y)\n            y = norm_layer(params.norm, f\"{lcl_name}.CN1\")(y)\n\n            y = keras.layers.Conv2D(\n                filters=params.filters,\n                kernel_size=params.kernel,\n                strides=(1, 1),\n                padding=\"same\",\n                use_bias=params.norm is None,\n                dilation_rate=params.dilation,\n                kernel_initializer=\"he_normal\",\n                kernel_regularizer=keras.regularizers.L2(1e-3),\n                name=f\"{lcl_name}.CN2\",\n            )(y)\n            y = norm_layer(params.norm, f\"{lcl_name}.CN2\")(y)\n\n            if y_skip.shape[-1] == y.shape[-1]:\n                y = keras.layers.Add(name=f\"{lcl_name}.ADD\")([y, y_skip])\n\n            y = keras.layers.Activation(\"relu6\", name=f\"{lcl_name}.RELU\")(y)\n\n            # Squeeze and excite\n            if params.se_ratio &gt; 0:\n                y = se_block(ratio=params.se_ratio, name=f\"{lcl_name}.SE\")(y)\n            # END IF\n\n            if params.dropout and params.dropout &gt; 0:\n                y = keras.layers.SpatialDropout2D(rate=params.dropout, name=f\"{lcl_name}.DROP\")(y)\n            # END IF\n\n        # END FOR\n        return y\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.tcn_block_mb","title":"<code>tcn_block_mb(params, name)</code>","text":"<p>TCN mbconv block</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>TcnBlockParams</code>)         \u2013          <p>Parameters</p> </li> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name</p> </li> </ul> <p>Returns:     KerasLayer: Layer</p> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>def tcn_block_mb(params: TcnBlockParams, name: str) -&gt; KerasLayer:\n    \"\"\"TCN mbconv block\n\n    Args:\n        params (TcnBlockParams): Parameters\n        name (str): Name\n    Returns:\n        KerasLayer: Layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"TCN block layer\"\"\"\n        y = x\n        y_skip = y\n        for d in range(params.depth):\n            lcl_name = f\"{name}.D{d+1}\"\n\n            if params.ex_ratio != 1:\n                y = keras.layers.Conv2D(\n                    filters=int(params.filters * params.ex_ratio),\n                    kernel_size=(1, 1),\n                    strides=(1, 1),\n                    padding=\"same\",\n                    use_bias=params.norm is None,\n                    kernel_initializer=\"he_normal\",\n                    kernel_regularizer=keras.regularizers.L2(1e-3),\n                    name=f\"{lcl_name}.EX.CN\",\n                )(y)\n                y = norm_layer(params.norm, f\"{lcl_name}.EX\")(y)\n                y = keras.layers.Activation(\"relu6\", name=f\"{lcl_name}.EX.RELU\")(y)\n            # END IF\n\n            branches = []\n            for b in range(params.branch):\n                yb = y\n                yb = keras.layers.DepthwiseConv2D(\n                    kernel_size=params.kernel,\n                    strides=(1, 1),\n                    padding=\"same\",\n                    use_bias=params.norm is None,\n                    dilation_rate=params.dilation,\n                    depthwise_initializer=\"he_normal\",\n                    depthwise_regularizer=keras.regularizers.L2(1e-3),\n                    name=f\"{lcl_name}.DW.B{b+1}.CN\",\n                )(yb)\n                yb = norm_layer(params.norm, f\"{lcl_name}.DW.B{b+1}\")(yb)\n                branches.append(yb)\n            # END FOR\n\n            if params.branch &gt; 1:\n                y = keras.layers.Add(name=f\"{lcl_name}.DW.ADD\")(branches)\n            else:\n                y = branches[0]\n            # END IF\n\n            y = keras.layers.Activation(\"relu6\", name=f\"{lcl_name}.DW.RELU\")(y)\n\n            # Squeeze and excite\n            if params.se_ratio &gt; 0:\n                y = se_block(ratio=params.se_ratio, name=f\"{lcl_name}.SE\")(y)\n            # END IF\n\n            branches = []\n            for b in range(params.branch):\n                yb = y\n                yb = keras.layers.Conv2D(\n                    filters=params.filters,\n                    kernel_size=(1, 1),\n                    strides=(1, 1),\n                    padding=\"same\",\n                    # groups=int(params.se_ratio) if params.se_ratio &gt; 0 else 1,\n                    use_bias=params.norm is None,\n                    kernel_initializer=\"he_normal\",\n                    kernel_regularizer=keras.regularizers.L2(1e-3),\n                    name=f\"{lcl_name}.PW.B{b+1}.CN\",\n                )(yb)\n                yb = norm_layer(params.norm, f\"{lcl_name}.PW.B{b+1}\")(yb)\n                branches.append(yb)\n            # END FOR\n\n            if params.branch &gt; 1:\n                y = keras.layers.Add(name=f\"{lcl_name}.PW.ADD\")(branches)\n            else:\n                y = branches[0]\n            # END IF\n\n            y = keras.layers.Activation(\"relu6\", name=f\"{lcl_name}.PW.RELU\")(y)\n        # END FOR\n\n        # Skip connection\n        if y_skip.shape[-1] == y.shape[-1]:\n            y = keras.layers.Add(name=f\"{name}.ADD\")([y, y_skip])\n\n        if params.dropout and params.dropout &gt; 0:\n            y = keras.layers.SpatialDropout2D(rate=params.dropout, name=f\"{name}.DROP\")(y)\n        # END IF\n        return y\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.tcn_block_sm","title":"<code>tcn_block_sm(params, name)</code>","text":"<p>TCN small block</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>TcnBlockParams</code>)         \u2013          <p>Parameters</p> </li> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name</p> </li> </ul> <p>Returns:     KerasLayer: Layer</p> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>def tcn_block_sm(params: TcnBlockParams, name: str) -&gt; KerasLayer:\n    \"\"\"TCN small block\n\n    Args:\n        params (TcnBlockParams): Parameters\n        name (str): Name\n    Returns:\n        KerasLayer: Layer\n    \"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        \"\"\"TCN block layer\"\"\"\n        y = x\n        y_skip = y\n        for d in range(params.depth):\n            lcl_name = f\"{name}.D{d+1}\"\n            branches = []\n            for b in range(params.branch):\n                yb = y\n                yb = keras.layers.DepthwiseConv2D(\n                    kernel_size=params.kernel,\n                    strides=(1, 1),\n                    padding=\"same\",\n                    use_bias=params.norm is None,\n                    dilation_rate=params.dilation,\n                    depthwise_initializer=\"he_normal\",\n                    depthwise_regularizer=keras.regularizers.L2(1e-3),\n                    name=f\"{lcl_name}.DW.B{b+1}.CN\",\n                )(yb)\n                yb = norm_layer(params.norm, f\"{lcl_name}.DW.B{b+1}\")(yb)\n                branches.append(yb)\n            # END FOR\n\n            if params.branch &gt; 1:\n                y = keras.layers.Add(name=f\"{lcl_name}.DW.ADD\")(branches)\n            else:\n                y = branches[0]\n            # END IF\n\n            y = keras.layers.Activation(\"relu6\", name=f\"{lcl_name}.DW.RELU\")(y)\n\n            branches = []\n            for b in range(params.branch):\n                yb = y\n                yb = keras.layers.Conv2D(\n                    filters=params.filters,\n                    kernel_size=(1, 1),\n                    strides=(1, 1),\n                    padding=\"same\",\n                    # groups=int(params.se_ratio) if params.se_ratio &gt; 0 else 1,\n                    use_bias=params.norm is None,\n                    kernel_initializer=\"he_normal\",\n                    kernel_regularizer=keras.regularizers.L2(1e-3),\n                    name=f\"{lcl_name}.PW.B{b+1}.CN\",\n                )(yb)\n                yb = norm_layer(params.norm, f\"{lcl_name}.PW.B{b+1}\")(yb)\n                branches.append(yb)\n            # END FOR\n\n            if params.branch &gt; 1:\n                y = keras.layers.Add(name=f\"{lcl_name}.PW.ADD\")(branches)\n            else:\n                y = branches[0]\n            # END IF\n\n            y = keras.layers.Activation(\"relu6\", name=f\"{lcl_name}.PW.RELU\")(y)\n        # END FOR\n\n        # Squeeze and excite\n        if params.se_ratio &gt; 0:\n            y = se_block(ratio=params.se_ratio, name=f\"{name}.SE\")(y)\n        # END IF\n\n        # Skip connection\n        if y_skip.shape[-1] == y.shape[-1]:\n            y = keras.layers.Add(name=f\"{name}.ADD\")([y, y_skip])\n\n        if params.dropout and params.dropout &gt; 0:\n            y = keras.layers.SpatialDropout2D(rate=params.dropout, name=f\"{name}.DROP\")(y)\n        # END IF\n        return y\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.tcn.tcn_core","title":"<code>tcn_core(params)</code>","text":"<p>TCN core</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>TcnParams</code>)         \u2013          <p>Parameters</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>KerasLayer</code> (            <code>KerasLayer</code> )        \u2013          <p>Layer</p> </li> </ul> Source code in <code>sleepkit/models/tcn.py</code> <pre><code>def tcn_core(params: TcnParams) -&gt; KerasLayer:\n    \"\"\"TCN core\n\n    Args:\n        params (TcnParams): Parameters\n\n    Returns:\n        KerasLayer: Layer\n    \"\"\"\n    if params.block_type == \"lg\":\n        tcn_block = tcn_block_lg\n    elif params.block_type == \"mb\":\n        tcn_block = tcn_block_mb\n    elif params.block_type == \"sm\":\n        tcn_block = tcn_block_sm\n    else:\n        raise ValueError(f\"Invalid block type: {params.block_type}\")\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        y = x\n        for i, block in enumerate(params.blocks):\n            name = f\"B{i+1}\"\n            y = tcn_block(params=block, name=name)(y)\n        # END IF\n        return y\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.unet","title":"<code>sleepkit.models.unet</code>","text":"<p>UNet</p>"},{"location":"api/models/#sleepkit.models.unet.UNetBlockParams","title":"<code>UNetBlockParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>UNet block parameters</p> Source code in <code>sleepkit/models/unet.py</code> <pre><code>class UNetBlockParams(BaseModel):\n    \"\"\"UNet block parameters\"\"\"\n\n    filters: int = Field(..., description=\"# filters\")\n    depth: int = Field(default=1, description=\"Layer depth\")\n    kernel: int | tuple[int, int] = Field(default=3, description=\"Kernel size\")\n    pool: int | tuple[int, int] = Field(default=3, description=\"Pool size\")\n    strides: int | tuple[int, int] = Field(default=1, description=\"Stride size\")\n    skip: bool = Field(default=True, description=\"Add skip connection\")\n    seperable: bool = Field(default=False, description=\"Use seperable convs\")\n    dropout: float | None = Field(default=None, description=\"Dropout rate\")\n    norm: Literal[\"batch\", \"layer\"] | None = Field(default=\"batch\", description=\"Normalization type\")\n    dilation: int | tuple[int, int] | None = Field(default=None, description=\"Dilation factor\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.unet.UNetParams","title":"<code>UNetParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>UNet parameters</p> Source code in <code>sleepkit/models/unet.py</code> <pre><code>class UNetParams(BaseModel):\n    \"\"\"UNet parameters\"\"\"\n\n    blocks: list[UNetBlockParams] = Field(default_factory=list, description=\"UNet blocks\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    use_logits: bool = Field(default=True, description=\"Use logits\")\n    model_name: str = Field(default=\"UNet\", description=\"Model name\")\n    output_kernel_size: int | tuple[int, int] = Field(default=3, description=\"Output kernel size\")\n    output_kernel_stride: int | tuple[int, int] = Field(default=1, description=\"Output kernel stride\")\n    include_rnn: bool = Field(default=False, description=\"Include RNN\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.unet.UNet","title":"<code>UNet(x, params, num_classes)</code>","text":"<p>Create UNet TF functional model</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor</p> </li> <li> <code>params</code>             (<code>ResNetParams</code>)         \u2013          <p>Model parameters.</p> </li> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/models/unet.py</code> <pre><code>def UNet(\n    x: tf.Tensor,\n    params: UNetParams,\n    num_classes: int,\n) -&gt; keras.Model:\n    \"\"\"Create UNet TF functional model\n\n    Args:\n        x (tf.Tensor): Input tensor\n        params (ResNetParams): Model parameters.\n        num_classes (int, optional): # classes.\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n    requires_reshape = len(x.shape) == 3\n    if requires_reshape:\n        y = keras.layers.Reshape((1,) + x.shape[1:])(x)\n    else:\n        y = x\n\n    #### ENCODER ####\n    skip_layers: list[keras.layers.Layer | None] = []\n    for i, block in enumerate(params.blocks):\n        name = f\"ENC{i+1}\"\n        ym = y\n        for d in range(block.depth):\n            dname = f\"{name}.D{d+1}\"\n            if block.dilation is None:\n                dilation_rate = (1, 1)\n            elif isinstance(block.dilation, int):\n                dilation_rate = (block.dilation**d, block.dilation**d)\n            else:\n                dilation_rate = (block.dilation[0] ** d, block.dilation[1] ** d)\n            if block.seperable:\n                ym = keras.layers.SeparableConv2D(\n                    block.filters,\n                    kernel_size=block.kernel,\n                    strides=(1, 1),\n                    padding=\"same\",\n                    dilation_rate=dilation_rate,\n                    depthwise_initializer=\"he_normal\",\n                    pointwise_initializer=\"he_normal\",\n                    depthwise_regularizer=keras.regularizers.L2(1e-3),\n                    pointwise_regularizer=keras.regularizers.L2(1e-3),\n                    use_bias=block.norm is None,\n                    name=f\"{dname}.conv\",\n                )(ym)\n            else:\n                ym = keras.layers.Conv2D(\n                    block.filters,\n                    kernel_size=block.kernel,\n                    strides=(1, 1),\n                    padding=\"same\",\n                    dilation_rate=dilation_rate,\n                    kernel_initializer=\"he_normal\",\n                    kernel_regularizer=keras.regularizers.L2(1e-3),\n                    use_bias=block.norm is None,\n                    name=f\"{dname}.conv\",\n                )(ym)\n            if block.norm == \"layer\":\n                ym = layer_norm(name=dname, axis=[1, 2])(ym)\n            elif block.norm == \"batch\":\n                ym = batch_norm(name=dname, momentum=0.99)(ym)\n            ym = relu6(name=dname)(ym)\n        # END FOR\n\n        # Project residual\n        yr = keras.layers.Conv2D(\n            block.filters,\n            kernel_size=(1, 1),\n            strides=(1, 1),\n            padding=\"same\",\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.skip\",\n        )(y)\n\n        if block.dropout is not None:\n            ym = keras.layers.Dropout(block.dropout, noise_shape=ym.shape)(ym)\n        y = keras.layers.add([ym, yr], name=f\"{name}.add\")\n\n        skip_layers.append(y if block.skip else None)\n\n        y = keras.layers.MaxPooling2D(block.pool, strides=block.strides, padding=\"same\", name=f\"{name}.pool\")(y)\n    # END FOR\n\n    if params.include_rnn:\n        if requires_reshape:\n            y = keras.layers.Reshape(y.shape[2:])(y)\n            y = keras.layers.LSTM(units=params.blocks[-1].filters, return_sequences=True)(y)\n            y = keras.layers.Reshape((1,) + y.shape[1:])(y)\n        else:\n            y = keras.layers.ConvLSTM1D(params.blocks[-1].filters, padding=\"same\", return_sequences=True)(y)\n\n    #### DECODER ####\n    for i, block in enumerate(reversed(params.blocks)):\n        name = f\"DEC{i+1}\"\n        for d in range(block.depth):\n            dname = f\"{name}.D{d+1}\"\n            if block.seperable:\n                y = keras.layers.SeparableConv2D(\n                    block.filters,\n                    kernel_size=block.kernel,\n                    strides=(1, 1),\n                    padding=\"same\",\n                    dilation_rate=dilation_rate,\n                    depthwise_initializer=\"he_normal\",\n                    pointwise_initializer=\"he_normal\",\n                    depthwise_regularizer=keras.regularizers.L2(1e-3),\n                    pointwise_regularizer=keras.regularizers.L2(1e-3),\n                    use_bias=block.norm is None,\n                    name=f\"{dname}.conv\",\n                )(y)\n            else:\n                y = keras.layers.Conv2D(\n                    block.filters,\n                    kernel_size=block.kernel,\n                    strides=(1, 1),\n                    padding=\"same\",\n                    dilation_rate=dilation_rate,\n                    kernel_initializer=\"he_normal\",\n                    kernel_regularizer=keras.regularizers.L2(1e-3),\n                    use_bias=block.norm is None,\n                    name=f\"{dname}.conv\",\n                )(y)\n            if block.norm == \"layer\":\n                y = layer_norm(name=dname, axis=[1, 2])(y)\n            elif block.norm == \"batch\":\n                y = batch_norm(name=dname, momentum=0.99)(y)\n            y = relu6(name=dname)(y)\n        # END FOR\n\n        y = keras.layers.UpSampling2D(size=block.strides, name=f\"{dname}.unpool\")(y)\n\n        # Add skip connection\n        dname = f\"{name}.D{block.depth+1}\"\n        skip_layer = skip_layers.pop()\n        if skip_layer is not None:\n            y = keras.layers.concatenate([y, skip_layer], name=f\"{dname}.cat\")  # Can add or concatenate\n            # Use 1x1 conv to reduce filters\n            y = keras.layers.Conv2D(\n                block.filters,\n                kernel_size=(1, 1),\n                padding=\"same\",\n                kernel_initializer=\"he_normal\",\n                kernel_regularizer=keras.regularizers.L2(1e-3),\n                use_bias=block.norm is None,\n                name=f\"{dname}.conv\",\n            )(y)\n            if block.norm == \"layer\":\n                y = layer_norm(name=dname, axis=[1, 2])(y)\n            elif block.norm == \"batch\":\n                y = batch_norm(name=dname, momentum=0.99)(y)\n            y = relu6(name=dname)(y)\n        # END IF\n\n        dname = f\"{name}.D{block.depth+2}\"\n        if block.seperable:\n            ym = keras.layers.SeparableConv2D(\n                block.filters,\n                kernel_size=block.kernel,\n                strides=(1, 1),\n                padding=\"same\",\n                depthwise_initializer=\"he_normal\",\n                pointwise_initializer=\"he_normal\",\n                depthwise_regularizer=keras.regularizers.L2(1e-3),\n                pointwise_regularizer=keras.regularizers.L2(1e-3),\n                use_bias=block.norm is None,\n                name=f\"{dname}.conv\",\n            )(y)\n        else:\n            ym = keras.layers.Conv2D(\n                block.filters,\n                kernel_size=block.kernel,\n                strides=(1, 1),\n                padding=\"same\",\n                kernel_initializer=\"he_normal\",\n                kernel_regularizer=keras.regularizers.L2(1e-3),\n                use_bias=block.norm is None,\n                name=f\"{dname}.conv\",\n            )(y)\n        if block.norm == \"layer\":\n            ym = layer_norm(name=dname, axis=[1, 2])(ym)\n        elif block.norm == \"batch\":\n            ym = batch_norm(name=dname, momentum=0.99)(ym)\n        ym = relu6(name=dname)(ym)\n\n        # Project residual\n        yr = keras.layers.Conv2D(\n            block.filters,\n            kernel_size=(1, 1),\n            padding=\"same\",\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.skip\",\n        )(y)\n        y = keras.layers.add([ym, yr], name=f\"{name}.add\")  # Add back residual\n    # END FOR\n\n    if params.include_top:\n        # Add a per-point classification layer\n        y = keras.layers.Conv2D(\n            num_classes,\n            kernel_size=params.output_kernel_size,\n            padding=\"same\",\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=\"NECK.conv\",\n            use_bias=True,\n        )(y)\n        if not params.use_logits:\n            y = keras.layers.Softmax()(y)\n        # END IF\n    # END IF\n    if requires_reshape:\n        y = keras.layers.Reshape(y.shape[2:])(y)\n    # Define the model\n    model = keras.Model(x, y, name=params.model_name)\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.unet.UNet--classes","title":"classes.","text":""},{"location":"api/models/#sleepkit.models.unext","title":"<code>sleepkit.models.unext</code>","text":"<p>UNext</p>"},{"location":"api/models/#sleepkit.models.unext.UNextBlockParams","title":"<code>UNextBlockParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>UNext block parameters</p> Source code in <code>sleepkit/models/unext.py</code> <pre><code>class UNextBlockParams(BaseModel):\n    \"\"\"UNext block parameters\"\"\"\n\n    filters: int = Field(..., description=\"# filters\")\n    depth: int = Field(default=1, description=\"Layer depth\")\n    ddepth: int | None = Field(default=None, description=\"Layer decoder depth\")\n    kernel: int | tuple[int, int] = Field(default=3, description=\"Kernel size\")\n    pool: int | tuple[int, int] = Field(default=2, description=\"Pool size\")\n    strides: int | tuple[int, int] = Field(default=2, description=\"Stride size\")\n    skip: bool = Field(default=True, description=\"Add skip connection\")\n    expand_ratio: float = Field(default=1, description=\"Expansion ratio\")\n    se_ratio: float = Field(default=0, description=\"Squeeze and excite ratio\")\n    dropout: float | None = Field(default=None, description=\"Dropout rate\")\n    norm: Literal[\"batch\", \"layer\"] | None = Field(default=\"layer\", description=\"Normalization type\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.unext.UNextParams","title":"<code>UNextParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>UNext parameters</p> Source code in <code>sleepkit/models/unext.py</code> <pre><code>class UNextParams(BaseModel):\n    \"\"\"UNext parameters\"\"\"\n\n    blocks: list[UNextBlockParams] = Field(default_factory=list, description=\"UNext blocks\")\n    include_top: bool = Field(default=True, description=\"Include top\")\n    use_logits: bool = Field(default=True, description=\"Use logits\")\n    model_name: str = Field(default=\"UNext\", description=\"Model name\")\n    output_kernel_size: int | tuple[int, int] = Field(default=3, description=\"Output kernel size\")\n    output_kernel_stride: int | tuple[int, int] = Field(default=1, description=\"Output kernel stride\")\n</code></pre>"},{"location":"api/models/#sleepkit.models.unext.UNext","title":"<code>UNext(x, params, num_classes)</code>","text":"<p>Create UNext TF functional model</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor</p> </li> <li> <code>params</code>             (<code>UNextParams</code>)         \u2013          <p>Model parameters.</p> </li> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/models/unext.py</code> <pre><code>def UNext(\n    x: tf.Tensor,\n    params: UNextParams,\n    num_classes: int,\n) -&gt; keras.Model:\n    \"\"\"Create UNext TF functional model\n\n    Args:\n        x (tf.Tensor): Input tensor\n        params (UNextParams): Model parameters.\n        num_classes (int, optional): # classes.\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n    requires_reshape = len(x.shape) == 3\n    if requires_reshape:\n        y = keras.layers.Reshape((1,) + x.shape[1:])(x)\n    else:\n        y = x\n\n    y = unext_core(y, params)\n\n    if params.include_top:\n        # Add a per-point classification layer\n        y = keras.layers.Conv2D(\n            num_classes,\n            kernel_size=params.output_kernel_size,\n            padding=\"same\",\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=\"NECK.conv\",\n            use_bias=True,\n        )(y)\n        if not params.use_logits:\n            y = keras.layers.Softmax()(y)\n        # END IF\n    # END IF\n\n    if requires_reshape:\n        y = keras.layers.Reshape(y.shape[2:])(y)\n\n    # Define the model\n    model = keras.Model(x, y, name=params.model_name)\n    return model\n</code></pre>"},{"location":"api/models/#sleepkit.models.unext.UNext--classes","title":"classes.","text":""},{"location":"api/models/#sleepkit.models.unext.UNext_block","title":"<code>UNext_block(output_filters, expand_ratio=1, kernel_size=3, strides=1, se_ratio=4, dropout=0, norm='batch', name=None)</code>","text":"<p>Create UNext block</p> Source code in <code>sleepkit/models/unext.py</code> <pre><code>def UNext_block(\n    output_filters: int,\n    expand_ratio: float = 1,\n    kernel_size: int | tuple[int, int] = 3,\n    strides: int | tuple[int, int] = 1,\n    se_ratio: float = 4,\n    dropout: float | None = 0,\n    norm: Literal[\"batch\", \"layer\"] | None = \"batch\",\n    name: str | None = None,\n) -&gt; KerasLayer:\n    \"\"\"Create UNext block\"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        input_filters: int = x.shape[-1]\n        strides_len = strides if isinstance(strides, int) else sum(strides) // len(strides)\n        add_residual = input_filters == output_filters and strides_len == 1\n        ln_axis = 2 if x.shape[1] == 1 else 1 if x.shape[2] == 1 else (1, 2)\n\n        # Depthwise conv\n        y = keras.layers.Conv2D(\n            input_filters,\n            kernel_size=kernel_size,\n            groups=input_filters,\n            strides=1,\n            padding=\"same\",\n            use_bias=norm is None,\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.dwconv\" if name else None,\n        )(x)\n        if norm == \"batch\":\n            y = keras.layers.BatchNormalization(\n                name=f\"{name}.norm\",\n            )(y)\n        elif norm == \"layer\":\n            y = keras.layers.LayerNormalization(\n                axis=ln_axis,\n                name=f\"{name}.norm\" if name else None,\n            )(y)\n        # END IF\n\n        # Inverted expansion block\n        y = keras.layers.Conv2D(\n            filters=int(expand_ratio * input_filters),\n            kernel_size=1,\n            strides=1,\n            padding=\"same\",\n            use_bias=norm is None,\n            groups=input_filters,\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.expand\" if name else None,\n        )(y)\n\n        y = keras.layers.Activation(\n            tf.nn.relu6,\n            name=f\"{name}.relu\" if name else None,\n        )(y)\n\n        # Squeeze and excite\n        if se_ratio &gt; 1:\n            name_se = f\"{name}.se\" if name else None\n            y = se_block(ratio=se_ratio, name=name_se)(y)\n\n        y = keras.layers.Conv2D(\n            filters=output_filters,\n            kernel_size=1,\n            strides=1,\n            padding=\"same\",\n            use_bias=norm is None,\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.project\" if name else None,\n        )(y)\n\n        if add_residual:\n            if dropout and dropout &gt; 0:\n                y = keras.layers.Dropout(\n                    dropout,\n                    noise_shape=(y.shape),\n                    name=f\"{name}.drop\" if name else None,\n                )(y)\n            y = keras.layers.Add(name=f\"{name}.res\" if name else None)([x, y])\n        return y\n\n    # END DEF\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.unext.layer_norm","title":"<code>layer_norm(epsilon=0.001)</code>","text":"<p>Layer normalization</p> Source code in <code>sleepkit/models/unext.py</code> <pre><code>def layer_norm(epsilon: float = 1e-3) -&gt; KerasLayer:\n    \"\"\"Layer normalization\"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        # Compute mean for each channel\n        mu = tf.math.reduce_mean(x, axis=1, keepdims=True)\n        std = tf.math.sqrt(tf.math.reduce_variance(x, axis=1, keepdims=True) + epsilon)\n        # Normalize\n        y = (x - mu) / (std)\n        return y\n\n    # END DEF\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.unext.se_block","title":"<code>se_block(ratio=8, name=None)</code>","text":"<p>Squeeze and excite block</p> Source code in <code>sleepkit/models/unext.py</code> <pre><code>def se_block(ratio: int = 8, name: str | None = None):\n    \"\"\"Squeeze and excite block\"\"\"\n\n    def layer(x: tf.Tensor) -&gt; tf.Tensor:\n        num_chan = x.shape[-1]\n        # Squeeze\n        y = keras.layers.GlobalAveragePooling2D(name=f\"{name}.pool\" if name else None, keepdims=True)(x)\n\n        y = keras.layers.Conv2D(num_chan // ratio, kernel_size=1, use_bias=True, name=f\"{name}.sq\" if name else None)(y)\n\n        y = keras.layers.Activation(tf.nn.relu6, name=f\"{name}.relu\" if name else None)(y)\n\n        # Excite\n        y = keras.layers.Conv2D(num_chan, kernel_size=1, use_bias=True, name=f\"{name}.ex\" if name else None)(y)\n        y = keras.layers.Activation(keras.activations.hard_sigmoid, name=f\"{name}.sigg\" if name else None)(y)\n        y = keras.layers.Multiply(name=f\"{name}.mul\" if name else None)([x, y])\n        return y\n\n    return layer\n</code></pre>"},{"location":"api/models/#sleepkit.models.unext.unext_core","title":"<code>unext_core(x, params)</code>","text":"<p>Create UNext TF functional core</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Input tensor</p> </li> <li> <code>params</code>             (<code>UNextParams</code>)         \u2013          <p>Model parameters.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tensor</code>         \u2013          <p>tf.Tensor: Output tensor</p> </li> </ul> Source code in <code>sleepkit/models/unext.py</code> <pre><code>def unext_core(\n    x: tf.Tensor,\n    params: UNextParams,\n) -&gt; tf.Tensor:\n    \"\"\"Create UNext TF functional core\n\n    Args:\n        x (tf.Tensor): Input tensor\n        params (UNextParams): Model parameters.\n\n    Returns:\n        tf.Tensor: Output tensor\n    \"\"\"\n\n    y = x\n\n    #### ENCODER ####\n    skip_layers: list[keras.layers.Layer | None] = []\n    for i, block in enumerate(params.blocks):\n        name = f\"ENC{i+1}\"\n        for d in range(block.depth):\n            y = UNext_block(\n                output_filters=block.filters,\n                expand_ratio=block.expand_ratio,\n                kernel_size=block.kernel,\n                strides=1,\n                se_ratio=block.se_ratio,\n                dropout=block.dropout,\n                norm=block.norm,\n                name=f\"{name}.D{d+1}\",\n            )(y)\n        # END FOR\n        skip_layers.append(y if block.skip else None)\n\n        # Downsample using strided conv\n        y = keras.layers.Conv2D(\n            filters=block.filters,\n            kernel_size=block.pool,\n            strides=block.strides,\n            padding=\"same\",\n            use_bias=block.norm is None,\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.pool\",\n        )(y)\n        if block.norm == \"batch\":\n            y = keras.layers.BatchNormalization(\n                name=f\"{name}.norm\",\n            )(y)\n        elif block.norm == \"layer\":\n            ln_axis = 2 if y.shape[1] == 1 else 1 if y.shape[2] == 1 else (1, 2)\n            y = keras.layers.LayerNormalization(\n                axis=ln_axis,\n                name=f\"{name}.norm\",\n            )(y)\n        # END IF\n    # END FOR\n\n    #### DECODER ####\n    for i, block in enumerate(reversed(params.blocks)):\n        name = f\"DEC{i+1}\"\n        for d in range(block.ddepth or block.depth):\n            y = UNext_block(\n                output_filters=block.filters,\n                expand_ratio=block.expand_ratio,\n                kernel_size=block.kernel,\n                strides=1,\n                se_ratio=block.se_ratio,\n                dropout=block.dropout,\n                norm=block.norm,\n                name=f\"{name}.D{d+1}\",\n            )(y)\n        # END FOR\n\n        y = keras.layers.Conv2D(\n            filters=block.filters,\n            kernel_size=block.pool,\n            strides=1,\n            padding=\"same\",\n            use_bias=block.norm is None,\n            kernel_initializer=\"he_normal\",\n            kernel_regularizer=keras.regularizers.L2(1e-3),\n            name=f\"{name}.conv\",\n        )(y)\n        y = keras.layers.UpSampling2D(size=block.strides, name=f\"{name}.unpool\")(y)\n\n        # Skip connection\n        skip_layer = skip_layers.pop()\n        if skip_layer is not None:\n            # y = keras.layers.Concatenate(name=f\"{name}.S1.cat\")([y, skip_layer])\n            y = keras.layers.Add(name=f\"{name}.S1.cat\")([y, skip_layer])\n\n            # Use conv to reduce filters\n            y = keras.layers.Conv2D(\n                block.filters,\n                kernel_size=1,  # block.kernel,\n                padding=\"same\",\n                kernel_initializer=\"he_normal\",\n                kernel_regularizer=keras.regularizers.L2(1e-3),\n                use_bias=block.norm is None,\n                name=f\"{name}.S1.conv\",\n            )(y)\n\n            if block.norm == \"batch\":\n                y = keras.layers.BatchNormalization(\n                    name=f\"{name}.S1.norm\",\n                )(y)\n            elif block.norm == \"layer\":\n                ln_axis = 2 if y.shape[1] == 1 else 1 if y.shape[2] == 1 else (1, 2)\n                y = keras.layers.LayerNormalization(\n                    axis=ln_axis,\n                    name=f\"{name}.S1.norm\",\n                )(y)\n            # END IF\n\n            y = keras.layers.Activation(\n                tf.nn.relu6,\n                name=f\"{name}.S1.relu\" if name else None,\n            )(y)\n        # END IF\n\n        y = UNext_block(\n            output_filters=block.filters,\n            expand_ratio=block.expand_ratio,\n            kernel_size=block.kernel,\n            strides=1,\n            se_ratio=block.se_ratio,\n            dropout=block.dropout,\n            norm=block.norm,\n            name=f\"{name}.D{block.depth+1}\",\n        )(y)\n\n    # END FOR\n    return y\n</code></pre>"},{"location":"api/sleepkit/","title":"SleepKit","text":""},{"location":"api/sleepkit/#sleepkit.augmentations","title":"<code>sleepkit.augmentations</code>","text":""},{"location":"api/sleepkit/#sleepkit.augmentations.AugmentationParams","title":"<code>AugmentationParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Augmentation parameters</p> Source code in <code>sleepkit/augmentations.py</code> <pre><code>class AugmentationParams(BaseModel, extra=\"allow\"):\n    \"\"\"Augmentation parameters\"\"\"\n\n    name: str\n    args: dict[str, tuple[float | int, float | int]]\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.augmentations.augment_pipeline","title":"<code>augment_pipeline(x, augmentations, sample_rate)</code>","text":"<p>Apply augmentation pipeline</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>NDArray</code>)         \u2013          <p>Signal</p> </li> <li> <code>augmentations</code>             (<code>list[AugmentationParams]</code>)         \u2013          <p>Augmentations to apply</p> </li> <li> <code>sample_rate</code>             (<code>float</code>)         \u2013          <p>Sampling rate in Hz.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>         \u2013          <p>npt.NDArray: Augmented signal</p> </li> </ul> Source code in <code>sleepkit/augmentations.py</code> <pre><code>def augment_pipeline(x: npt.NDArray, augmentations: list[AugmentationParams], sample_rate: float) -&gt; npt.NDArray:\n    \"\"\"Apply augmentation pipeline\n\n    Args:\n        x (npt.NDArray): Signal\n        augmentations (list[AugmentationParams]): Augmentations to apply\n        sample_rate: Sampling rate in Hz.\n\n    Returns:\n        npt.NDArray: Augmented signal\n    \"\"\"\n    x_sd = np.nanstd(x)\n    for augmentation in augmentations:\n        args = augmentation.args\n        match augmentation.name:\n            case \"baseline_wander\":\n                amplitude = args.get(\"amplitude\", [0.05, 0.06])\n                frequency = args.get(\"frequency\", [0, 1])\n                x = pk.signal.add_baseline_wander(\n                    x,\n                    amplitude=np.random.uniform(amplitude[0], amplitude[1]),\n                    frequency=np.random.uniform(frequency[0], frequency[1]),\n                    sample_rate=sample_rate,\n                    signal_sd=x_sd,\n                )\n            case \"motion_noise\":\n                amplitude = args.get(\"amplitude\", [0.5, 1.0])\n                frequency = args.get(\"frequency\", [0.4, 0.6])\n                x = pk.signal.add_motion_noise(\n                    x,\n                    amplitude=np.random.uniform(amplitude[0], amplitude[1]),\n                    frequency=np.random.uniform(frequency[0], frequency[1]),\n                    sample_rate=sample_rate,\n                    signal_sd=x_sd,\n                )\n            case \"burst_noise\":\n                amplitude = args.get(\"amplitude\", [0.05, 0.5])\n                frequency = args.get(\"frequency\", [sample_rate / 4, sample_rate / 2])\n                burst_number = args.get(\"burst_number\", [0, 2])\n                x = pk.signal.add_burst_noise(\n                    x,\n                    amplitude=np.random.uniform(amplitude[0], amplitude[1]),\n                    frequency=np.random.uniform(frequency[0], frequency[1]),\n                    num_bursts=np.random.randint(burst_number[0], burst_number[1]),\n                    sample_rate=sample_rate,\n                    signal_sd=x_sd,\n                )\n            case \"powerline_noise\":\n                amplitude = args.get(\"amplitude\", [0.005, 0.01])\n                frequency = args.get(\"frequency\", [50, 60])\n                x = pk.signal.add_powerline_noise(\n                    x,\n                    amplitude=np.random.uniform(amplitude[0], amplitude[1]),\n                    frequency=np.random.uniform(frequency[0], frequency[1]),\n                    sample_rate=sample_rate,\n                    signal_sd=x_sd,\n                )\n            case \"noise_sources\":\n                num_sources = args.get(\"num_sources\", [1, 2])\n                amplitude = args.get(\"amplitude\", [0, 0.1])\n                frequency = args.get(\"frequency\", [0, sample_rate / 2])\n                num_sources: int = np.random.randint(num_sources[0], num_sources[1])\n                x = pk.signal.add_noise_sources(\n                    x,\n                    amplitudes=[np.random.uniform(amplitude[0], amplitude[1]) for _ in range(num_sources)],\n                    frequencies=[np.random.uniform(frequency[0], frequency[1]) for _ in range(num_sources)],\n                    noise_shapes=[\"laplace\" for _ in range(num_sources)],\n                    sample_rate=sample_rate,\n                    signal_sd=x_sd,\n                )\n            case \"lead_noise\":\n                scale = args.get(\"scale\", [1e-3, 1e-2])\n                x = pk.signal.add_lead_noise(\n                    x,\n                    scale=np.random.uniform(scale[0], scale[1]),\n                )\n            case _:\n                raise ValueError(f\"Unknown augmentation '{augmentation.name}'\")\n        # END MATCH\n    # END FOR\n    return x\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.cli","title":"<code>sleepkit.cli</code>","text":""},{"location":"api/sleepkit/#sleepkit.cli.parse_content","title":"<code>parse_content(cls, content)</code>","text":"<p>Parse file or raw content into Pydantic model.</p> <p>Parameters:</p> <ul> <li> <code>cls</code>             (<code>B</code>)         \u2013          <p>Pydantic model subclasss</p> </li> <li> <code>content</code>             (<code>str</code>)         \u2013          <p>File path or raw content</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>B</code> (            <code>B</code> )        \u2013          <p>Pydantic model subclass instance</p> </li> </ul> Source code in <code>sleepkit/cli.py</code> <pre><code>def parse_content(cls: Type[B], content: str) -&gt; B:\n    \"\"\"Parse file or raw content into Pydantic model.\n\n    Args:\n        cls (B): Pydantic model subclasss\n        content (str): File path or raw content\n\n    Returns:\n        B: Pydantic model subclass instance\n    \"\"\"\n    if os.path.isfile(content):\n        with open(content, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n    return cls.model_validate_json(json_data=content)\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.cli.run","title":"<code>run()</code>","text":"<p>Run CLI.</p> Source code in <code>sleepkit/cli.py</code> <pre><code>def run():\n    \"\"\"Run CLI.\"\"\"\n    cli()\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines","title":"<code>sleepkit.defines</code>","text":""},{"location":"api/sleepkit/#sleepkit.defines.SKDemoParams","title":"<code>SKDemoParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Demo command params</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKDemoParams(BaseModel, extra=\"allow\"):\n    \"\"\"Demo command params\"\"\"\n\n    job_dir: Path = Field(default_factory=tempfile.gettempdir, description=\"Job output directory\")\n    # Dataset arguments\n    ds_path: Path = Field(default_factory=Path, description=\"Dataset base directory\")\n    ds_handler: str = Field(description=\"Dataset handler name\")\n    ds_params: dict[str, Any] | None = Field(default_factory=dict, description=\"Dataset parameters\")\n    frame_size: int = Field(1250, description=\"Frame size\")\n    num_classes: int = Field(2, description=\"# of classes\")\n    # Model arguments\n    model_file: str | None = Field(None, description=\"Path to model file\")\n    backend: Literal[\"pc\", \"evb\"] = Field(\"pc\", description=\"Backend\")\n    # Extra arguments\n    seed: int | None = Field(None, description=\"Random state seed\")\n    model_config = ConfigDict(protected_namespaces=())\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKDownloadParams","title":"<code>SKDownloadParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>SleepKit download command params</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKDownloadParams(BaseModel, extra=\"allow\"):\n    \"\"\"SleepKit download command params\"\"\"\n\n    ds_path: Path = Field(default_factory=Path, description=\"Dataset root directory\")\n    datasets: list[DatasetTypes] = Field(default_factory=list, description=\"Datasets\")\n    progress: bool = Field(True, description=\"Display progress bar\")\n    force: bool = Field(False, description=\"Force download dataset- overriding existing files\")\n    data_parallelism: int = Field(\n        default_factory=lambda: os.cpu_count() or 1,\n        description=\"# of data loaders running in parallel\",\n    )\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKExportParams","title":"<code>SKExportParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>Export command params</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKExportParams(BaseModel, extra=\"allow\"):\n    \"\"\"Export command params\"\"\"\n\n    job_dir: Path = Field(default_factory=tempfile.gettempdir, description=\"Job output directory\")\n    # Dataset arguments\n    ds_path: Path = Field(default_factory=Path, description=\"Dataset base directory\")\n    ds_handler: str = Field(description=\"Dataset handler name\")\n    ds_params: dict[str, Any] | None = Field(default_factory=dict, description=\"Dataset parameters\")\n    sampling_rate: int = Field(250, description=\"Target sampling rate (Hz)\")\n    frame_size: int = Field(1250, description=\"Frame size\")\n    num_classes: int = Field(2, description=\"# of classes\")\n    samples_per_subject: int | list[int] = Field(100, description=\"# test samples per subject\")\n    test_subjects: float | None = Field(None, description=\"# or proportion of subjects for testing\")\n    test_size: int = Field(20_000, description=\"# samples for testing\")\n    model_file: str | None = Field(None, description=\"Path to model file\")\n    threshold: float | None = Field(None, description=\"Model output threshold\")\n    val_acc_threshold: float | None = Field(0.98, description=\"Validation accuracy threshold\")\n    use_logits: bool = Field(True, description=\"Use logits output or softmax\")\n    quantization: bool | None = Field(None, description=\"Enable post training quantization (PQT)\")\n    tflm_var_name: str = Field(\"g_model\", description=\"TFLite Micro C variable name\")\n    tflm_file: Path | None = Field(None, description=\"Path to copy TFLM header file (e.g. ./model_buffer.h)\")\n    data_parallelism: int = Field(\n        default_factory=lambda: os.cpu_count() or 1,\n        description=\"# of data loaders running in parallel\",\n    )\n    model_config = ConfigDict(protected_namespaces=())\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKFeatureParams","title":"<code>SKFeatureParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>SleepKit feature command params</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKFeatureParams(BaseModel, extra=\"allow\"):\n    \"\"\"SleepKit feature command params\"\"\"\n\n    job_dir: Path = Field(default_factory=tempfile.gettempdir, description=\"Job output directory\")\n    ds_path: Path = Field(default_factory=Path, description=\"Dataset base directory\")\n    datasets: list[str] = Field(default_factory=list, description=\"Dataset names\")\n    feature_set: str = Field(description=\"Feature set name\")\n    feature_params: dict[str, Any] | None = Field(default=None, description=\"Custom feature parameters\")\n    save_path: Path = Field(default_factory=Path, description=\"Save directory\")\n    sampling_rate: float = Field(250, description=\"Target sampling rate (Hz)\")\n    frame_size: int = Field(1250, description=\"Frame size\")\n    data_parallelism: int = Field(\n        default_factory=lambda: os.cpu_count() or 1,\n        description=\"# of data loaders running in parallel\",\n    )\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKMode","title":"<code>SKMode</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>SleepKit Mode</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKMode(StrEnum):\n    \"\"\"SleepKit Mode\"\"\"\n\n    download = \"download\"\n    feature = \"feature\"\n    train = \"train\"\n    evaluate = \"evaluate\"\n    export = \"export\"\n    demo = \"demo\"\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKTask","title":"<code>SKTask</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>SleepKit task</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKTask(StrEnum):\n    \"\"\"SleepKit task\"\"\"\n\n    detect = \"detect\"\n    stage = \"stage\"\n    apnea = \"apnea\"\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKTestParams","title":"<code>SKTestParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>SleepKit test command params</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKTestParams(BaseModel, extra=\"allow\"):\n    \"\"\"SleepKit test command params\"\"\"\n\n    job_dir: Path = Field(default_factory=tempfile.gettempdir, description=\"Job output directory\")\n    # Dataset arguments\n    ds_path: Path = Field(default_factory=Path, description=\"Dataset base directory\")\n    ds_handler: str = Field(description=\"Dataset handler name\")\n    ds_params: dict[str, Any] | None = Field(default_factory=dict, description=\"Dataset parameters\")\n    sampling_rate: float = Field(250, description=\"Target sampling rate (Hz)\")\n    frame_size: int = Field(1250, description=\"Frame size\")\n    num_classes: int = Field(2, description=\"# of classes\")\n    test_subjects: float | None = Field(None, description=\"# or proportion of subjects for testing\")\n    test_size: int = Field(20_000, description=\"# samples for testing\")\n    data_parallelism: int = Field(\n        default_factory=lambda: os.cpu_count() or 1,\n        description=\"# of data loaders running in parallel\",\n    )\n    # Model arguments\n    model_file: str | None = Field(None, description=\"Path to model file\")\n    # Extra arguments\n    seed: int | None = Field(None, description=\"Random state seed\")\n    model_config = ConfigDict(protected_namespaces=())\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.defines.SKTrainParams","title":"<code>SKTrainParams</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>SleepKit train command params</p> Source code in <code>sleepkit/defines.py</code> <pre><code>class SKTrainParams(BaseModel, extra=\"allow\"):\n    \"\"\"SleepKit train command params\"\"\"\n\n    job_dir: Path = Field(default_factory=tempfile.gettempdir, description=\"Job output directory\")\n    # Dataset arguments\n    ds_path: Path = Field(default_factory=Path, description=\"Dataset base directory\")\n    ds_handler: str = Field(description=\"Dataset handler name\")\n    ds_params: dict[str, Any] | None = Field(default_factory=dict, description=\"Dataset parameters\")\n    sampling_rate: float = Field(250, description=\"Target sampling rate (Hz)\")\n    frame_size: int = Field(1250, description=\"Frame size\")\n    num_classes: int = Field(2, description=\"# of classes\")\n    samples_per_subject: int | list[int] = Field(1000, description=\"# train samples per subject\")\n    val_samples_per_subject: int | list[int] = Field(1000, description=\"# validation samples per subject\")\n    train_subjects: float | None = Field(None, description=\"# or proportion of subjects for training\")\n    val_subjects: float | None = Field(None, description=\"# or proportion of subjects for validation\")\n    val_file: Path | None = Field(None, description=\"Path to load/store pickled validation file\")\n    val_size: int | None = Field(None, description=\"# samples for validation\")\n    data_parallelism: int = Field(\n        default_factory=lambda: os.cpu_count() or 1,\n        description=\"# of data loaders running in parallel\",\n    )\n    # Model arguments\n    model: str | None = Field(default=None, description=\"Custom model\")\n    model_file: str | None = Field(None, description=\"Path to model file\")\n    model_params: dict[str, Any] | None = Field(default=None, description=\"Custom model parameters\")\n\n    weights_file: Path | None = Field(None, description=\"Path to a checkpoint weights to load\")\n    quantization: bool | None = Field(None, description=\"Enable quantization aware training (QAT)\")\n    # Training arguments\n    batch_size: int = Field(32, description=\"Batch size\")\n    buffer_size: int = Field(100, description=\"Buffer size\")\n    epochs: int = Field(50, description=\"Number of epochs\")\n    steps_per_epoch: int | None = Field(None, description=\"Number of steps per epoch\")\n    val_metric: Literal[\"loss\", \"acc\", \"f1\"] = Field(\"loss\", description=\"Performance metric\")\n    # augmentations: list[AugmentationParams] = Field(default_factory=list, description=\"Augmentations\")\n    # Extra arguments\n    seed: int | None = Field(None, description=\"Random state seed\")\n    model_config = ConfigDict(protected_namespaces=())\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.features","title":"<code>sleepkit.features</code>","text":""},{"location":"api/sleepkit/#sleepkit.metrics","title":"<code>sleepkit.metrics</code>","text":""},{"location":"api/sleepkit/#sleepkit.metrics.compute_iou","title":"<code>compute_iou(y_true, y_pred, average='micro')</code>","text":"<p>Compute IoU</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code>NDArray</code>)         \u2013          <p>Y true</p> </li> <li> <code>y_pred</code>             (<code>NDArray</code>)         \u2013          <p>Y predicted</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code> (            <code>float</code> )        \u2013          <p>IoU</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def compute_iou(\n    y_true: npt.NDArray,\n    y_pred: npt.NDArray,\n    average: Literal[\"micro\", \"macro\", \"weighted\"] = \"micro\",\n) -&gt; float:\n    \"\"\"Compute IoU\n\n    Args:\n        y_true (npt.NDArray): Y true\n        y_pred (npt.NDArray): Y predicted\n\n    Returns:\n        float: IoU\n    \"\"\"\n    return jaccard_score(y_true.flatten(), y_pred.flatten(), average=average)\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.metrics.confusion_matrix_plot","title":"<code>confusion_matrix_plot(y_true, y_pred, labels, save_path=None, normalize=False, **kwargs)</code>","text":"<p>Generate confusion matrix plot via matplotlib/seaborn</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code>NDArray</code>)         \u2013          <p>True y labels</p> </li> <li> <code>y_pred</code>             (<code>NDArray</code>)         \u2013          <p>Predicted y labels</p> </li> <li> <code>labels</code>             (<code>list[str]</code>)         \u2013          <p>Label names</p> </li> <li> <code>save_path</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Path to save plot. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Figure, Axes] | None</code>         \u2013          <p>tuple[plt.Figure, plt.Axes] | None: Figure and axes</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def confusion_matrix_plot(\n    y_true: npt.NDArray,\n    y_pred: npt.NDArray,\n    labels: list[str],\n    save_path: str | None = None,\n    normalize: Literal[\"true\", \"pred\", \"all\"] | None = False,\n    **kwargs,\n) -&gt; tuple[plt.Figure, plt.Axes] | None:\n    \"\"\"Generate confusion matrix plot via matplotlib/seaborn\n\n    Args:\n        y_true (npt.NDArray): True y labels\n        y_pred (npt.NDArray): Predicted y labels\n        labels (list[str]): Label names\n        save_path (str | None): Path to save plot. Defaults to None.\n\n    Returns:\n        tuple[plt.Figure, plt.Axes] | None: Figure and axes\n    \"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    cmn = cm\n    ann = True\n    fmt = \"g\"\n    if normalize:\n        cmn = confusion_matrix(y_true, y_pred, normalize=normalize)\n        ann = np.asarray([f\"{c:g}{os.linesep}{nc:.2%}\" for c, nc in zip(cm.flatten(), cmn.flatten())]).reshape(cm.shape)\n        fmt = \"\"\n    # END IF\n    fig, ax = plt.subplots(figsize=kwargs.get(\"figsize\", (10, 8)))\n    sns.heatmap(cmn, xticklabels=labels, yticklabels=labels, annot=ann, fmt=fmt, ax=ax, vmin=0, vmax=0.9)\n    ax.set_xlabel(\"Prediction\")\n    ax.set_ylabel(\"Label\")\n    if save_path:\n        fig.savefig(save_path, bbox_inches=\"tight\")\n        plt.close(fig)\n        return None\n    return fig, ax\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.metrics.f1","title":"<code>f1(y_true, y_prob, multiclass=False, threshold=None)</code>","text":"<p>Compute F1 scores</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code> npt.NDArray</code>)         \u2013          <p>Y true</p> </li> <li> <code>y_prob</code>             (<code> npt.NDArray</code>)         \u2013          <p>2D matrix with class probs</p> </li> <li> <code>multiclass</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>If multiclass. Defaults to False.</p> </li> <li> <code>threshold</code>             (<code>float</code>, default:                 <code>None</code> )         \u2013          <p>Decision threshold for multiclass. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray | float</code>         \u2013          <p>npt.NDArray|float: F1 scores</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def f1(\n    y_true: npt.NDArray,\n    y_prob: npt.NDArray,\n    multiclass: bool = False,\n    threshold: float = None,\n) -&gt; npt.NDArray | float:\n    \"\"\"Compute F1 scores\n\n    Args:\n        y_true ( npt.NDArray): Y true\n        y_prob ( npt.NDArray): 2D matrix with class probs\n        multiclass (bool, optional): If multiclass. Defaults to False.\n        threshold (float, optional): Decision threshold for multiclass. Defaults to None.\n\n    Returns:\n        npt.NDArray|float: F1 scores\n    \"\"\"\n    if y_prob.ndim != 2:\n        raise ValueError(\"y_prob must be a 2d matrix with class probabilities for each sample\")\n    if y_true.ndim == 1:  # we assume that y_true is sparse (consequently, multiclass=False)\n        if multiclass:\n            raise ValueError(\"if y_true cannot be sparse and multiclass at the same time\")\n        depth = y_prob.shape[1]\n        y_true = _one_hot(y_true, depth)\n    if multiclass:\n        if threshold is None:\n            threshold = 0.5\n        y_pred = y_prob &gt;= threshold\n    else:\n        y_pred = y_prob &gt;= np.max(y_prob, axis=1)[:, None]\n    return f1_score(y_true, y_pred, average=\"macro\")\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.metrics.f_max","title":"<code>f_max(y_true, y_prob, thresholds=None)</code>","text":"<p>Compute F max (https://github.com/helme/ecg_ptbxl_benchmarking)</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code>NDArray</code>)         \u2013          <p>Y True</p> </li> <li> <code>y_prob</code>             (<code>NDArray</code>)         \u2013          <p>Y probs</p> </li> <li> <code>thresholds</code>             (<code>float | list[float] | None</code>, default:                 <code>None</code> )         \u2013          <p>Thresholds. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[float, float]</code>         \u2013          <p>tuple[float, float]: F1 and thresholds</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def f_max(\n    y_true: npt.NDArray,\n    y_prob: npt.NDArray,\n    thresholds: float | list[float] | None = None,\n) -&gt; tuple[float, float]:\n    \"\"\"Compute F max (https://github.com/helme/ecg_ptbxl_benchmarking)\n\n    Args:\n        y_true (npt.NDArray): Y True\n        y_prob (npt.NDArray): Y probs\n        thresholds (float|list[float]|None, optional): Thresholds. Defaults to None.\n\n    Returns:\n        tuple[float, float]: F1 and thresholds\n    \"\"\"\n    if thresholds is None:\n        thresholds = np.linspace(0, 1, 100)\n    pr, rc = macro_precision_recall(y_true, y_prob, thresholds)\n    f1s = (2 * pr * rc) / (pr + rc)\n    i = np.nanargmax(f1s)\n    return f1s[i], thresholds[i]\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.metrics.macro_precision_recall","title":"<code>macro_precision_recall(y_true, y_prob, thresholds)</code>","text":"<p>Compute macro precision and recall source: https://github.com/helme/ecg_ptbxl_benchmarking</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code>NDArray</code>)         \u2013          <p>True y labels</p> </li> <li> <code>y_prob</code>             (<code>NDArray</code>)         \u2013          <p>Predicted y labels</p> </li> <li> <code>thresholds</code>             (<code>NDArray</code>)         \u2013          <p>Thresholds</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[float_, float_]</code>         \u2013          <p>tuple[np.float_, np.float_]: Precision and recall</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def macro_precision_recall(\n    y_true: npt.NDArray, y_prob: npt.NDArray, thresholds: npt.NDArray\n) -&gt; tuple[np.float_, np.float_]:\n    \"\"\"Compute macro precision and recall\n    source: https://github.com/helme/ecg_ptbxl_benchmarking\n\n    Args:\n        y_true (npt.NDArray): True y labels\n        y_prob (npt.NDArray): Predicted y labels\n        thresholds (npt.NDArray): Thresholds\n\n    Returns:\n       tuple[np.float_, np.float_]: Precision and recall\n    \"\"\"\n\n    # expand analysis to the number of thresholds\n    y_true = np.repeat(y_true[None, :, :], len(thresholds), axis=0)\n    y_prob = np.repeat(y_prob[None, :, :], len(thresholds), axis=0)\n    y_pred = y_prob &gt;= thresholds[:, None, None]\n\n    # compute true positives\n    tp = np.sum(np.logical_and(y_true, y_pred), axis=2)\n\n    # compute macro average precision handling all warnings\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        den = np.sum(y_pred, axis=2)\n        precision = tp / den\n        precision[den == 0] = np.nan\n        with warnings.catch_warnings():  # for nan slices\n            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n            av_precision = np.nanmean(precision, axis=1)\n\n    # compute macro average recall\n    recall = tp / np.sum(y_true, axis=2)\n    av_recall = np.mean(recall, axis=1)\n\n    return av_precision, av_recall\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.metrics.multi_f1","title":"<code>multi_f1(y_true, y_prob)</code>","text":"<p>Compute multi-class F1</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code>NDArray</code>)         \u2013          <p>True y labels</p> </li> <li> <code>y_prob</code>             (<code>NDArray</code>)         \u2013          <p>Predicted y labels</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>NDArray</code>         \u2013          <p>npt.NDArray|float: F1 score</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def multi_f1(y_true: npt.NDArray, y_prob: npt.NDArray) -&gt; npt.NDArray:\n    \"\"\"Compute multi-class F1\n\n    Args:\n        y_true (npt.NDArray): True y labels\n        y_prob (npt.NDArray): Predicted y labels\n\n    Returns:\n        npt.NDArray|float: F1 score\n    \"\"\"\n    return f1(y_true, y_prob, multiclass=True, threshold=0.5)\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.metrics.roc_auc_plot","title":"<code>roc_auc_plot(y_true, y_prob, labels, save_path=None, **kwargs)</code>","text":"<p>Generate ROC plot via matplotlib/seaborn</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>             (<code>NDArray</code>)         \u2013          <p>True y labels</p> </li> <li> <code>y_prob</code>             (<code>NDArray</code>)         \u2013          <p>Predicted y labels</p> </li> <li> <code>labels</code>             (<code>list[str]</code>)         \u2013          <p>Label names</p> </li> <li> <code>save_path</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Path to save plot. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Figure, Axes] | None</code>         \u2013          <p>tuple[plt.Figure, plt.Axes] | None: Figure and axes</p> </li> </ul> Source code in <code>sleepkit/metrics.py</code> <pre><code>def roc_auc_plot(\n    y_true: npt.NDArray,\n    y_prob: npt.NDArray,\n    labels: list[str],\n    save_path: str | None = None,\n    **kwargs,\n) -&gt; tuple[plt.Figure, plt.Axes] | None:\n    \"\"\"Generate ROC plot via matplotlib/seaborn\n\n    Args:\n        y_true (npt.NDArray): True y labels\n        y_prob (npt.NDArray): Predicted y labels\n        labels (list[str]): Label names\n        save_path (str | None): Path to save plot. Defaults to None.\n\n    Returns:\n        tuple[plt.Figure, plt.Axes] | None: Figure and axes\n    \"\"\"\n\n    fpr, tpr, _ = roc_curve(y_true, y_prob)\n    roc_auc = auc(fpr, tpr)\n    fig, ax = plt.subplots(figsize=kwargs.get(\"figsize\", (10, 8)))\n    label = f\"ROC curve (area = {roc_auc:0.2f})\"\n    ax.plot(fpr, tpr, lw=2, color=\"darkorange\", label=label)\n    ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n    ax.set_xlim([0.0, 1.0])\n    ax.set_ylim([0.0, 1.05])\n    ax.set_xlabel(\"False Positive Rate\")\n    ax.set_ylabel(\"True Positive Rate\")\n    ax.set_title(\"ROC-AUC\")\n    fig.legend(loc=\"lower right\")\n    if save_path:\n        fig.savefig(save_path)\n        plt.close(fig)\n        return None\n    return fig, ax\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.utils","title":"<code>sleepkit.utils</code>","text":""},{"location":"api/sleepkit/#sleepkit.utils.download_file","title":"<code>download_file(src, dst, progress=True)</code>","text":"<p>Download file from supplied url to destination streaming.</p> <p>Parameters:</p> <ul> <li> <code>src</code>             (<code>str</code>)         \u2013          <p>Source URL path</p> </li> <li> <code>dst</code>             (<code>PathLike</code>)         \u2013          <p>Destination file path</p> </li> <li> <code>progress</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Display progress bar. Defaults to True.</p> </li> </ul> Source code in <code>sleepkit/utils.py</code> <pre><code>def download_file(src: str, dst: os.PathLike, progress: bool = True):\n    \"\"\"Download file from supplied url to destination streaming.\n\n    Args:\n        src (str): Source URL path\n        dst (PathLike): Destination file path\n        progress (bool, optional): Display progress bar. Defaults to True.\n\n    \"\"\"\n    with requests.get(src, stream=True, timeout=3600 * 24) as r:\n        r.raise_for_status()\n        req_len = int(r.headers.get(\"Content-length\", 0))\n        prog_bar = tqdm(total=req_len, unit=\"iB\", unit_scale=True) if progress else None\n        with open(dst, \"wb\") as f:\n            for chunk in r.iter_content(chunk_size=8192):\n                f.write(chunk)\n                if prog_bar:\n                    prog_bar.update(len(chunk))\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.utils.env_flag","title":"<code>env_flag(env_var, default=False)</code>","text":"<p>Return the specified environment variable coerced to a bool, as follows: - When the variable is unset, or set to the empty string, return <code>default</code>. - When the variable is set to a truthy value, returns <code>True</code>.   These are the truthy values:       - 1       - true, yes, on - When the variable is set to the anything else, returns False.    Example falsy values:       - 0       - no - Ignore case and leading/trailing whitespace.</p> <p>Parameters:</p> <ul> <li> <code>env_var</code>             (<code>str</code>)         \u2013          <p>Environment variable name</p> </li> <li> <code>default</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Default value. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code> (            <code>bool</code> )        \u2013          <p>Value of environment variable</p> </li> </ul> Source code in <code>sleepkit/utils.py</code> <pre><code>def env_flag(env_var: str, default: bool = False) -&gt; bool:\n    \"\"\"Return the specified environment variable coerced to a bool, as follows:\n    - When the variable is unset, or set to the empty string, return `default`.\n    - When the variable is set to a truthy value, returns `True`.\n      These are the truthy values:\n          - 1\n          - true, yes, on\n    - When the variable is set to the anything else, returns False.\n       Example falsy values:\n          - 0\n          - no\n    - Ignore case and leading/trailing whitespace.\n\n    Args:\n        env_var (str): Environment variable name\n        default (bool, optional): Default value. Defaults to False.\n\n    Returns:\n        bool: Value of environment variable\n    \"\"\"\n    environ_string = os.environ.get(env_var, \"\").strip().lower()\n    if not environ_string:\n        return default\n    return environ_string in [\"1\", \"true\", \"yes\", \"on\"]\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.utils.load_pkl","title":"<code>load_pkl(file, compress=True)</code>","text":"<p>Load pickled file.</p> <p>Parameters:</p> <ul> <li> <code>file</code>             (<code>str</code>)         \u2013          <p>File path (.pkl)</p> </li> <li> <code>compress</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>If file is compressed. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[str, Any]</code>         \u2013          <p>dict[str, Any]: Dictionary of pickled objects</p> </li> </ul> Source code in <code>sleepkit/utils.py</code> <pre><code>def load_pkl(file: str, compress: bool = True) -&gt; dict[str, Any]:\n    \"\"\"Load pickled file.\n\n    Args:\n        file (str): File path (.pkl)\n        compress (bool, optional): If file is compressed. Defaults to True.\n\n    Returns:\n        dict[str, Any]: Dictionary of pickled objects\n    \"\"\"\n    if compress:\n        with gzip.open(file, \"rb\") as fh:\n            return pickle.load(fh)\n    else:\n        with open(file, \"rb\") as fh:\n            return pickle.load(fh)\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.utils.save_pkl","title":"<code>save_pkl(file, compress=True, **kwargs)</code>","text":"<p>Save python objects into pickle file.</p> <p>Parameters:</p> <ul> <li> <code>file</code>             (<code>str</code>)         \u2013          <p>File path (.pkl)</p> </li> <li> <code>compress</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Whether to compress file. Defaults to True.</p> </li> </ul> Source code in <code>sleepkit/utils.py</code> <pre><code>def save_pkl(file: str, compress: bool = True, **kwargs):\n    \"\"\"Save python objects into pickle file.\n\n    Args:\n        file (str): File path (.pkl)\n        compress (bool, optional): Whether to compress file. Defaults to True.\n    \"\"\"\n    if compress:\n        with gzip.open(file, \"wb\") as fh:\n            pickle.dump(kwargs, fh, protocol=4)\n    else:\n        with open(file, \"wb\") as fh:\n            pickle.dump(kwargs, fh, protocol=4)\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.utils.set_random_seed","title":"<code>set_random_seed(seed=None)</code>","text":"<p>Set random seed across libraries: TF, Numpy, Python</p> <p>Parameters:</p> <ul> <li> <code>seed</code>             (<code>int | None</code>, default:                 <code>None</code> )         \u2013          <p>Random seed state to use. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code> (            <code>int</code> )        \u2013          <p>Random seed</p> </li> </ul> Source code in <code>sleepkit/utils.py</code> <pre><code>def set_random_seed(seed: int | None = None) -&gt; int:\n    \"\"\"Set random seed across libraries: TF, Numpy, Python\n\n    Args:\n        seed (int | None, optional): Random seed state to use. Defaults to None.\n\n    Returns:\n        int: Random seed\n    \"\"\"\n    seed = seed or np.random.randint(2**16)\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    return seed\n</code></pre>"},{"location":"api/sleepkit/#sleepkit.utils.setup_logger","title":"<code>setup_logger(log_name)</code>","text":"<p>Setup logger with Rich</p> <p>Parameters:</p> <ul> <li> <code>log_name</code>             (<code>str</code>)         \u2013          <p>Logger name</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Logger</code>         \u2013          <p>logging.Logger: Logger</p> </li> </ul> Source code in <code>sleepkit/utils.py</code> <pre><code>def setup_logger(log_name: str) -&gt; logging.Logger:\n    \"\"\"Setup logger with Rich\n\n    Args:\n        log_name (str): Logger name\n\n    Returns:\n        logging.Logger: Logger\n    \"\"\"\n    logger = logging.getLogger(log_name)\n    if logger.handlers:\n        return logger\n    rich_handler = RichHandler()\n    logging.basicConfig(level=logging.ERROR, force=True, handlers=[rich_handler])\n    logger.propagate = False\n    logger.setLevel(logging.INFO)\n    logger.handlers = [rich_handler]\n    return logger\n</code></pre>"},{"location":"api/stage/","title":"Sleep Stage Classification","text":""},{"location":"api/stage/#sleepkit.stage","title":"<code>sleepkit.stage</code>","text":""},{"location":"api/stage/#sleepkit.stage.defines","title":"<code>sleepkit.stage.defines</code>","text":""},{"location":"api/stage/#sleepkit.stage.defines.SleepStage","title":"<code>SleepStage</code>","text":"<p>             Bases: <code>IntEnum</code></p> <p>Sleep stage class</p> Source code in <code>sleepkit/stage/defines.py</code> <pre><code>class SleepStage(IntEnum):\n    \"\"\"Sleep stage class\"\"\"\n\n    wake = 0\n    stage1 = 1\n    stage2 = 2\n    stage3 = 3\n    stage4 = 4\n    rem = 5\n    noise = 6\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.defines.SleepStageName","title":"<code>SleepStageName</code>","text":"<p>             Bases: <code>StrEnum</code></p> <p>Sleep stage name</p> Source code in <code>sleepkit/stage/defines.py</code> <pre><code>class SleepStageName(StrEnum):\n    \"\"\"Sleep stage name\"\"\"\n\n    wake = \"wake\"\n    stage1 = \"stage1\"\n    stage2 = \"stage2\"\n    stage3 = \"stage3\"\n    stage4 = \"stage4\"\n    rem = \"rem\"\n    noise = \"noise\"\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.defines.get_stage_class_mapping","title":"<code>get_stage_class_mapping(nstages)</code>","text":"<p>Get class mapping for sleep stage classification</p> <p>Parameters:</p> <ul> <li> <code>nstages</code>             (<code>int</code>)         \u2013          <p>Number of sleep stages</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, int]</code>         \u2013          <p>dict[int, int]: Class mapping</p> </li> </ul> Source code in <code>sleepkit/stage/defines.py</code> <pre><code>def get_stage_class_mapping(nstages: int) -&gt; dict[int, int]:\n    \"\"\"Get class mapping for sleep stage classification\n\n    Args:\n        nstages (int): Number of sleep stages\n\n    Returns:\n        dict[int, int]: Class mapping\n    \"\"\"\n    if nstages == 2:\n        return {\n            SleepStage.wake: 0,\n            SleepStage.stage1: 1,\n            SleepStage.stage2: 1,\n            SleepStage.stage3: 1,\n            SleepStage.stage4: 1,\n            SleepStage.rem: 1,\n        }\n    if nstages == 3:\n        return {\n            SleepStage.wake: 0,\n            SleepStage.stage1: 1,\n            SleepStage.stage2: 1,\n            SleepStage.stage3: 1,\n            SleepStage.stage4: 1,\n            SleepStage.rem: 2,\n        }\n    if nstages == 4:\n        return {\n            SleepStage.wake: 0,\n            SleepStage.stage1: 1,\n            SleepStage.stage2: 1,\n            SleepStage.stage3: 2,\n            SleepStage.stage4: 2,\n            SleepStage.rem: 3,\n        }\n    if nstages == 5:\n        return {\n            SleepStage.wake: 0,\n            SleepStage.stage1: 1,\n            SleepStage.stage2: 2,\n            SleepStage.stage3: 3,\n            SleepStage.stage4: 3,\n            SleepStage.rem: 4,\n        }\n    raise ValueError(f\"Invalid number of stages: {nstages}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.defines.get_stage_class_names","title":"<code>get_stage_class_names(nstages)</code>","text":"<p>Get class names for sleep stage classification</p> <p>Parameters:</p> <ul> <li> <code>nstages</code>             (<code>int</code>)         \u2013          <p>Number of sleep stages</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[str]</code>         \u2013          <p>list[str]: Class names</p> </li> </ul> Source code in <code>sleepkit/stage/defines.py</code> <pre><code>def get_stage_class_names(nstages: int) -&gt; list[str]:\n    \"\"\"Get class names for sleep stage classification\n\n    Args:\n        nstages (int): Number of sleep stages\n\n    Returns:\n        list[str]: Class names\n    \"\"\"\n    if nstages == 2:\n        return [\"WAKE\", \"SLEEP\"]\n    if nstages == 3:\n        return [\"WAKE\", \"NREM\", \"REM\"]\n    if nstages == 4:\n        return [\"WAKE\", \"CORE\", \"DEEP\", \"REM\"]\n    if nstages == 5:\n        return [\"WAKE\", \"N1\", \"N2\", \"N3\", \"REM\"]\n    raise ValueError(f\"Invalid number of stages: {nstages}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.defines.get_stage_classes","title":"<code>get_stage_classes(nstages)</code>","text":"<p>Get target classes for sleep stage classification</p> <p>Parameters:</p> <ul> <li> <code>nstages</code>             (<code>int</code>)         \u2013          <p>Number of sleep stages</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[int]</code>         \u2013          <p>list[int]: Target classes</p> </li> </ul> Source code in <code>sleepkit/stage/defines.py</code> <pre><code>def get_stage_classes(nstages: int) -&gt; list[int]:\n    \"\"\"Get target classes for sleep stage classification\n\n    Args:\n        nstages (int): Number of sleep stages\n\n    Returns:\n        list[int]: Target classes\n    \"\"\"\n    if 2 &lt;= nstages &lt;= 5:\n        return list(range(nstages))\n    raise ValueError(f\"Invalid number of stages: {nstages}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.demo","title":"<code>sleepkit.stage.demo</code>","text":""},{"location":"api/stage/#sleepkit.stage.demo.demo","title":"<code>demo(params)</code>","text":"<p>Run sleep stage classification demo.</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>SKDemoParams</code>)         \u2013          <p>Demo parameters</p> </li> </ul> Source code in <code>sleepkit/stage/demo.py</code> <pre><code>def demo(params: SKDemoParams):\n    \"\"\"Run sleep stage classification demo.\n\n    Args:\n        params (SKDemoParams): Demo parameters\n    \"\"\"\n    bg_color = \"rgba(38,42,50,1.0)\"\n    plotly_template = \"plotly_dark\"\n\n    sleep_classes = get_stage_classes(params.num_classes)\n    class_names = get_stage_class_names(params.num_classes)\n    class_mapping = get_stage_class_mapping(params.num_classes)\n    class_colors = get_stage_color_map(params.num_classes)\n\n    logger.info(\"Setting up\")\n\n    BackendRunner = EvbBackend if params.backend == \"evb\" else PcBackend\n    runner = BackendRunner(params=params)\n\n    runner.open()\n\n    # Load data handler\n    ds = load_dataset(\n        handler=params.ds_handler, ds_path=params.ds_path, frame_size=params.frame_size, params=params.ds_params\n    )\n\n    # Load entire subject's features\n    subject_id = random.choice(ds.subject_ids)\n    logger.info(f\"Loading subject {subject_id} data\")\n    features, _, _ = ds.load_subject_data(subject_id=subject_id, normalize=False)\n    x, y_true, y_mask = ds.load_subject_data(subject_id=subject_id, normalize=True)\n    y_true = np.vectorize(class_mapping.get)(y_true)\n\n    # Run inference\n    logger.info(\"Running inference\")\n    y_pred = np.zeros_like(y_true)\n    for i in tqdm(range(0, x.shape[0], params.frame_size), desc=\"Inference\"):\n        if i + params.frame_size &gt; x.shape[0]:\n            start, stop = x.shape[0] - params.frame_size, x.shape[0]\n        else:\n            start, stop = i, i + params.frame_size\n        runner.set_inputs(x[start:stop, :])\n        runner.perform_inference()\n        yy = runner.get_outputs()\n        y_pred[start:stop] = np.argmax(yy, axis=-1).flatten()\n    # END FOR\n\n    # Mask out bad data\n    y_pred = y_pred[y_mask == 1]\n    y_true = y_true[y_mask == 1]\n\n    tod = datetime.datetime(2025, 5, 24, random.randint(12, 23), 00)\n    ts = [tod + datetime.timedelta(seconds=30 * i) for i in range(y_pred.size)]\n\n    # Report\n    logger.info(\"Generating report\")\n    fig = make_subplots(\n        rows=2,\n        cols=2,\n        specs=[\n            [{\"colspan\": 2, \"type\": \"xy\", \"secondary_y\": True}, None],\n            [{\"type\": \"domain\"}, {\"type\": \"bar\"}],\n        ],\n        subplot_titles=(None, None),\n        horizontal_spacing=0.05,\n        vertical_spacing=0.1,\n    )\n\n    pred_sleep_durations = compute_sleep_stage_durations(y_pred)\n    class_durations = [30 * pred_sleep_durations.get(c, 0) / 60 for c in sleep_classes]\n    # pred_sleep_eff = compute_sleep_efficiency(pred_sleep_durations, class_mapping)\n\n    # Sleep Stage Plot\n    sleep_bounds = np.concatenate(([0], np.diff(y_pred).nonzero()[0] + 1))\n    legend_groups = set()\n    for i in range(1, len(sleep_bounds)):\n        start, stop = sleep_bounds[i - 1], sleep_bounds[i]\n        label = y_pred[start]\n        name = class_names[label]\n        color = class_colors.get(label, None)\n        fig.add_trace(\n            go.Scatter(\n                x=[ts[start], ts[stop]],\n                y=[label, label],\n                mode=\"lines\",\n                line_shape=\"hv\",\n                name=name,\n                legendgroup=name,\n                showlegend=name not in legend_groups,\n                line_color=color,\n                line_width=4,\n                fill=\"tozeroy\",\n                opacity=0.7,\n            ),\n            row=1,\n            col=1,\n        )\n        # END IF\n        legend_groups.add(name)\n    # END FOR\n\n    fig.update_yaxes(\n        autorange=False,\n        range=[max(sleep_classes) + 0.25, min(sleep_classes) - 0.25],\n        ticktext=class_names,\n        tickvals=list(range(len(class_names))),\n        row=1,\n        col=1,\n        secondary_y=False,\n    )\n\n    # Data Plot\n    for f in range(features.shape[1]):\n        name = f\"FEAT{f+1}\"\n        feat_y = np.where(y_mask == 1, features[:, f], np.nan)\n        fig.add_trace(\n            go.Scatter(\n                x=ts,\n                y=feat_y,\n                name=name,\n                opacity=0.5,\n                legendgroup=\"Features\",\n                legendgrouptitle_text=\"Features\",\n                visible=\"legendonly\",\n            ),\n            row=1,\n            col=1,\n            secondary_y=True,\n        )\n    # END FOR\n\n    # Cycle Plot | Efficiency Plot\n    fig.add_trace(\n        go.Pie(\n            name=\"\",\n            labels=class_names,\n            values=[pred_sleep_durations.get(c, 0) for c in sleep_classes],\n            textinfo=\"label+percent\",\n            # texttemplate = \"%{label}: %{percent}\",\n            textfont_size=15,\n            hole=0.3,\n            hoverinfo=\"none\",  # \"label+percent\",\n            showlegend=False,\n            marker_colors=[class_colors.get(c, None) for c in sleep_classes],\n        ),\n        row=2,\n        col=1,\n    )\n\n    fig.add_trace(\n        go.Bar(\n            x=class_durations,\n            y=class_names,\n            marker_color=[class_colors.get(c, \"red\") for c in sleep_classes],\n            showlegend=False,\n            text=[f\"{t:0.0f} min\" for t in class_durations],\n            textposition=\"auto\",\n            hoverinfo=\"none\",\n            # hovertemplate=\"%{y}: %{x:0.2}H\",\n            orientation=\"h\",\n            name=\"\",\n        ),\n        row=2,\n        col=2,\n    )\n\n    fig.update_xaxes(title=\"Duration (min)\", row=2, col=2)\n\n    fig.update_layout(\n        template=plotly_template,\n        height=800,\n        plot_bgcolor=bg_color,\n        paper_bgcolor=bg_color,\n        margin=dict(l=10, r=10, t=40, b=20),\n        legend=dict(groupclick=\"toggleitem\"),\n        title=f\"Sleep {'Detect' if params.num_classes else 'Stage'} Demo (subject {subject_id})\",\n    )\n    fig.write_html(params.job_dir / \"demo.html\", include_plotlyjs=\"cdn\", full_html=False)\n    fig.show()\n\n    runner.close()\n\n    logger.info(f\"Report saved to {params.job_dir / 'demo.html'}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.demo.get_stage_color_map","title":"<code>get_stage_color_map(num_classes)</code>","text":"<p>Get color map for sleep stages</p> <p>Parameters:</p> <ul> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          <p>Number of sleep stages</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, str]</code>         \u2013          <p>dict[int, str]: Color map</p> </li> </ul> Source code in <code>sleepkit/stage/demo.py</code> <pre><code>def get_stage_color_map(num_classes) -&gt; dict[int, str]:\n    \"\"\"Get color map for sleep stages\n\n    Args:\n        num_classes (int): Number of sleep stages\n\n    Returns:\n        dict[int, str]: Color map\n    \"\"\"\n    gray, blue, navy, purple, red = \"gray\", \"#11acd5\", \"#1f1054\", \"#ce6cff\", \"#d62728\"\n    if num_classes == 2:\n        return {0: gray, 1: blue}\n    if num_classes == 3:\n        return {0: gray, 1: blue, 2: red}\n    if num_classes == 4:\n        return {0: gray, 1: blue, 2: purple, 3: red}\n    if num_classes == 5:\n        return {0: gray, 1: navy, 2: blue, 3: purple, 4: red}\n    raise ValueError(\"Invalid number of classes\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.evaluate","title":"<code>sleepkit.stage.evaluate</code>","text":"<p>Sleep Stage Evaluation</p>"},{"location":"api/stage/#sleepkit.stage.evaluate.evaluate","title":"<code>evaluate(params)</code>","text":"<p>Evaluate sleep stage model.</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>SKTestParams</code>)         \u2013          <p>Testing/evaluation parameters</p> </li> </ul> Source code in <code>sleepkit/stage/evaluate.py</code> <pre><code>def evaluate(params: SKTestParams):\n    \"\"\"Evaluate sleep stage model.\n\n    Args:\n        params (SKTestParams): Testing/evaluation parameters\n    \"\"\"\n    params.seed = set_random_seed(params.seed)\n\n    logger.info(f\"Creating working directory in {params.job_dir}\")\n    os.makedirs(params.job_dir, exist_ok=True)\n\n    handler = logging.FileHandler(params.job_dir / \"test.log\", mode=\"w\")\n    handler.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    logger.info(f\"Random seed {params.seed}\")\n\n    class_names = get_stage_class_names(params.num_classes)\n    class_mapping = get_stage_class_mapping(params.num_classes)\n\n    ds = load_dataset(\n        handler=params.ds_handler, ds_path=params.ds_path, frame_size=params.frame_size, params=params.ds_params\n    )\n    test_true, test_pred, test_prob = [], [], []\n    pt_metrics = []\n\n    strategy = tfa.get_strategy()\n    with strategy.scope(), tfmot.quantization.keras.quantize_scope():\n        logger.info(\"Loading model\")\n        model = tfa.load_model(params.model_file, custom_objects={\"MultiF1Score\": tfa.MultiF1Score})\n        flops = tfa.get_flops(model, batch_size=1, fpath=params.job_dir / \"model_flops.log\")\n        model.summary(print_fn=logger.info)\n        logger.info(f\"Model requires {flops/1e6:0.2f} MFLOPS\")\n\n        logger.info(\"Performing full inference\")\n        for subject_id in tqdm(ds.test_subject_ids, desc=\"Subject\"):\n            features, labels, mask = ds.load_subject_data(subject_id=subject_id, normalize=True)\n            num_windows = int(features.shape[0] // params.frame_size)\n            data_len = params.frame_size * num_windows\n\n            x = features[:data_len, :].reshape((num_windows, params.frame_size) + ds.feature_shape[1:])\n            m = mask[:data_len].reshape((num_windows, params.frame_size))\n            # m[:, :64] = 0 # Ignore first N samples\n            y_prob = tf.nn.softmax(model.predict(x, verbose=0)).numpy()\n            y_pred = np.argmax(y_prob, axis=-1).flatten()\n            y_prob = y_prob.reshape((-1, y_prob.shape[-1]))\n            # y_mask = mask[:data_len].flatten()\n            y_mask = m.flatten()\n            y_true = np.vectorize(class_mapping.get)(labels[:data_len].flatten())\n            y_pred = y_pred[y_mask == 1]\n            y_true = y_true[y_mask == 1]\n            y_prob = y_prob[y_mask == 1]\n\n            # Get subject specific metrics\n            pred_sleep_durations = compute_sleep_stage_durations(y_pred)\n            pred_sleep_tst = compute_total_sleep_time(pred_sleep_durations, class_mapping)\n            pred_sleep_eff = compute_sleep_efficiency(pred_sleep_durations, class_mapping)\n            act_sleep_duration = compute_sleep_stage_durations(y_true)\n            act_sleep_tst = compute_total_sleep_time(act_sleep_duration, class_mapping)\n            act_sleep_eff = compute_sleep_efficiency(act_sleep_duration, class_mapping)\n            pt_acc = np.sum(y_pred == y_true) / y_true.size\n            pt_metrics.append([subject_id, pt_acc, act_sleep_eff, pred_sleep_eff, act_sleep_tst, pred_sleep_tst])\n            test_true.append(y_true)\n            test_pred.append(y_pred)\n            test_prob.append(y_prob)\n        # END FOR\n        test_true = np.concatenate(test_true)\n        test_pred = np.concatenate(test_pred)\n        test_prob = np.vstack(test_prob)\n\n        df_metrics = pd.DataFrame(pt_metrics, columns=[\"subject\", \"acc\", \"act_eff\", \"pred_eff\", \"act_tst\", \"pred_tst\"])\n        df_metrics.to_csv(params.job_dir / \"metrics.csv\", header=True, index=False)\n\n        df_results = pd.DataFrame(dict(y_true=test_true, y_pred=test_pred))\n        df_results.to_csv(params.job_dir / \"results.csv\", header=True, index=False)\n\n        confusion_matrix_plot(\n            y_true=test_true,\n            y_pred=test_pred,\n            labels=class_names,\n            save_path=params.job_dir / \"confusion_matrix_test.png\",\n            normalize=\"true\",\n        )\n\n        # Summarize results\n        logger.info(\"Testing Results\")\n        test_acc = np.sum(test_pred == test_true) / test_true.size\n        test_f1 = f1_score(y_true=test_true, y_pred=test_pred, average=\"weighted\")\n        y_scores = test_prob[:, 1] if params.num_classes == 2 else test_prob\n        test_ap = sklearn.metrics.average_precision_score(y_true=test_true, y_score=y_scores, average=\"weighted\")\n        test_iou = compute_iou(test_true, test_pred, average=\"weighted\")\n        logger.info(f\"[TEST SET] ACC={test_acc:.2%}, F1={test_f1:.2%}, AP={test_ap:0.2%}, IoU={test_iou:0.2%}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.export","title":"<code>sleepkit.stage.export</code>","text":"<p>Sleep Stage Export</p>"},{"location":"api/stage/#sleepkit.stage.export.export","title":"<code>export(params)</code>","text":"<p>Export sleep stage model.</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>SKExportParams</code>)         \u2013          <p>Deployment parameters</p> </li> </ul> Source code in <code>sleepkit/stage/export.py</code> <pre><code>def export(params: SKExportParams):\n    \"\"\"Export sleep stage model.\n\n    Args:\n        params (SKExportParams): Deployment parameters\n    \"\"\"\n    params.num_sleep_stages = getattr(params, \"num_sleep_stages\", 3)\n\n    logger.info(f\"Creating working directory in {params.job_dir}\")\n    os.makedirs(params.job_dir, exist_ok=True)\n\n    handler = logging.FileHandler(params.job_dir / \"export.log\", mode=\"w\")\n    handler.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    target_classes = get_stage_classes(params.num_sleep_stages)\n    class_mapping = get_stage_class_mapping(params.num_sleep_stages)\n\n    tfl_model_path = params.job_dir / \"model.tflite\"\n    tflm_model_path = params.job_dir / \"model_buffer.h\"\n\n    ds = load_dataset(\n        handler=params.ds_handler, ds_path=params.ds_path, frame_size=params.frame_size, params=params.ds_params\n    )\n\n    class_shape = (params.frame_size, len(target_classes))\n\n    test_x, test_y = load_test_dataset(\n        ds=ds,\n        subject_ids=ds.test_subject_ids,\n        samples_per_subject=params.samples_per_subject,\n        test_size=params.test_size,\n        feat_shape=ds.feature_shape,\n        class_shape=class_shape,\n        class_map=class_mapping,\n    )\n\n    # Load model and set fixed batch size of 1\n    strategy = tfa.get_strategy()\n    with strategy.scope(), tfmot.quantization.keras.quantize_scope():\n        logger.info(\"Loading trained model\")\n        model = tfa.load_model(params.model_file, custom_objects={\"MultiF1Score\": tfa.MultiF1Score})\n\n        inputs = keras.layers.Input(ds.feature_shape, dtype=tf.float32, batch_size=1)\n        outputs = model(inputs)\n        if not params.use_logits and not isinstance(model.layers[-1], keras.layers.Softmax):\n            outputs = keras.layers.Softmax()(outputs)\n            model = keras.Model(inputs, outputs, name=model.name)\n            outputs = model(inputs)\n        # END IF\n        flops = tfa.get_flops(model, batch_size=1, fpath=params.job_dir / \"model_flops.log\")\n        model.summary(print_fn=logger.info)\n\n        logger.info(f\"Model requires {flops/1e6:0.2f} MFLOPS\")\n\n        logger.info(f\"Converting model to TFLite (quantization={params.quantization})\")\n        model_func = tf.function(func=model)\n        model_cf = model_func.get_concrete_function(tf.TensorSpec(shape=(1,) + ds.feature_shape, dtype=tf.float32))\n\n        if params.quantization:\n            _, quant_df = tfa.debug_quant_tflite(\n                model=model,\n                test_x=test_x,\n                input_type=tf.int8 if params.quantization else None,\n                output_type=tf.int8 if params.quantization else None,\n            )\n            quant_df.to_csv(params.job_dir / \"quant.csv\")\n\n        # Following is a workaround for bug (https://github.com/tensorflow/tflite-micro/issues/2319)\n        # Default TFLiteConverter generates equivalent graph w/ SpaceToBatchND operations but losses dilation_rate factor.\n        # Using concrete function instead of model object to avoid this issue.\n        converter = tf.lite.TFLiteConverter.from_concrete_functions([model_cf], model)\n\n        if params.quantization:\n            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n            if test_x is not None:\n                converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n                converter.inference_input_type = tf.int8\n                converter.inference_output_type = tf.int8\n\n                def rep_dataset():\n                    for i in range(test_x.shape[0]):\n                        yield [test_x[i : i + 1]]\n\n                converter.representative_dataset = rep_dataset\n            # END IF\n        tflite_model = converter.convert()\n\n        # Save TFLite model\n        logger.info(f\"Saving TFLite model to {tfl_model_path}\")\n        with open(tfl_model_path, \"wb\") as fp:\n            fp.write(tflite_model)\n\n        # Save TFLM model\n        logger.info(f\"Saving TFL micro model to {tflm_model_path}\")\n        tfa.xxd_c_dump(\n            src_path=tfl_model_path,\n            dst_path=tflm_model_path,\n            var_name=params.tflm_var_name,\n            chunk_len=20,\n            is_header=True,\n        )\n    # END WITH\n\n    y_pred_tf = np.argmax(model.predict(test_x), axis=-1).flatten()\n\n    # Verify TFLite results match TF results on example data\n    logger.info(\"Validating model results\")\n    y_true = np.argmax(test_y, axis=-1).flatten()\n\n    _, y_pred_tfl = tfa.predict_tflite(model_content=tflite_model, test_x=test_x)\n    y_pred_tfl = np.argmax(y_pred_tfl, axis=-1).flatten()\n\n    tf_acc = np.sum(y_true == y_pred_tf) / y_true.size\n    tf_f1 = f1_score(y_true, y_pred_tf, average=\"weighted\")\n    logger.info(f\"[TF SET] ACC={tf_acc:.2%}, F1={tf_f1:.2%}\")\n\n    tfl_acc = np.sum(y_true == y_pred_tfl) / y_true.size\n    tfl_f1 = f1_score(y_true, y_pred_tfl, average=\"weighted\")\n    logger.info(f\"[TFL SET] ACC={tfl_acc:.2%}, F1={tfl_f1:.2%}\")\n\n    # Check accuracy hit\n    tfl_acc_drop = max(0, tf_acc - tfl_acc)\n    if params.val_acc_threshold is not None and (1 - tfl_acc_drop) &lt; params.val_acc_threshold:\n        logger.warning(f\"TFLite accuracy dropped by {tfl_acc_drop:0.2%}\")\n    elif params.val_acc_threshold:\n        logger.info(f\"Validation passed ({tfl_acc_drop:0.2%})\")\n\n    if params.tflm_file and tflm_model_path != params.tflm_file:\n        logger.info(f\"Copying TFLM header to {params.tflm_file}\")\n        shutil.copyfile(tflm_model_path, params.tflm_file)\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.metrics","title":"<code>sleepkit.stage.metrics</code>","text":""},{"location":"api/stage/#sleepkit.stage.metrics.compute_sleep_efficiency","title":"<code>compute_sleep_efficiency(sleep_durations, class_map)</code>","text":"<p>Compute sleep efficiency.</p> <p>Parameters:</p> <ul> <li> <code>sleep_durations</code>             (<code>dict[int, int]</code>)         \u2013          <p>Sleep stage durations (class -&gt; duration)</p> </li> <li> <code>class_map</code>             (<code>dict[int, int]</code>)         \u2013          <p>Class map (class -&gt; class)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code> (            <code>float</code> )        \u2013          <p>Sleep efficiency</p> </li> </ul> Source code in <code>sleepkit/stage/metrics.py</code> <pre><code>def compute_sleep_efficiency(sleep_durations: dict[int, int], class_map: dict[int, int]) -&gt; float:\n    \"\"\"Compute sleep efficiency.\n\n    Args:\n        sleep_durations (dict[int, int]): Sleep stage durations (class -&gt; duration)\n        class_map (dict[int, int]): Class map (class -&gt; class)\n\n    Returns:\n        float: Sleep efficiency\n    \"\"\"\n    wake_classes = [SleepStage.wake]\n    sleep_classes = [SleepStage.stage1, SleepStage.stage2, SleepStage.stage3, SleepStage.stage4, SleepStage.rem]\n    wake_keys = list(set(class_map.get(s) for s in wake_classes if s in class_map))\n    sleep_keys = list(set(class_map.get(s) for s in sleep_classes if s in class_map))\n    wake_duration = sum(sleep_durations.get(k, 0) for k in wake_keys)\n    sleep_duration = sum(sleep_durations.get(k, 0) for k in sleep_keys)\n    efficiency = sleep_duration / (sleep_duration + wake_duration)\n    return efficiency\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.metrics.compute_sleep_stage_durations","title":"<code>compute_sleep_stage_durations(sleep_mask)</code>","text":"<p>Compute sleep stage durations</p> <p>Parameters:</p> <ul> <li> <code>sleep_mask</code>             (<code>NDArray</code>)         \u2013          <p>Sleep mask (1D array of sleep stages)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict[int, int]</code>         \u2013          <p>dict[int, int]: Sleep stage durations (class -&gt; duration)</p> </li> </ul> Source code in <code>sleepkit/stage/metrics.py</code> <pre><code>def compute_sleep_stage_durations(sleep_mask: npt.NDArray) -&gt; dict[int, int]:\n    \"\"\"Compute sleep stage durations\n\n    Args:\n        sleep_mask (npt.NDArray): Sleep mask (1D array of sleep stages)\n\n    Returns:\n        dict[int, int]: Sleep stage durations (class -&gt; duration)\n    \"\"\"\n    bounds = np.diff(sleep_mask).nonzero()[0] + 1\n    left_bounds = np.concatenate(([0], bounds))\n    right_bounds = np.concatenate((bounds, [sleep_mask.size]))\n    dur_bounds = right_bounds - left_bounds\n    class_bounds = sleep_mask[left_bounds]\n    class_durations = {k: 0 for k in set(class_bounds)}\n    for i, c in enumerate(class_bounds):\n        class_durations[c] += dur_bounds[i]\n    # END FOR\n    return class_durations\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.metrics.compute_total_sleep_time","title":"<code>compute_total_sleep_time(sleep_durations, class_map)</code>","text":"<p>Compute total sleep time (# samples).</p> <p>Parameters:</p> <ul> <li> <code>sleep_durations</code>             (<code>dict[int, int]</code>)         \u2013          <p>Sleep stage durations (class -&gt; duration)</p> </li> <li> <code>class_map</code>             (<code>dict[int, int]</code>)         \u2013          <p>Class map (class -&gt; class)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code> (            <code>int</code> )        \u2013          <p>Total sleep time (# samples)</p> </li> </ul> Source code in <code>sleepkit/stage/metrics.py</code> <pre><code>def compute_total_sleep_time(sleep_durations: dict[int, int], class_map: dict[int, int]) -&gt; int:\n    \"\"\"Compute total sleep time (# samples).\n\n    Args:\n        sleep_durations (dict[int, int]): Sleep stage durations (class -&gt; duration)\n        class_map (dict[int, int]): Class map (class -&gt; class)\n\n    Returns:\n        int: Total sleep time (# samples)\n    \"\"\"\n    # wake_classes = [SleepStage.wake]\n    sleep_classes = [SleepStage.stage1, SleepStage.stage2, SleepStage.stage3, SleepStage.stage4, SleepStage.rem]\n    # wake_keys = list(set(class_map.get(s) for s in wake_classes if s in class_map))\n    sleep_keys = list(set(class_map.get(s) for s in sleep_classes if s in class_map))\n    # wake_duration = sum(sleep_durations.get(k, 0) for k in wake_keys)\n    sleep_duration = sum(sleep_durations.get(k, 0) for k in sleep_keys)\n    tst = sleep_duration\n    return tst\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.train","title":"<code>sleepkit.stage.train</code>","text":"<p>Sleep Stage Training</p>"},{"location":"api/stage/#sleepkit.stage.train.train","title":"<code>train(params)</code>","text":"<p>Train sleep stage model.</p> <p>Parameters:</p> <ul> <li> <code>params</code>             (<code>SKTrainParams</code>)         \u2013          <p>Training parameters</p> </li> </ul> Source code in <code>sleepkit/stage/train.py</code> <pre><code>def train(params: SKTrainParams):\n    \"\"\"Train sleep stage model.\n\n    Args:\n        params (SKTrainParams): Training parameters\n\n    \"\"\"\n\n    # Custom parameters (add to SKTrainParams for automatic logging)\n    params.lr_rate: float = getattr(params, \"lr_rate\", 1e-3)\n    params.lr_cycles: int = getattr(params, \"lr_cycles\", 3)\n    params.steps_per_epoch = params.steps_per_epoch or 100\n    params.seed = set_random_seed(params.seed)\n\n    logger.info(f\"Creating working directory in {params.job_dir}\")\n    os.makedirs(params.job_dir, exist_ok=True)\n\n    handler = logging.FileHandler(params.job_dir / \"train.log\", mode=\"w\")\n    handler.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    logger.info(f\"Random seed {params.seed}\")\n\n    with open(params.job_dir / \"train_config.json\", \"w\", encoding=\"utf-8\") as fp:\n        fp.write(params.model_dump_json(indent=2))\n\n    if env_flag(\"WANDB\"):\n        wandb.init(\n            project=f\"sk-stage-{params.num_classes}\",\n            entity=\"ambiq\",\n            dir=params.job_dir,\n        )\n        wandb.config.update(params.model_dump())\n\n    target_classes = get_stage_classes(params.num_classes)\n    class_names = get_stage_class_names(params.num_classes)\n    class_mapping = get_stage_class_mapping(params.num_classes)\n\n    ds = load_dataset(\n        handler=params.ds_handler, ds_path=params.ds_path, frame_size=params.frame_size, params=params.ds_params\n    )\n    feat_shape = ds.feature_shape\n    class_shape = (params.frame_size, len(target_classes))\n\n    # Get train/val subject IDs and generators\n    train_subject_ids, val_subject_ids = sklearn.model_selection.train_test_split(\n        ds.train_subject_ids, test_size=params.val_subjects\n    )\n    logger.info(\"Loading training dataset\")\n    train_ds = load_train_dataset(\n        ds=ds,\n        subject_ids=train_subject_ids,\n        samples_per_subject=params.samples_per_subject,\n        buffer_size=params.buffer_size,\n        batch_size=params.batch_size,\n        feat_shape=feat_shape,\n        class_shape=class_shape,\n        class_map=class_mapping,\n        num_workers=params.data_parallelism,\n    )\n\n    logger.info(\"Loading validation dataset\")\n    val_ds = load_validation_dataset(\n        ds=ds,\n        subject_ids=val_subject_ids,\n        samples_per_subject=params.val_samples_per_subject,\n        batch_size=params.batch_size,\n        val_size=params.val_size,\n        feat_shape=feat_shape,\n        class_shape=class_shape,\n        class_map=class_mapping,\n    )\n    test_labels = [y.numpy() for _, y in val_ds]\n    y_true = np.argmax(np.concatenate(test_labels).squeeze(), axis=-1).flatten()\n    class_weights = sklearn.utils.compute_class_weight(\"balanced\", classes=np.array(target_classes), y=y_true)\n    class_weights = (class_weights + class_weights.mean()) / 2\n\n    strategy = tfa.get_strategy()\n    with strategy.scope():\n        logger.info(\"Building model\")\n        inputs = keras.Input(feat_shape, batch_size=None, dtype=tf.float32)\n        model = create_model(inputs, num_classes=len(target_classes), name=params.model, params=params.model_params)\n        flops = tfa.get_flops(model, batch_size=1, fpath=params.job_dir / \"model_flops.log\")\n\n        if params.lr_cycles == 1:\n            scheduler = keras.optimizers.schedules.CosineDecay(\n                initial_learning_rate=params.lr_rate,\n                decay_steps=int(params.steps_per_epoch * params.epochs),\n            )\n        else:\n            scheduler = keras.optimizers.schedules.CosineDecayRestarts(\n                initial_learning_rate=params.lr_rate,\n                first_decay_steps=int(0.1 * params.steps_per_epoch * params.epochs),\n                t_mul=1.65 / (0.1 * params.lr_cycles * (params.lr_cycles - 1)),\n                m_mul=0.4,\n            )\n        optimizer = keras.optimizers.Adam(scheduler)\n        loss = keras.losses.CategoricalFocalCrossentropy(\n            from_logits=True,\n            alpha=class_weights,\n            label_smoothing=params.label_smoothing,\n        )\n        metrics = [\n            keras.metrics.CategoricalAccuracy(name=\"acc\"),\n            tfa.MultiF1Score(name=\"f1\", dtype=tf.float32, average=\"weighted\"),\n            keras.metrics.OneHotIoU(\n                num_classes=len(target_classes),\n                target_class_ids=target_classes,\n                name=\"iou\",\n            ),\n        ]\n\n        if params.weights_file:\n            logger.info(f\"Loading weights from file {params.weights_file}\")\n            model.load_weights(params.weights_file)\n        params.weights_file = params.job_dir / \"model.weights\"\n\n        if params.quantization:\n            logger.info(\"Performing QAT...\")\n\n            def apply_quantization_to_non_norm(layer):\n                if not isinstance(layer, keras.layers.LayerNormalization):\n                    return tfmot.quantization.keras.quantize_annotate_layer(layer)\n                return layer\n\n            # model = tfmot.quantization.keras.quantize_model(model)\n            model = keras.models.clone_model(model, clone_function=apply_quantization_to_non_norm)\n            model = tfmot.quantization.keras.quantize_apply(model)\n\n        model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n        model(inputs)\n        model.summary(print_fn=logger.info)\n        logger.info(f\"Model requires {flops/1e6:0.2f} MFLOPS\")\n\n        # Remove existing TB logs\n        if os.path.exists(params.job_dir / \"logs\"):\n            shutil.rmtree(params.job_dir / \"logs\")\n\n        ModelCheckpoint = keras.callbacks.ModelCheckpoint\n        if env_flag(\"WANDB\"):\n            ModelCheckpoint = WandbModelCheckpoint\n        model_callbacks = [\n            keras.callbacks.EarlyStopping(\n                monitor=f\"val_{params.val_metric}\",\n                patience=max(int(0.25 * params.epochs), 1),\n                mode=\"max\" if params.val_metric == \"f1\" else \"auto\",\n                restore_best_weights=True,\n            ),\n            ModelCheckpoint(\n                filepath=params.weights_file,\n                monitor=f\"val_{params.val_metric}\",\n                save_best_only=True,\n                save_weights_only=True,\n                mode=\"max\" if params.val_metric == \"f1\" else \"auto\",\n                verbose=1,\n            ),\n            keras.callbacks.CSVLogger(params.job_dir / \"history.csv\"),\n            keras.callbacks.TensorBoard(\n                log_dir=params.job_dir / \"logs\",\n                write_steps_per_second=True,\n            ),\n        ]\n        if env_flag(\"WANDB\"):\n            model_callbacks.append(WandbMetricsLogger())\n\n        try:\n            model.fit(\n                train_ds,\n                steps_per_epoch=params.steps_per_epoch,\n                verbose=2,\n                epochs=params.epochs,\n                validation_data=val_ds,\n                callbacks=model_callbacks,\n            )\n        except KeyboardInterrupt:\n            logger.warning(\"Stopping training due to keyboard interrupt\")\n\n        # Restore best weights from checkpoint\n        model.load_weights(params.weights_file)\n\n        # Save full model\n        tf_model_path = params.job_dir / \"model.tf\"\n        logger.info(f\"Model saved to {tf_model_path}\")\n        model.save(tf_model_path)\n\n        # Get full validation results\n        logger.info(\"Performing full validation\")\n        y_pred = np.argmax(model.predict(val_ds).squeeze(), axis=-1).flatten()\n\n        confusion_matrix_plot(\n            y_true=y_true,\n            y_pred=y_pred,\n            labels=class_names,\n            save_path=params.job_dir / \"confusion_matrix.png\",\n            normalize=\"true\",\n        )\n        if env_flag(\"WANDB\"):\n            conf_mat = wandb.plot.confusion_matrix(preds=y_pred, y_true=y_true, class_names=class_names)\n            wandb.log({\"conf_mat\": conf_mat})\n        # END IF\n\n        # Summarize results\n        test_acc = np.sum(y_pred == y_true) / y_true.size\n        test_f1 = f1_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n        test_iou = compute_iou(y_true, y_pred, average=\"weighted\")\n        logger.info(f\"[TEST SET] ACC={test_acc:.2%}, F1={test_f1:.2%} IoU={test_iou:0.2%}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.utils","title":"<code>sleepkit.stage.utils</code>","text":""},{"location":"api/stage/#sleepkit.stage.utils.create_model","title":"<code>create_model(inputs, num_classes, name=None, params=None)</code>","text":"<p>Generate model or use default</p> <p>Parameters:</p> <ul> <li> <code>inputs</code>             (<code>Tensor</code>)         \u2013          <p>Model inputs</p> </li> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          <p>Number of classes</p> </li> <li> <code>name</code>             (<code>str | None</code>, default:                 <code>None</code> )         \u2013          <p>Architecture type. Defaults to None.</p> </li> <li> <code>params</code>             (<code>dict[str, Any] | None</code>, default:                 <code>None</code> )         \u2013          <p>Model parameters. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Model</code>         \u2013          <p>keras.Model: Model</p> </li> </ul> Source code in <code>sleepkit/stage/utils.py</code> <pre><code>def create_model(\n    inputs: tf.Tensor, num_classes: int, name: str | None = None, params: dict[str, Any] | None = None\n) -&gt; keras.Model:\n    \"\"\"Generate model or use default\n\n    Args:\n        inputs (tf.Tensor): Model inputs\n        num_classes (int): Number of classes\n        name (str | None, optional): Architecture type. Defaults to None.\n        params (dict[str, Any] | None, optional): Model parameters. Defaults to None.\n\n    Returns:\n        keras.Model: Model\n    \"\"\"\n    if name:\n        return generate_model(inputs=inputs, num_classes=num_classes, name=name, params=params)\n\n    return Tcn(\n        x=inputs,\n        params=TcnParams(\n            input_kernel=(1, 5),\n            input_norm=\"batch\",\n            blocks=[\n                TcnBlockParams(\n                    filters=64, kernel=(1, 5), dilation=(1, 2**d), dropout=0.1, ex_ratio=1, se_ratio=4, norm=\"batch\"\n                )\n                for d in range(4)\n            ],\n            output_kernel=(1, 5),\n            include_top=True,\n            use_logits=True,\n            model_name=\"tcn\",\n        ),\n        num_classes=num_classes,\n    )\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.utils.load_dataset","title":"<code>load_dataset(handler, ds_path, frame_size, params)</code>","text":"<p>Load dataset(s)</p> <p>Parameters:</p> <ul> <li> <code>handler</code>             (<code>str</code>)         \u2013          <p>Dataset handler</p> </li> <li> <code>ds_path</code>             (<code>Path</code>)         \u2013          <p>Dataset path</p> </li> <li> <code>frame_size</code>             (<code>int</code>)         \u2013          <p>Frame size</p> </li> <li> <code>params</code>             (<code>dict[str, Any]</code>)         \u2013          <p>Dataset arguments</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SKDataset</code> (            <code>SKDataset</code> )        \u2013          <p>Dataset</p> </li> </ul> Source code in <code>sleepkit/stage/utils.py</code> <pre><code>def load_dataset(handler: str, ds_path: Path, frame_size: int, params: dict[str, Any]) -&gt; SKDataset:\n    \"\"\"Load dataset(s)\n\n    Args:\n        handler (str): Dataset handler\n        ds_path (Path): Dataset path\n        frame_size (int): Frame size\n        params (dict[str, Any]): Dataset arguments\n\n    Returns:\n        SKDataset: Dataset\n    \"\"\"\n    if handler == \"hdf5\":\n        return Hdf5Dataset(ds_path=ds_path, frame_size=frame_size, **params)\n    raise ValueError(f\"Unknown dataset handler {handler}\")\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.utils.load_test_dataset","title":"<code>load_test_dataset(ds, subject_ids, samples_per_subject, test_size, feat_shape, class_shape, class_map)</code>","text":"<p>Load test dataset</p> <p>Parameters:</p> <ul> <li> <code>ds</code>             (<code>SKDataset</code>)         \u2013          <p>Dataset</p> </li> <li> <code>subject_ids</code>             (<code>list[str]</code>)         \u2013          <p>Subject IDs</p> </li> <li> <code>samples_per_subject</code>             (<code>int</code>)         \u2013          <p>Samples per subject</p> </li> <li> <code>test_size</code>             (<code>int</code>)         \u2013          <p>Test size</p> </li> <li> <code>feat_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Feature shape</p> </li> <li> <code>class_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Class shape</p> </li> <li> <code>class_map</code>             (<code>dict[int, int]</code>)         \u2013          <p>Class mapping</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[NDArray, NDArray]</code>         \u2013          <p>tuple[npt.NDArray, npt.NDArray]: Test features and labels</p> </li> </ul> Source code in <code>sleepkit/stage/utils.py</code> <pre><code>def load_test_dataset(\n    ds: SKDataset,\n    subject_ids: list[str],\n    samples_per_subject: int,\n    test_size: int,\n    feat_shape: tuple[int, ...],\n    class_shape: tuple[int, ...],\n    class_map: dict[int, int],\n) -&gt; tuple[npt.NDArray, npt.NDArray]:\n    \"\"\"Load test dataset\n\n    Args:\n        ds (SKDataset): Dataset\n        subject_ids (list[str]): Subject IDs\n        samples_per_subject (int): Samples per subject\n        test_size (int): Test size\n        feat_shape (tuple[int,...]): Feature shape\n        class_shape (tuple[int,...]): Class shape\n        class_map (dict[int, int]): Class mapping\n\n    Returns:\n        tuple[npt.NDArray, npt.NDArray]: Test features and labels\n    \"\"\"\n\n    def preprocess(x: npt.NDArray[np.float32]):\n        return x\n\n    output_signature = (\n        tf.TensorSpec(shape=feat_shape, dtype=tf.float32),\n        tf.TensorSpec(shape=class_shape, dtype=tf.int32),\n    )\n\n    def test_generator():\n        test_subj_gen = ds.uniform_subject_generator(subject_ids)\n        return map(\n            lambda x_y: prepare(preprocess(x_y[0]), x_y[1], class_shape[-1], class_map),\n            ds.signal_generator(test_subj_gen, samples_per_subject=samples_per_subject, normalize=True),\n        )\n\n    test_ds = tf.data.Dataset.from_generator(generator=test_generator, output_signature=output_signature)\n    test_x, test_y = next(test_ds.batch(test_size).as_numpy_iterator())\n\n    return test_x, test_y\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.utils.load_train_dataset","title":"<code>load_train_dataset(ds, subject_ids, samples_per_subject, buffer_size, batch_size, feat_shape, class_shape, class_map, num_workers=4)</code>","text":"<p>Load train dataset</p> <p>Parameters:</p> <ul> <li> <code>ds</code>             (<code>SKDataset</code>)         \u2013          <p>Dataset</p> </li> <li> <code>subject_ids</code>             (<code>list[str]</code>)         \u2013          <p>Subject IDs</p> </li> <li> <code>samples_per_subject</code>             (<code>int</code>)         \u2013          <p>Samples per subject</p> </li> <li> <code>buffer_size</code>             (<code>int</code>)         \u2013          <p>Buffer size</p> </li> <li> <code>batch_size</code>             (<code>int</code>)         \u2013          <p>Batch size</p> </li> <li> <code>feat_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Feature shape</p> </li> <li> <code>class_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Class shape</p> </li> <li> <code>class_map</code>             (<code>dict[int, int]</code>)         \u2013          <p>Class mapping</p> </li> <li> <code>num_workers</code>             (<code>int</code>, default:                 <code>4</code> )         \u2013          <p>Number of workers. Defaults to 4.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>         \u2013          <p>tf.data.Dataset: Train dataset</p> </li> </ul> Source code in <code>sleepkit/stage/utils.py</code> <pre><code>def load_train_dataset(\n    ds: SKDataset,\n    subject_ids: list[str],\n    samples_per_subject: int,\n    buffer_size: int,\n    batch_size: int,\n    feat_shape: tuple[int, ...],\n    class_shape: tuple[int, ...],\n    class_map: dict[int, int],\n    num_workers: int = 4,\n) -&gt; tf.data.Dataset:\n    \"\"\"Load train dataset\n\n    Args:\n        ds (SKDataset): Dataset\n        subject_ids (list[str]): Subject IDs\n        samples_per_subject (int): Samples per subject\n        buffer_size (int): Buffer size\n        batch_size (int): Batch size\n        feat_shape (tuple[int,...]): Feature shape\n        class_shape (tuple[int,...]): Class shape\n        class_map (dict[int, int]): Class mapping\n        num_workers (int, optional): Number of workers. Defaults to 4.\n\n    Returns:\n        tf.data.Dataset: Train dataset\n    \"\"\"\n\n    def preprocess(x: npt.NDArray[np.float32]) -&gt; npt.NDArray[np.float32]:\n        \"\"\"Preprocess data\"\"\"\n        xx = x.copy()\n        xx = xx + np.random.normal(0, 0.1, size=x.shape)\n        # if np.random.rand() &lt; 0.2:\n        # xx = np.flip(xx, axis=0)\n        return xx\n\n    def train_generator(subject_ids):\n        \"\"\"Train generator per worker\"\"\"\n\n        def ds_gen():\n            \"\"\"Worker generator routine\"\"\"\n            train_subj_gen = ds.uniform_subject_generator(subject_ids)\n            return map(\n                lambda x_y: prepare(preprocess(x_y[0]), x_y[1], class_shape[-1], class_map),\n                ds.signal_generator(train_subj_gen, samples_per_subject=samples_per_subject, normalize=True),\n            )\n\n        return tf.data.Dataset.from_generator(\n            ds_gen,\n            output_signature=(\n                tf.TensorSpec(shape=feat_shape, dtype=tf.float32),\n                tf.TensorSpec(shape=class_shape, dtype=tf.int32),\n            ),\n        )\n\n    split = len(subject_ids) // num_workers\n    train_datasets = [train_generator(subject_ids[i * split : (i + 1) * split]) for i in range(num_workers)]\n\n    # Create TF datasets (interleave workers)\n    train_ds = (\n        tf.data.Dataset.from_tensor_slices(train_datasets)\n        .interleave(\n            lambda x: x,\n            cycle_length=num_workers,\n            deterministic=False,\n            num_parallel_calls=tf.data.AUTOTUNE,\n        )\n        .shuffle(\n            buffer_size=buffer_size,\n            reshuffle_each_iteration=True,\n        )\n        .batch(\n            batch_size=batch_size,\n            drop_remainder=False,\n        )\n        .prefetch(buffer_size=tf.data.AUTOTUNE)\n    )\n\n    return train_ds\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.utils.load_validation_dataset","title":"<code>load_validation_dataset(ds, subject_ids, samples_per_subject, batch_size, val_size, feat_shape, class_shape, class_map)</code>","text":"<p>Load validation dataset.</p> <p>Parameters:</p> <ul> <li> <code>ds</code>             (<code>SKDataset</code>)         \u2013          <p>Dataset</p> </li> <li> <code>subject_ids</code>             (<code>list[str]</code>)         \u2013          <p>Subject IDs</p> </li> <li> <code>samples_per_subject</code>             (<code>int</code>)         \u2013          <p>Samples per subject</p> </li> <li> <code>batch_size</code>             (<code>int</code>)         \u2013          <p>Batch size</p> </li> <li> <code>val_size</code>             (<code>int</code>)         \u2013          <p>Validation size</p> </li> <li> <code>feat_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Feature shape</p> </li> <li> <code>class_shape</code>             (<code>tuple[int, ...]</code>)         \u2013          <p>Class shape</p> </li> <li> <code>class_map</code>             (<code>dict[int, int]</code>)         \u2013          <p>Class mapping</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dataset</code>         \u2013          <p>tf.data.Dataset: Validation dataset</p> </li> </ul> Source code in <code>sleepkit/stage/utils.py</code> <pre><code>def load_validation_dataset(\n    ds: SKDataset,\n    subject_ids: list[str],\n    samples_per_subject: int,\n    batch_size: int,\n    val_size: int,\n    feat_shape: tuple[int, ...],\n    class_shape: tuple[int, ...],\n    class_map: dict[int, int],\n) -&gt; tf.data.Dataset:\n    \"\"\"Load validation dataset.\n\n    Args:\n        ds (SKDataset): Dataset\n        subject_ids (list[str]): Subject IDs\n        samples_per_subject (int): Samples per subject\n        batch_size (int): Batch size\n        val_size (int): Validation size\n        feat_shape (tuple[int,...]): Feature shape\n        class_shape (tuple[int,...]): Class shape\n        class_map (dict[int, int]): Class mapping\n\n    Returns:\n        tf.data.Dataset: Validation dataset\n    \"\"\"\n\n    def preprocess(x: npt.NDArray[np.float32]):\n        return x\n\n    output_signature = (\n        tf.TensorSpec(shape=feat_shape, dtype=tf.float32),\n        tf.TensorSpec(shape=class_shape, dtype=tf.int32),\n    )\n\n    def val_generator():\n        val_subj_gen = ds.uniform_subject_generator(subject_ids)\n        return map(\n            lambda x_y: prepare(preprocess(x_y[0]), x_y[1], class_shape[-1], class_map),\n            ds.signal_generator(val_subj_gen, samples_per_subject=samples_per_subject, normalize=True),\n        )\n\n    val_ds = tf.data.Dataset.from_generator(generator=val_generator, output_signature=output_signature)\n    val_x, val_y = next(val_ds.batch(val_size).as_numpy_iterator())\n    val_ds = create_dataset_from_data(val_x, val_y, output_signature=output_signature).batch(\n        batch_size=batch_size,\n        drop_remainder=False,\n    )\n\n    return val_ds\n</code></pre>"},{"location":"api/stage/#sleepkit.stage.utils.prepare","title":"<code>prepare(x, y, num_classes, class_map)</code>","text":"<p>Prepare data for training</p> <p>Parameters:</p> <ul> <li> <code>x</code>             (<code>Tensor</code>)         \u2013          <p>Features</p> </li> <li> <code>y</code>             (<code>Tensor</code>)         \u2013          <p>Labels</p> </li> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          <p>Number of classes</p> </li> <li> <code>class_map</code>             (<code>dict[int, int]</code>)         \u2013          <p>Class mapping</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple[Tensor, Tensor]</code>         \u2013          <p>tuple[tf.Tensor, tf.Tensor]: Features and labels</p> </li> </ul> Source code in <code>sleepkit/stage/utils.py</code> <pre><code>def prepare(x: tf.Tensor, y: tf.Tensor, num_classes: int, class_map: dict[int, int]) -&gt; tuple[tf.Tensor, tf.Tensor]:\n    \"\"\"Prepare data for training\n\n    Args:\n        x (tf.Tensor): Features\n        y (tf.Tensor): Labels\n        num_classes (int): Number of classes\n        class_map (dict[int, int]): Class mapping\n\n    Returns:\n        tuple[tf.Tensor, tf.Tensor]: Features and labels\n    \"\"\"\n    return (\n        x,\n        # tf.one_hot(class_map.get(sts.mode(y[-5:]).mode, 0), num_classes)\n        tf.one_hot(np.vectorize(class_map.get)(y), num_classes),\n    )\n</code></pre>"},{"location":"apnea/overview/","title":"Sleep Apnea Detection","text":""},{"location":"detect/demo/","title":"Sleep Detection Demo","text":"<p>A demo is provided to showcase the capabilities of the sleep detect model. Similar to other modes, the demo can be invoked either via CLI or within <code>sleepkit</code> python package. At a high level, the demo performs the following actions based on the provided configuration parameters:</p> <ol> <li>Load the configuration file (e.g. <code>demo.json</code>)</li> <li>Load the desired dataset features (e.g. <code>fs004</code>)</li> <li>Load the trained model (e.g. <code>sleep-detect</code>)</li> <li>Load random test subject's data</li> <li>Perform inference either on PC or EVB</li> <li>Generate report</li> </ol>"},{"location":"detect/demo/#usage","title":"Usage","text":""},{"location":"detect/demo/#pc-backend","title":"PC backend","text":"<ol> <li>Create / modify configuration file (e.g. <code>demo.json</code>)</li> <li>Ensure \"pc\" is selected as the backend in configuration file.</li> <li>Run demo <code>sleepkit --mode demo --task detect --config ./configs/sleep-detect/demo.json</code></li> <li>HTML report will be saved to <code>${job_dir}/report.html</code></li> </ol>"},{"location":"detect/demo/#evb-backend","title":"EVB backend","text":"<ol> <li>Create / modify configuration file (e.g. <code>demo.json</code>)</li> <li>Ensure \"evb\" is selected as the backend in configuration file.</li> <li>Plug EVB into PC via two USB-C cables.</li> <li>Build and flash firmware to EVB <code>cd evb &amp;&amp; make &amp;&amp; make deploy</code></li> <li>Run demo <code>sleepkit --mode demo --task detect --config ./configs/sleep-detect/demo.json</code></li> <li>HTML report will be saved to <code>${job_dir}/report.html</code></li> </ol>"},{"location":"detect/demo/#outputs","title":"Outputs","text":""},{"location":"detect/methods/","title":"Methods &amp; Materials","text":""},{"location":"detect/methods/#datasets","title":"Datasets","text":"<p>For training the included models, we utilize the CMIDSS dataset from the Child Mind Institute - Detect Sleep States Kaggle competition. For this dataset, we leverage only the data from a 3-axis accelerometer.</p>"},{"location":"detect/methods/#feature-extraction","title":"Feature Extraction","text":"<p>In this task, we are interested in capturing the general trends in a subject's physical activity. Specifically from a 3-axis accelerometer, we compute the mean and st. dev of ENMO and z-angle. ENMO provides a more consistent measure of physical activity across different age groups and body types. Also, ENMO is more suitable than actigraphy <code>counts</code> as the latter is manufacturer specific. The z-angle is a measure of the angle of the wrist with respect to the ground. The z-angle has proven to be very valuable in distinguishing between inactivity bouts and sleep (2018 Hees). Furthermore, we provide temporal embedding of the time of day to account for the 24-hour circadian cycle.</p>"},{"location":"detect/methods/#feature-normalization","title":"Feature Normalization","text":"<p>Since physical activity can vary greatly between subjects and even within a single subject, we normalize the features across the temporal window fed into the model. For the pre-trained models, we typically pass 4 hours of data to better capture long-term trends.</p>"},{"location":"detect/methods/#training-procedure","title":"Training Procedure","text":"<p>For training the models, we utilize the following setup. We utilize a focal loss function Lin et al., 2018 to deal with the significant class imbalance. Rather than artificially oversampling or undersampling we provide class weight factors to penalize under-represented class losses more. The model is trained using Adam optimizer Kingma et al., 2014. We also employ a cosine decay learning rate scheduler with restarts Loshchilov et al., 2016 to improve the model's generalization ability. Additionally, we use early stopping to prevent overfitting based on loss metric.</p>"},{"location":"detect/methods/#evaluation-metrics","title":"Evaluation Metrics","text":"<p>For each dataset, 20% of the data is held out for validation and 20% of the data is held out for testing. The remaining 60% of the data is used for training. There is no mixing of subjects between the training, validation, and test sets. Furthermore, the test set is held fixed while training and validation are randomly split during training. We evaluate the models performance using a variety of metrics including loss, accuracy, F1 score, average precision (AP).</p>"},{"location":"detect/methods/#sleep-detection-classes","title":"Sleep Detection Classes","text":"<p>Below outlines the grouping of sleep detection task.</p> 2-Stage CLASS STAGES 0- WAKE W 1- SLEEP N1, N2, N3, REM"},{"location":"detect/overview/","title":"Sleep Detection","text":""},{"location":"detect/overview/#overview","title":"Overview","text":"<p>The objective of sleep detection is to identify periods of sustained sleep over the course of several days or weeks. The de facto standard for long-term, ambulatory sleep detection is actigraphy, which is a method of monitoring gross motor activity using an accelerometer. However, actigraphy is not a reliable method for sleep detection as it employs very simple heuristics to determine sleep. Often actigraphy can misclassify periods of inactivity or even not-worn as detected sleep.</p> <p>In this task, we look to leverage a light-weight model that can outperform actigraphy similarly using only data from an IMU. For more advanced sleep analysis, refer to the Sleep Stage Classification. By leveraring Ambiq's ultra-low-power microcontroller along with an ultra-low-power IMU, an efficient AI enabled actigraphy or fitness band will be able to run for weeks off a single charge.</p> <p> </p> Wrist-based Sleep Detection"},{"location":"detect/results/","title":"Results","text":"<p>The following table provides the latest performance and accuracy results of the reference models.</p> Task Params FLOPS Accuracy F1 AP Sleep Detect 6K 425K/hr 94.0% 94.2% 92.5%"},{"location":"detect/results/#confusion-matrix","title":"Confusion Matrix","text":""},{"location":"detect/results/#sleep-efficiency-plot","title":"Sleep Efficiency Plot","text":""},{"location":"detect/results/#total-sleep-time-tst-plot","title":"Total Sleep Time (TST) Plot","text":""},{"location":"detect/results/#evb-performance","title":"EVB Performance","text":"<p>The following table provides the latest performance and accuracy results of all models when running on Apollo4 Plus EVB. These results are obtained using neuralSPOTs Autodeploy tool. From neuralSPOT repo, the following command can be used to capture EVB results via Autodeploy:</p> <pre><code>python -m ns_autodeploy \\\n--tflite-filename sleep-detect-model.tflite \\\n--model-name sleepdetect \\\n--cpu-mode 192 \\\n--arena-size-scratch-buffer-padding 0 \\\n--max-arena-size 60 \\\n</code></pre> Task Params FLOPS Metric Cycles Time Arena NVM RAM Sleep Detect 6K 425K/hr 92.5% AP 7.3M/hr 38ms/hr 38KB 208KB 57KB"},{"location":"stages/architecture/","title":"Model Architecture","text":"<p>For sleep staging, the pre-trained models leverage a modified Temporal Convolutional Network (TCN) architecture. During preliminary exploration we also tried various 1-D CNN, RNN (LSTM and GRU), and U-NET based architectures but found them to either require too much memory, computation, or suffer significant accuracy degredation when quantizing to 8-bit.</p> <p>The below diagram shows the full TCN model architecture for sleep stage classification. The top-level block diagram is depicted in TCN and consists of an input convolutional encoder, a series of TCN blocks, and lastly an output convolutional layer. The vanilla TCN architecture consists of several TCN blocks with each block consisting of 2 sequential dilated 1-D convolutional layers followed by a residual connection. Each convolutional layer is followed by weight normalization and ReLU layers.  In our implementation, we replace the first convolutional layer with a depthwise convolutional layer and the second convolutional layer with a pointwise convolutional layer (w/o dilation) as shown in TCN Block.  We also added a squeeze and excitation (SE) block between the convolutional layers to emphasize specific channels, depicted in SE Block. In place of weight normalization we use standard batch normalization to enable fusing them after training. ReLU is also replaced with the approximated ReLU6. We employ over-parameterization by introducing parallel branches for each convolutional and normalization layers as described in Vasu et al., 2023. Post-training, these parallel branches are fused to create a single branch, thus, imposing no added computation or memory at inference time.</p> <p> </p> Modified TCN Architecture. Conv=Convolutional, DWConv=depthwise convolutional, PWConv=pointwise convolutional, Norm=Normalization, DWConv.k= kernel size, DWConv.d=dilation rate, Conv.k=kernel size, Conv.f= filter size"},{"location":"stages/demo/","title":"Sleep Stage Demo","text":"<p>A demo is provided to showcase the capabilities of the sleep stage classifier models. Similar to other modes, the demo can be invoked either via CLI or within <code>sleepkit</code> python package. At a high level, the demo performs the following actions based on the provided configuration parameters:</p> <ol> <li>Load the configuration file (e.g. <code>demo-stage-4.json</code>)</li> <li>Load the desired dataset features (e.g. <code>fs001</code>)</li> <li>Load the trained model (e.g. <code>sleep-stage-4</code>)</li> <li>Load random test subject's data</li> <li>Perform inference either on PC or EVB</li> <li>Generate report</li> </ol>"},{"location":"stages/demo/#usage","title":"Usage","text":""},{"location":"stages/demo/#pc-backend","title":"PC backend","text":"<ol> <li>Create / modify configuration file (e.g. <code>demo-stage-4.json</code>)</li> <li>Ensure \"pc\" is selected as the backend in configuration file.</li> <li>Run demo <code>sleepkit --mode demo --task stage --config ./configs/demo-stage-4.json</code></li> <li>HTML report will be saved to <code>${job_dir}/report.html</code></li> </ol>"},{"location":"stages/demo/#evb-backend","title":"EVB backend","text":"<ol> <li>Create / modify configuration file (e.g. <code>demo-stage-4.json</code>)</li> <li>Ensure \"evb\" is selected as the backend in configuration file.</li> <li>Plug EVB into PC via two USB-C cables.</li> <li>Build and flash firmware to EVB <code>cd evb &amp;&amp; make &amp;&amp; make deploy</code></li> <li>Run demo <code>sleepkit --mode demo --task stage --config ./configs/demo-stage-4.json</code></li> <li>HTML report will be saved to <code>${job_dir}/report.html</code></li> </ol>"},{"location":"stages/demo/#outputs","title":"Outputs","text":""},{"location":"stages/experiments/","title":"Experiments","text":""},{"location":"stages/experiments/#ablation-studies","title":"Ablation Studies","text":"<p>In the following, we perform ablation studies to investigate the impact of different design choices on the performance of the model. All ablation studies are performed using the 4-stage sleep classification model trained on the MESA dataset. Unless otherwise noted, all experiments are carried out with identical training procedures.</p>"},{"location":"stages/experiments/#temporal-context","title":"Temporal Context","text":"<p>We first evaluate the impact of the temporal context- the number of time steps that are considered when making a prediction. For example, a temporal context of 1 means that only the current time step is considered when making a prediction. A temporal context of 2 means that the current time step and the previous time step are considered when making a prediction. The following plot shows the impact of the temporal context on the validation loss. As we can see, increasing the temporal context provides a roughly proportional decrease in loss up to around 2 hours after which the loss increases.</p> <p>A typical night sleep involves 4 or 5 sleep cycles each of which lasts around 90-120 minutes. By providing the model with nearly an entire cycle allows the model to learn the patterns associated with each stage. However, providing the model with more than one cycle does not provide additional benefit. This is likely due to the fact that the model is already able to learn the patterns associated with each stage within a single cycle.</p>"},{"location":"stages/experiments/#model-width","title":"Model Width","text":"<p>Another important design choice is the width (aka. # channels) of the network. To reduce the number of hyper-parameters, we provide a width multiplier to adjust number of channels in each layer relative to the baseline model. For example, a width multiplier of 0.5 means that the number of channels in each layer is half of the baseline model. The following plot shows the impact of the width multiplier on the validation loss. Increasing the width to 1.25 provides a slight 1.2% reduction in loss but requires 47% more FLOPS. As we continue to increase the width, the loss largely plateaus while the FLOPS and memory requirements increase dramatically. On the other hand, decreasing the width below 1 causes a stark increase in loss.</p>"},{"location":"stages/experiments/#kernel-size","title":"Kernel Size","text":"<p>We further investigate the impact on kernel size on the validation loss. Traditionally, computer vision tasks leveraged 3x3 filter sizes. However, recent works have shown that larger filter sizes can provide better performance especially in 1D time-series by providing larger receptive fields. The plot below shows the impact of the kernel size on the validation loss. Using a filter length of 5 provides a significant reduction in loss while requiring 10% increase in FLOPS and 1K additional parameters. Beyond a filter length of 5, the loss plateaus while the FLOPS and memory requirements increase.</p>"},{"location":"stages/experiments/#squeeze-and-excitation-ratio","title":"Squeeze and Excitation Ratio","text":"<p>In the following ablation, we evaluate the impact of the squeeze-and-excitation (SE) ratio. As background, the SE block \"adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels.\" The SE reduction ratio is a hyperparameter that controls the amount channel compression within the SE block. When the SE block is utilized, the reduction ratio has negligible impact on the computational and memory cost. The following plot shows the impact on validation loss for different SE reduction ratios. NOTE: <code>ratio=0</code> corresponds to no SE block. We see that using an SE ratio of 4 results in the lowest validation loss. This provides a 16% reduction in loss while requiring only 3K additional parameters versus no SE blocks.</p>"},{"location":"stages/experiments/#dilated-convolution","title":"Dilated Convolution","text":"<p>Taking inspiration from WaveNet, we evaluate the impact of dilated convolutions on the validation loss. By utilizing increasing dilation rates, we are able to increase the temporal context without increasing the number of parameters nor computation. For example, using a dilation rate of 4 with a kernel length of 5 gives a temporal resolution of 20 time steps compared to 5 time steps for a standard convolution. The following bar chart shows the impact of using dilation convolutions on the validation loss. In the case with dilation, dilation rates of 1, 2, 4, and 8 are used. By adding dilation the model loss decreases by 23% without any increase on memory or computation footprint.</p>"},{"location":"stages/methods/","title":"Methods &amp; Materials","text":""},{"location":"stages/methods/#datasets","title":"Datasets","text":"<p>For training the included model, we utilize the MESA dataset. For this dataset, we leverage PPG, SpO2, and leg sensor data. Typically we would compute SpO2 directly from two or more PPG signals but only 1 PPG signal is provided in this dataset. Furthermore, we use the provided leg sensor as a proxy for general body movement. Ideally, capturing accelerometer on the wrist would provide better insights as we can extract movement as well as positioning (e.g. 2018 Hees).</p>"},{"location":"stages/methods/#feature-extraction","title":"Feature Extraction","text":"<p>For sleep stage classification, we are interested in capturing both short and long-term trends in a subject's physiological signals. In particular, as a subject transitions from one sleep stage to another, we expect to see changes in the subject's physiological signals. For example, as a subject transitions from wake to sleep, we might expect to see a decrease in heart rate and an increase in respiratory rate. Similarly, as a subject transitions from light sleep to deep sleep, we expect to see a decrease in heart rate and respiratory rate. While the general trend with AI is to use raw sensory input, we believe that feeding the model with pre-processed features provides a more robust and interpretable model. By extracting sensor agnostic features, we can better understand the model's decision making process and provide more accurate and actionable insights to the user. Furthermore, we beleive this will make the models more robust to sensor noise and drift and will be able to generalize to new subjects and environments.</p> <p>In general, we compute features derived from the circulatory, respiratory, and muscular system. We leverage Ambiq's PhysioKit Python package to extract these physiological features from raw sensory data. The following table provides a list of these features computed over sliding windows (e.g. 30 seconds).</p> <ul> <li>Inter-beat interval (IBI) Mean</li> <li>IBI St. Deviation</li> <li>IBI Median</li> <li>Heart Rate Variability (HRV) LF/HF Ratio</li> <li>SpO2 mean</li> <li>SpO2 St. Deviation</li> <li>SpO2 Median</li> <li>Movement mean</li> <li>Movement St. Deviation</li> <li>Movement Median</li> <li>Respiratory Rate (BPM)</li> <li>Quality of Signal (QoS)</li> </ul> <p>Please refer to sleepkit/features.py to examine the full list of features computed along with their implementations.</p>"},{"location":"stages/methods/#feature-normalization","title":"Feature Normalization","text":"<p>Physiological signals can vary greatly between subjects and even within a single subject. For example, a subject's heart rate can vary from 40 BPM to 100 BPM. In order to account for this, we normalize the features to have a mean of 0 and a standard deviation of 1 over an entire nights recording. This allows the model to learn the general trends in the data rather than the absolute values. For example, a subject's heart rate may be 80 BPM while another subject's heart rate may be 60 BPM. However, the general trend of the heart rate is the same for both subjects. By normalizing the features, the model can learn the general trend of the heart rate rather than the absolute value.</p>"},{"location":"stages/methods/#training-procedure","title":"Training Procedure","text":"<p>For training the models, we utilize the following setup. We utilize a focal loss function Lin et al., 2018 to deal with the significant class imbalance. Rather than artificially oversampling or undersampling we provide class weight factors to penalize under-represented class losses more. The model is trained using Adam optimizer Kingma et al., 2014. We also employ a cosine decay learning rate scheduler with restarts Loshchilov et al., 2016 to improve the model's generalization ability. Additionally, we use early stopping to prevent overfitting based on loss metric.</p>"},{"location":"stages/methods/#evaluation-metrics","title":"Evaluation Metrics","text":"<p>For each dataset, 20% of the data is held out for validation and 20% of the data is held out for testing. The remaining 60% of the data is used for training. There is no mixing of subjects between the training, validation, and test sets. Furthermore, the test set is held fixed while training and validation are randomly split during training. We evaluate the models performance using a variety of metrics including loss, accuracy, F1 score, average precision (AP).</p>"},{"location":"stages/methods/#sleep-stage-classes","title":"Sleep Stage Classes","text":"<p>Below outlines the grouping of sleep stages used for 2, 3, 4, and 5 stage sleep classification tasks.</p> 2-Stage3-Stage4-Stage5-Stage CLASS STAGES 0- WAKE W 1- SLEEP N1, N2, N3, REM CLASS STAGES 0- WAKE W 1- NREM N1, N2, N3 2- REM REM CLASS STAGES 0- WAKE W 1- CORE N1, N2 2- DEEP N3 3- REM REM CLASS STAGES 0- WAKE W 1- N1 N1 2- N2 N2 3- N3 N3 4- REM REM"},{"location":"stages/overview/","title":"Sleep Stage Assessment","text":""},{"location":"stages/overview/#overview","title":"Overview","text":"<p>The objective of sleep stage assessment is to determine the different stages of sleep (N1, N2, N3, REM, and wake) over the course of a night. The de facto standard for sleep stage assessment is polysomnography (PSG) that requires collecting numerous multi-site physiological signals and a trained sleep technician to perform the assessment. The technician uses the physiological signals to determine the sleep stage based on the American Academy of Sleep Medicine (AASM) guidelines. The identification of stages is possible due to specific electrophysiological signatures present and recorded by EEG, EOG, and EMG signals.</p> <p> </p> Sleep Stage Assessment <p>The focus of this project is to develop a model that can perform sleep stage assessment using only a small subset of the signals that can be captured from same body location (e.g. wrist) that is viable for long-term use. In particular, the current models are trained on physiological signals that can be captured from the wrist for fitness band and smartwatch applications. Traditionally, wrist-based sleep classification has been performed using actigraphy, which is a method of monitoring gross motor activity using an accelerometer. However, actigraphy is not a reliable method for sleep stage assessment. The current model is designed to perform sleep stage assessment using a combination of motor activity, cardiovascular signals (e.g. heart rate), and derived resipiratory signals (e.g. respiration rate).</p> <p> </p> Wrist-based Sleep Classification"},{"location":"stages/overview/#sleep-stages","title":"Sleep Stages","text":"<p>Sleep stages consists of wake (W), non-rapid eye movement (NREM) sleep, and rapid eye movement (REM) sleep. NREM sleep is further divided into three stages: N1, N2, and N3. N1 and N2 are considered light sleep, while N3 is considered deep sleep. REM sleep is considered the dreaming stage of sleep. During the course of a night, a subject will undergo multiple rounds of sleep cycles, each composed of the individual stages. The duration of each cycle and length of each stage various throughout the night. Each sleep cycle typically lasts around 90 to 120 minutes.</p>"},{"location":"stages/overview/#characteristics","title":"Characteristics","text":"Wake (W)Light Sleep (N1)Core Sleep (N2)Deep Sleep (N3)REM Sleep (REM) <p>This is the time before or after bed when individual is awake.</p> <p>Key Characteristics</p> <ul> <li>Alpha waves on the EEG</li> <li>No K-complexes or sleep spindles</li> <li>Eye movements are normal</li> <li>Respiratory rate and heart rate are normal</li> <li>Body movements are common</li> </ul> <p>This is the shortest and lightest stage of sleep. It is the transition from wakefulness to sleep. It is characterized by slow eye movements, and alpha and theta waves on the EEG. It is also known as somnolence, or drowsy sleep. This stage lasts around 1 to 5 minutes, consisting of 5% of total sleep time. This stage is extremely difficult by EEG alone, and is often misclassified as wake or N2.</p> <p>Key Characteristics:</p> <ul> <li>Alpha and theta waves on the EEG</li> <li>No K-complexes or sleep spindles</li> <li>Slow eye movements</li> <li>Respiratory rate and heart rate are normal</li> <li>Body temperature begins to drop</li> <li>Muscles relax; might jerk</li> </ul> <p>This stage represents deeper sleep as the body begins to prepare for deep sleep. Physiologically, the body temperature begins to drop and the heart rate begins to slow. The stage is characterized by sleep spindles and K-complexes on the EEG. Stage 2 sleep lasts around 10 to 25 minutes, consisting of 45% to 55% of total sleep time. The duration increases as the night progresses.</p> <p>Key Characteristics:</p> <ul> <li>Sleep spindles and K-complexes on the EEG</li> <li>No eye movements</li> <li>Respiratory rate and heart rate slows</li> <li>Body temperature drops</li> <li>Body movements are rare</li> </ul> <p>Stage 3 sleep is the deepest stage of sleep. It is characterized by delta waves on the EEG. It is also known as slow-wave sleep (SWS) or delta sleep. It is difficult to wake someone from this stage. Stage 3 sleep lasts around 20 to 40 minutes, consisting of 3% to 8% of total sleep time. The duration decreases as the night progresses.</p> <p>Key Characteristics:</p> <ul> <li>Delta waves on the EEG</li> <li>No eye movements</li> <li>Blood pressure drops, flow increases</li> <li>Respiratory rate and heart rate are at lowest levels</li> <li>Body movements are rare (sleep walking, sleep talking, bed wetting, and night terrors may occur)</li> </ul> <p>The REM stage is characterized by rapid eye movements, low muscle tone, and dreaming. It is also known as paradoxical sleep. It is difficult to wake someone from this stage. REM sleep lasts around 10 to 60 minutes, consisting of 20% to 25% of total sleep time. The duration increases as the night progresses.</p> <ul> <li>Brain activity mimicks normal awake</li> <li>Rapid eye movements</li> <li>Respiration increases and irregular</li> <li>Heart rate increases</li> <li>Temperature regulation is off</li> <li>Body becomes immobile</li> </ul>"},{"location":"stages/overview/#limitations","title":"Limitations","text":"<p>Inferring sleep stage without electrophysiological signals is an extremely challenging task. Especially when considering a highly noisy ambulatory environment. Furthermore, the limited time spent in certain sleep stages such as N1 makes it difficult to accurately classify these stages. This is highlighted by the limited interrater reliability of sleep stage scoring. A recent paper by Kapur et al., 2021 performed a meta-analysis of 101 studies and found that the interrater reliability for stage N1 sleep was only fair, while the interrater reliabilities for stage N2 and N3 sleep were moderate. The paper found the Cohen\u2019s kappa for manual, overall sleep scoring was 0.76, indicating substantial agreement (95% confidence interval, 0.71\u20130.81; P &lt; .001). By sleep stage, the figures were 0.70, 0.24, 0.57, 0.57, and 0.69 for the W, N1, N2, N3, and R stages, respectively. The interrater reliabilities for stage N2 and N3 sleep were moderate, and that for stage N1 sleep was only fair. Taking this into account, we should not expect to achieve perfect sleep stage classification.</p>"},{"location":"stages/results/","title":"Results","text":"<p>The following table provides the latest performance and accuracy results of the reference models.</p> # Classes Model Dataset Fs Params FLOPs Accuracy F1 AP 2 TCN MESA 64 Hz 10K 1.7M/hr 88.8% 88.8% 96.2% 3 TCN MESA 64 Hz 14K 2.2M/hr 83.9% 84.2% 91.5% 4 TCN MESA 64 Hz 14K 2.3M/hr 75.8% 76.4% 83.1% 5 TCN MESA 64 Hz 17K 2.8M/hr 70.4% 70.2% 76.4%"},{"location":"stages/results/#confusion-matrices","title":"Confusion Matrices","text":"2-Stage3-Stage4-Stage5-Stage"},{"location":"stages/results/#sleep-efficiency-plot","title":"Sleep Efficiency Plot","text":""},{"location":"stages/results/#total-sleep-time-tst-plot","title":"Total Sleep Time (TST) Plot","text":""},{"location":"stages/results/#evb-performance","title":"EVB Performance","text":"<p>The following table provides the latest performance and accuracy results of all models when running on Apollo4 Plus EVB. These results are obtained using neuralSPOTs Autodeploy tool. From neuralSPOT repo, the following command can be used to capture EVB results via Autodeploy:</p> <pre><code>python -m ns_autodeploy \\\n--tflite-filename sleep-stage-4-model.tflite \\\n--model-name sleepstage4 \\\n--cpu-mode 192 \\\n--arena-size-scratch-buffer-padding 0 \\\n--max-arena-size 80 \\\n</code></pre> Task Params FLOPS Metric Cycles Time Arena NVM RAM 2-Stage Sleep 10K 1.7M/hr 88.8% F1 11M/hr 58ms/hr 35KB 193KB 53KB 3-Stage Sleep 14K 2.2M/hr 84.2% F1 16M/hr 80ms/hr 38KB 208KB 57KB 4-Stage Sleep 14K 2.3M/hr 76.4% F1 16M/hr 80ms/hr 38KB 208KB 57KB 5-Stage Sleep 17K 2.8M/hr 70.2% F1 18M/hr 91ms/hr 43KB 216KB 61KB <p>In addition, we can capture statistics from each layer. The following bar plot provides the latency of each block in the 4-stage sleep classification TCN model. For example, <code>ENC</code> refers to initial encoder 1-d seperable convulional layer, <code>B1.1</code> refers to all the layers in block 1, depth 1, <code>B1.2</code> refers to block 1, depth 2, and so on. We can see that as we go deeper into the network we see an increase in latency due to the increasing number of channels. The final <code>DEC</code> layer refers to the decoder layer which is a 1-d convolutional layer with 3 output channels (4 classes).</p>"},{"location":"stages/results/#comparison","title":"Comparison","text":"<p>We compare our 3-stage and 4-stage model to the SLAMSS model from Song et al., 2023. Their model was also trained on MESA dataset using only motor and cardiac physiological signals. In particular, they extract activity count, heart rate, and heart rate standard deviation in 30 second epochs. They fed 12 epochs (6 minutes) of the 3 features (12x6) as input to the network. The newtork consists of 3 1-D CNN layers, 2 LSTM layers, and 1 attention layer. The underlying design of the attention block is unclear but using only the 3 CNN and 2 LSTM layers the network requires roughly 8.8 MFLOPS per epoch. This equates to roughly 450X more computation (1,056 MFLOPS/hr) compared to our 4-stage sleep classification model (2.3 MFLOPS/hr).</p>"},{"location":"stages/results/#3-stage-sleep-classification-mesa","title":"3-Stage Sleep Classification (MESA)","text":"Reference Acc F1 WAKE NREM REM Song et al., 2023 79.1 80.0 78.0 81.8 70.9 SleepKit 83.9 84.2 80.3 86.6 83.5"},{"location":"stages/results/#4-stage-sleep-classification-mesa","title":"4-Stage Sleep Classification (MESA)","text":"Reference Acc F1 WAKE CORE DEEP REM Song et al., 2023 70.0 72.0 78.7 66.3 55.9 63.0 SleepKit 75.8 76.4 80.6 73.9 52.2 81.7"}]}